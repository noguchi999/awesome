{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime, time, re, warnings, gc, json, random, yaml, umap, pickle\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score, f1_score\n",
    "from sklearn import datasets, manifold, mixture, model_selection\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz, hstack\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as tuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 256)\n",
    "pd.set_option(\"display.max_rows\", 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    print(f'[{title}] start')\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(metaclass=ABCMeta):\n",
    "    BASE_DIR = \".\"\n",
    "    NUMERICS = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = self.__class__.__name__\n",
    "        self.train = pd.DataFrame()\n",
    "        self.test = pd.DataFrame()\n",
    "        self.train_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_train\"\n",
    "        self.test_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_test\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_features(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def run(self, use_columns=[], skip_columns=[]):\n",
    "        with timer(self.name):\n",
    "            self.load_data()\n",
    "            self.replace_na(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.onehot_encode(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.create_features()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def onehot_encode(self, use_columns=[], skip_columns=[], sparse=False):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        self.label_encode(use_columns, skip_columns)\n",
    "        if sparse:\n",
    "            encoder = OneHotEncoder(categories='auto', sparse=sparse, dtype='uint8').fit(pd.concat([self.train.loc[:, use_columns], self.test.loc[:, use_columns]]))\n",
    "            m = 100000\n",
    "            train = vstack([encoder.transform(self.train[i*m:(i+1)*m].loc[:, use_columns]) for i in range(self.train.shape[0] // m + 1)])\n",
    "            test  = vstack([encoder.transform(self.test[i*m:(i+1)*m].loc[:, use_columns])  for i in range(self.test.shape[0] // m +  1)])\n",
    "            save_npz(f\"{self.train_file_path}.npz\", train, compressed=True)\n",
    "            save_npz(f\"{self.test_file_path}.npz\",  test,  compressed=True)\n",
    "        else:\n",
    "            self.train[\"is_train_date\"] = 1\n",
    "            self.test[\"is_train_date\"]  = 0\n",
    "            df = pd.concat([self.train, self.test])\n",
    "            del self.train, self.test\n",
    "            gc.collect()\n",
    "            for col in use_columns:\n",
    "                df = df.join(pd.get_dummies(df[col], prefix=col))\n",
    "            \n",
    "            self.train = df[df[\"is_train_date\"]==1]\n",
    "            self.test = df[df[\"is_train_date\"]==0]\n",
    "            self.train.drop(columns=\"is_train_date\", inplace=True)\n",
    "            self.test.drop(columns=\"is_train_date\", inplace=True)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def label_encode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        \n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "        \n",
    "        for col in use_columns:\n",
    "            if df[col].dtype.name in [\"object\", \"category\"]:\n",
    "                df[col] = df[col].astype(str)\n",
    "                le = LabelEncoder().fit(df[col])\n",
    "                df[col] = le.transform(df[col])+1\n",
    "    \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def target_encode(self, col_name, target_name, min_samples_leaf=1, smoothing=1, noise_level=0):\n",
    "        trn_series = self.train[col_name]\n",
    "        tst_series = self.test[col_name]\n",
    "        target = self.train[target_name]\n",
    "        \n",
    "        assert len(trn_series) == len(target)\n",
    "\n",
    "        temp = pd.concat([trn_series, target], axis=1)\n",
    "        averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "        smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "        prior = target.mean()\n",
    "        averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "        averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "        ft_trn_series = pd.merge(\n",
    "            trn_series.to_frame(trn_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=trn_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_trn_series.index = trn_series.index \n",
    "        ft_tst_series = pd.merge(\n",
    "            tst_series.to_frame(tst_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=tst_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_tst_series.index = tst_series.index\n",
    "\n",
    "        self.train[f\"te_smoothing_{col_name}\"], self.test[f\"te_smoothing_{col_name}\"] = self.__add_noise(ft_trn_series, noise_level), self.__add_noise(ft_tst_series, noise_level)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "            \n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                df[f\"{prefix}{k}_{v}\"] = df.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    df[f\"{prefix}{k}_{vv}\"] = df.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform_ratio(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "        prefix = f\"ratio_{prefix}\"\n",
    "        \n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                self.train[f\"{prefix}{k}_{v}\"] = self.train[k] / self.train.groupby(group)[k].transform(v)\n",
    "                self.test[f\"{prefix}{k}_{v}\"] = self.test[k] / self.test.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    self.train[f\"{prefix}{k}_{vv}\"] = self.train[k] / self.train.groupby(group)[k].transform(vv)\n",
    "                    self.test[f\"{prefix}{k}_{vv}\"] = self.test[k] / self.test.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def replace_na(self, use_columns=[], skip_columns=[], fill_value=-1):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mode().values[0])\n",
    "            self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mode().values[0])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mean(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mean())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mean())\n",
    "\n",
    "        return self\n",
    "\n",
    "    def replace_na_median(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].median())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].median())\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_topic_score(self, topic_text_columns, num_topics=5):\n",
    "        df = pd.concat([self.train.loc[:, topic_text_columns], self.test.loc[:, topic_text_columns]])\n",
    "        \n",
    "        for col in topic_text_columns:\n",
    "            texts = [[word for word in document.lower().split()] for document in df[col].values]\n",
    "            dictionary = corpora.Dictionary(texts)\n",
    "            bow_corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "            lda = models.LdaModel(bow_corpus, id2word=dictionary, num_topics=num_topics)\n",
    "                        \n",
    "            size = df.shape[0]\n",
    "            topics = {i:[-1]*size for i in range(num_topics)}\n",
    "            for i, row in enumerate(lda[bow_corpus]):\n",
    "                for (topic_num, prop_topic) in row:\n",
    "                    topics[topic_num][i] = prop_topic\n",
    "            \n",
    "            for i in range(num_topics):\n",
    "                self.train[f\"{col}_topic_{i}\"] = topics[i][:self.train.shape[0]]\n",
    "                self.test[f\"{col}_topic_{i}\"] = topics[i][self.train.shape[0]:]\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_scdv_word2vec_score(self, text_col_name):\n",
    "        features_num = 20\n",
    "        min_word_count = 10\n",
    "        context = 5\n",
    "        downsampling = 1e-3\n",
    "        epoch_num = 10\n",
    "        clusters_num = 6\n",
    "        \n",
    "        df = pd.concat([self.train.loc[:, [text_col_name]], self.test.loc[:, [text_col_name]]])\n",
    "        df[text_col_name] = df[text_col_name].fillna(\"\")\n",
    "        \n",
    "        corpus = [self.__analyzer_cat(text) for text in df[text_col_name]]\n",
    "        word2vecs = Word2Vec(sentences=corpus, iter=epoch_num, size=features_num, min_count=min_word_count, window=context, sample=downsampling)\n",
    "        word_vectors = word2vecs.wv.vectors\n",
    "        \n",
    "        gmm = mixture.GaussianMixture(n_components=clusters_num, covariance_type='tied', max_iter=50)\n",
    "        gmm.fit(word_vectors)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer=self.__analyzer_cat, min_df=min_word_count)\n",
    "        tfidfs = tfidf_vectorizer.fit_transform(df[text_col_name])\n",
    "        \n",
    "        idf_dic = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer._tfidf.idf_))\n",
    "        assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict(word_vectors)))\n",
    "        soft_assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict_proba(word_vectors)))\n",
    "        \n",
    "        word_topic_vecs = {}\n",
    "        for word in assign_dic:\n",
    "            word_topic_vecs[word] = np.zeros(features_num*clusters_num, dtype=np.float32)\n",
    "            for i in range(0, clusters_num):\n",
    "                try:\n",
    "                    word_topic_vecs[word][i*features_num:(i+1)*features_num] = word2vecs.wv[word]*soft_assign_dic[word][i]*idf_dic[word]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        scdvs = np.zeros((len(df[text_col_name]), clusters_num*features_num), dtype=np.float32)\n",
    "\n",
    "        a_min = 0\n",
    "        a_max = 0\n",
    "\n",
    "        for i, text in enumerate(df[text_col_name]):\n",
    "            tmp = np.zeros(clusters_num*features_num, dtype=np.float32)\n",
    "            words = self.__analyzer_cat(text)\n",
    "            for word in words:\n",
    "                if word in word_topic_vecs:\n",
    "                    tmp += word_topic_vecs[word]\n",
    "            norm = np.sqrt(np.sum(tmp**2))\n",
    "            if norm > 0:\n",
    "                tmp /= norm\n",
    "            a_min += min(tmp)\n",
    "            a_max += max(tmp)\n",
    "            scdvs[i] = tmp\n",
    "\n",
    "        p = 0.04\n",
    "        a_min = a_min*1.0 / len(df[text_col_name])\n",
    "        a_max = a_max*1.0 / len(df[text_col_name])\n",
    "        thres = (abs(a_min)+abs(a_max)) / 2\n",
    "        thres *= p\n",
    "        scdvs[abs(scdvs) < thres] = 0\n",
    "        \n",
    "        tsne_scdv = manifold.TSNE(n_components=2).fit_transform(scdvs)\n",
    "        \n",
    "        self.train[f\"scdv_{text_col_name}_x\"] = tsne_scdv[:self.train.shape[0], 0]\n",
    "        self.train[f\"scdv_{text_col_name}_y\"] = tsne_scdv[:self.train.shape[0], 1]        \n",
    "        self.test[f\"scdv_{text_col_name}_x\"] = tsne_scdv[self.train.shape[0]:, 0]\n",
    "        self.test[f\"scdv_{text_col_name}_y\"] = tsne_scdv[self.train.shape[0]:, 1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def yeo_johnson(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "        \n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        pt.fit(df[num_columns])\n",
    "\n",
    "        df[num_columns] = pt.transform(df[num_columns])\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def umap_scaler(self, skip_columns=[]):\n",
    "        self.yeo_johnson(skip_columns=skip_columns)\n",
    "        \n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS and df[col].unique().shape[0] > 100]\n",
    "        for col in num_columns:\n",
    "            df[col] = df[col].replace(np.inf, np.nan)\n",
    "            df[col].fillna(-9999, inplace=True)\n",
    "        \n",
    "        um = umap.UMAP()\n",
    "        um.fit(df[num_columns])\n",
    "        d = um.transform(df[num_columns])\n",
    "        df[\"umap_d1\"] = d[:, 0]\n",
    "        df[\"umap_d2\"] = d[:, 1]\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_kmean_features(self, seed, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        for col in num_columns:\n",
    "            df[col].fillna(-9999, inplace=True)\n",
    "        X = df[num_columns]\n",
    "        \n",
    "        kmeans = MiniBatchKMeans(n_clusters=10, random_state=seed)\n",
    "        kmeans.fit(X)\n",
    "\n",
    "        df[\"k_class\"] = kmeans.predict(X)\n",
    "        train_distances = kmeans.transform(X)\n",
    "        for i in range(10):\n",
    "            df[f\"k_distance_{i}\"] = train_distances[:, i]\n",
    "    \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def min_max_scaling(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df[num_columns])\n",
    "        df[num_columns] = scaler.transform(df[num_columns])\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def two_by_two(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        targets = num_columns.copy()\n",
    "        for col in num_columns:\n",
    "            targets.remove(col)\n",
    "            for t in targets:\n",
    "                df[f\"{col}_{t}_mul\"] = df[col] * df[t]\n",
    "                df[f\"{col}_{t}_sub_left\"] = df[col] / df[t]\n",
    "                df[f\"{col}_{t}_sub_right\"] = df[t] / df[col]\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def columns_1d(self):\n",
    "        self.train.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.train.columns.tolist()])\n",
    "        self.test.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.test.columns.tolist()])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def head(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train head: {title}\")\n",
    "        print(self.train.loc[:, train_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test head: {title}\")\n",
    "        print(self.test.loc[:, test_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tail(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train tail: {title}\")\n",
    "        print(self.train.loc[:, train_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test tail: {title}\")\n",
    "        print(self.test.loc[:, test_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def save(self, format=\"feather\", index=False):\n",
    "        if format == \"feather\":\n",
    "            self.train.to_feather(f\"{self.train_file_path}.ftr\")\n",
    "            self.test.to_feather(f\"{self.test_file_path}.ftr\")\n",
    "        elif format == \"csv\":\n",
    "            self.train.to_csv(f\"{self.train_file_path}.csv\", index=index)\n",
    "            self.test.to_csv(f\"{self.test_file_path}.csv\", index=index)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __add_noise(self, series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "    def __analyzer_nlp(self, text):\n",
    "        stop_words = ['i', 'a', 'an', 'the', 'to', 'and', 'or', 'if', 'is', 'are', 'am', 'it', 'this', 'that', 'of', 'from', 'in', 'on']\n",
    "        text = text.lower()\n",
    "        text = text.replace('\\n', '')\n",
    "        text = text.replace('\\t', '')\n",
    "        text = re.sub(re.compile(r'[!-\\/:-@[-`{-~]'), ' ', text)\n",
    "        text = text.split(' ')\n",
    "\n",
    "        words = []\n",
    "        for word in text:\n",
    "            if (re.compile(r'^.*[0-9]+.*$').fullmatch(word) is not None):\n",
    "                continue\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            words.append(word)\n",
    "\n",
    "        return words\n",
    "\n",
    "    def __analyzer_cat(self, text):\n",
    "        return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoML():\n",
    "    SEED = 42\n",
    "    EVAL_COLUMN = \"_preds\"\n",
    "    NUMERICS = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        if not isinstance(engine, FeatureEngineering): raise TypeError\n",
    "        self.engine = engine\n",
    "    \n",
    "    def run(self, scenario):\n",
    "        self.__seed_everything(AutoML.SEED)\n",
    "        self.target = scenario[\"target\"]\n",
    "        self.engine.load_data()\n",
    "        \n",
    "        params = {\n",
    "            'objective': scenario[\"objective\"],\n",
    "            'boosting_type': scenario[\"boosting_type\"], \n",
    "            'metric': scenario[\"metric\"],\n",
    "            'n_jobs': -1,\n",
    "            'seed': AutoML.SEED\n",
    "        }\n",
    "        tuned = self.__hyper_parameter_tuning(params)\n",
    "        params = dict(params, **tuned)\n",
    "        \n",
    "        self.predicts, importance = self.__train(params)\n",
    "        \n",
    "    def greedy_forward_selection(self, base_score, base_path=\"./\"):\n",
    "        self.__seed_everything(AutoML.SEED)\n",
    "        best_score = 0.0\n",
    "        selected = set([])\n",
    "        params = None\n",
    "        scenario = None\n",
    "        del self.engine.train, self.engine.test\n",
    "        with open(f\"{base_path}/param_{base_score}.json\") as f:\n",
    "            params = json.load(f)\n",
    "        with open(f\"{base_path}/scenario_{base_score}.yml\", \"r\") as yml:\n",
    "            scenario = yaml.safe_load(yml)\n",
    "        self.target = scenario[\"target\"]\n",
    "        \n",
    "        train = pd.read_pickle(f\"{base_path}/train_{base_score}.pkl\")\n",
    "        test = pd.read_pickle(f\"{base_path}/test_{base_score}.pkl\")\n",
    "        \n",
    "        train_x = [f for f in train.columns if f not in self.target]\n",
    "        while True:\n",
    "            if len(selected) == len(train_x): break\n",
    "            \n",
    "            scores = []\n",
    "            for col in train_x:\n",
    "                if col not in selected:\n",
    "                    feats = list(selected) + [col]\n",
    "                    self.engine.train = train[list(feats)+[self.target]]\n",
    "                    self.engine.test = test[feats]\n",
    "                    self.predicts, importance = self.__train(params)\n",
    "                    param_with_score = self.__evaluate(params, pd.read_csv(scenario[\"eval_file_path\"]))\n",
    "                    scores.append((col, param_with_score[\"score\"]))\n",
    "            \n",
    "            b_feature, b_score = sorted(scores, key=lambda tpl: tpl[1], reverse=True)[0]\n",
    "            print(f\"b_score: {b_score}\")\n",
    "            print(f\"best_score: {best_score}\")\n",
    "            if b_score > best_score:\n",
    "                selected.add(b_feature)\n",
    "                best_score = b_score\n",
    "                print(f'selected:{b_feature}')\n",
    "                print(f'score:{b_score}')\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(f'selected features: {selected}')\n",
    "        with open(\"selected.pkl\", \"wb\") as fw:\n",
    "            pickle.dump(selected, fw)\n",
    "            \n",
    "    def __do(self, command):\n",
    "        if command == \"fill_numeric_na\":\n",
    "            self.__fill_numeric_na()\n",
    "        if command == \"binning\":\n",
    "            self.__binning()\n",
    "        if command == \"transformation\":\n",
    "            self.__transformation()\n",
    "        if command == \"topic_encoding\":\n",
    "            self.__topic_encoding()\n",
    "        if command == \"umap\":\n",
    "            self.engine.umap_scaler(skip_columns=[self.target])\n",
    "        if command == \"kmean_features\":\n",
    "            self.engine.create_kmean_features(skip_columns=[self.target], seed=AutoML.SEED)\n",
    "        if command == \"min_max_scaling\":\n",
    "            self.engine.min_max_scaling(skip_columns=[self.target])\n",
    "        if command == \"two_by_two\":\n",
    "            self.engine.two_by_two(skip_columns=[self.target])\n",
    "    \n",
    "    def __evaluate(self, params, actuals, metric):\n",
    "        calc_score_param = {\"metric\": metric}\n",
    "        actuals[AutoML.EVAL_COLUMN] = self.predicts\n",
    "        if params[\"objective\"] == \"binary\":\n",
    "            actuals.loc[actuals[AutoML.EVAL_COLUMN]>=0.5, AutoML.EVAL_COLUMN] = 1\n",
    "            actuals.loc[actuals[AutoML.EVAL_COLUMN]<0.5, AutoML.EVAL_COLUMN] = 0\n",
    "            actuals[AutoML.EVAL_COLUMN] = actuals[AutoML.EVAL_COLUMN].astype(\"int\")\n",
    "        \n",
    "        score = self.__calc_score(calc_score_param, actuals[self.target], actuals[AutoML.EVAL_COLUMN])\n",
    "        params[\"score\"] = score\n",
    "        print(f\"Score: {score}\")\n",
    "        return params\n",
    "    \n",
    "    def __transformation(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        aggs = [\"min\", \"max\", \"mean\", \"std\"]\n",
    "        for col in feats:\n",
    "            if self.engine.train[col].dtype.name == \"category\":\n",
    "                self.engine.agg_transform(group=[col], agg={f\"{col}\": [\"count\"]})\n",
    "            for c in num_columns:\n",
    "                if c == col: continue\n",
    "                self.engine.agg_transform(group=[col], agg={f\"{c}\": aggs})\n",
    "                for agg in aggs:\n",
    "                    if self.engine.train[self.engine.train[f\"{col}_{c}_{agg}\"].isnull()].shape[0] > 0:\n",
    "                        self.engine.train.drop(columns=[f\"{col}_{c}_{agg}\"], inplace=True)\n",
    "                        self.engine.test.drop(columns=[f\"{col}_{c}_{agg}\"], inplace=True)\n",
    "\n",
    "    def __fill_numeric_na(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        cat_columns = [col for col in feats if self.engine.train[col].dtype.name == \"category\"]\n",
    "        groups = []\n",
    "        for c in cat_columns:\n",
    "            if self.engine.train[self.engine.train[c].isnull()].shape[0] == 0:\n",
    "                if self.engine.train.groupby(c).size().shape[0] / self.engine.train.shape[0] < 0.1:\n",
    "                    groups.append(c)\n",
    "        for n in num_columns:\n",
    "            if len(groups) > 0:\n",
    "                self.engine.agg_transform(group=groups, agg={f\"{n}\": [\"mean\"]}, prefix=\"_tmp\")\n",
    "                self.engine.train[n].fillna(self.engine.train[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.test[n].fillna(self.engine.test[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.train.drop(columns=[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.test.drop(columns=[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "\n",
    "    def __binning(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        border = self.engine.train.shape[0]\n",
    "        df = pd.concat([self.engine.train, self.engine.test], ignore_index=True)\n",
    "        del self.engine.train, self.engine.test\n",
    "        gc.collect()\n",
    "\n",
    "        for c in num_columns:\n",
    "            if df[c].unique().shape[0] > 100:\n",
    "                df[f\"{c}_bin\"] = pd.cut(df[c], 10, labels=False)\n",
    "        self.engine.train = df.iloc[:border]\n",
    "        self.engine.test = df.iloc[border:]\n",
    "    \n",
    "    def __topic_encoding(self):\n",
    "        self.__create_topic_text()\n",
    "        self.engine.calc_topic_score(topic_text_columns=[\"topic_text\"], num_topics=5)\n",
    "        self.__drop_features([\"topic_text\"])\n",
    "\n",
    "    def __create_topic_text(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        border = self.engine.train.shape[0]\n",
    "        df = pd.concat([self.engine.train, self.engine.test], ignore_index=True)\n",
    "        del self.engine.train, self.engine.test\n",
    "        gc.collect()\n",
    "        \n",
    "        df[\"topic_text\"] = \"\"\n",
    "        for c in num_columns:\n",
    "            df[\"topic_text\"] = df[\"topic_text\"].astype(str) + \" \" + df[c].astype(str)\n",
    "\n",
    "        self.engine.train = df.iloc[:border]\n",
    "        self.engine.test = df.iloc[border:]\n",
    "    \n",
    "    def __set_column_type(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        for col in feats:\n",
    "            col_type = self.engine.train[col].dtypes\n",
    "            if self.engine.train[col].unique().shape[0] < 20:\n",
    "                self.engine.train[col] = self.engine.train[col].astype(\"category\")\n",
    "                self.engine.test[col] = self.engine.test[col].astype(\"category\")\n",
    "\n",
    "    def __drop_features(self, cols):\n",
    "        feats = [f for f in self.engine.train.columns if f in cols]\n",
    "        self.engine.train.drop(columns=feats, inplace=True)\n",
    "        self.engine.test.drop(columns=feats, inplace=True)\n",
    "    \n",
    "    def __feature_selection(self, cols):\n",
    "        self.engine.train = self.engine.train.loc[:, list(cols)+[self.target]]\n",
    "        self.engine.test = self.engine.test.loc[:, cols]\n",
    "    \n",
    "    def __hyper_parameter_tuning(self, params):\n",
    "        train, valid = model_selection.train_test_split(self.engine.train, test_size=0.33, random_state=AutoML.SEED, shuffle=True)\n",
    "        feats = list(range(0, 119))\n",
    "        \n",
    "        lgb_train = tuna.Dataset(train[feats], label=train[self.target].values)\n",
    "        lgb_valid = tuna.Dataset(valid[feats], label=valid[self.target].values)\n",
    "        best_params, tuning_history = dict(), list()\n",
    "\n",
    "        model = tuna.train(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_valid],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        num_boost_round=1000, \n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=100,\n",
    "                        best_params=best_params,\n",
    "                        tuning_history=tuning_history\n",
    "                        )\n",
    "\n",
    "        return best_params\n",
    "    \n",
    "    def __adversarial_validation(self, num_folds=5):\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        train = self.engine.train[feats]\n",
    "        test = self.engine.test[feats]\n",
    "        train[self.target] = 0\n",
    "        test[self.target] = 1\n",
    "        \n",
    "        df = pd.concat([train, test], ignore_index=True)\n",
    "        del train, test\n",
    "        gc.collect()\n",
    "        \n",
    "        oof_preds = np.zeros(df.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        scores = []\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[feats], df[self.target])):\n",
    "            train_x, train_y = df[feats].iloc[train_idx], df[self.target].iloc[train_idx]\n",
    "            valid_x, valid_y = df[feats].iloc[valid_idx], df[self.target].iloc[valid_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_x,\n",
    "                                    label=train_y,\n",
    "                                    free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(valid_x,\n",
    "                                   label=valid_y,\n",
    "                                   free_raw_data=False)\n",
    "            params = {'num_leaves': 50,\n",
    "                     'min_data_in_leaf': 30, \n",
    "                     'objective':'binary',\n",
    "                     'max_depth': 5,\n",
    "                     'learning_rate': 0.1,\n",
    "                     \"min_child_samples\": 20,\n",
    "                     \"boosting\": \"gbdt\",\n",
    "                     \"feature_fraction\": 0.9,\n",
    "                     \"bagging_freq\": 1,\n",
    "                     \"bagging_fraction\": 0.9 ,\n",
    "                     \"bagging_seed\": 44,\n",
    "                     \"metric\": 'auc',\n",
    "                     \"verbosity\": -1}\n",
    "\n",
    "            model = lgb.train(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_valid],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        num_boost_round=1000, \n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=100\n",
    "                        )\n",
    "\n",
    "            oof_preds[valid_idx] = model.predict(valid_x, num_iteration=model.best_iteration)\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = np.log1p(model.feature_importance(importance_type='gain', iteration=model.best_iteration))\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            scores.append(self.__calc_score(params, valid_y, oof_preds[valid_idx]))\n",
    "\n",
    "        self.__display_importances(feature_importance_df)\n",
    "        \n",
    "        return sum(scores)/len(scores), feature_importance_df\n",
    "        \n",
    "    def __train(self, params, num_folds=5, stratified=False):\n",
    "        if stratified:\n",
    "            folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "        else:\n",
    "            folds = KFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "\n",
    "        feats = list(range(0, 119))\n",
    "        oof_preds = np.zeros(self.engine.train.shape[0])\n",
    "        sub_preds = np.zeros(self.engine.test.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        scores = []\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(self.engine.train[feats], self.engine.train[self.target])):\n",
    "            train_x, train_y = self.engine.train[feats].iloc[train_idx], self.engine.train[self.target].iloc[train_idx]\n",
    "            valid_x, valid_y = self.engine.train[feats].iloc[valid_idx], self.engine.train[self.target].iloc[valid_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_x,\n",
    "                                    label=train_y,\n",
    "                                    free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(valid_x,\n",
    "                                   label=valid_y,\n",
    "                                   free_raw_data=False)\n",
    "            model = lgb.train(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            valid_sets=[lgb_train, lgb_valid],\n",
    "                            valid_names=['train', 'valid'],\n",
    "                            num_boost_round=1000, \n",
    "                            early_stopping_rounds=100,\n",
    "                            verbose_eval=100\n",
    "                            )\n",
    "\n",
    "            oof_preds[valid_idx] = model.predict(valid_x, num_iteration=model.best_iteration)\n",
    "            sub_preds += model.predict(self.engine.test[feats], num_iteration=model.best_iteration) / folds.n_splits\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = np.log1p(model.feature_importance(importance_type='gain', iteration=model.best_iteration))\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            scores.append(self.__calc_score(params, valid_y, oof_preds[valid_idx]))\n",
    "\n",
    "        print('CV : %.6f' % (sum(scores)/len(scores)))\n",
    "        self.__display_importances(feature_importance_df)\n",
    "\n",
    "        return sub_preds, feature_importance_df\n",
    "    \n",
    "    def __display_importances(self, feature_importance_df_):\n",
    "        all_cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).index\n",
    "        feature_importance_df_.loc[feature_importance_df_.feature.isin(all_cols)].to_csv(\"feature_importance.csv\", index=False)\n",
    "\n",
    "        cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "        best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "        plt.figure(figsize=(8, 10))\n",
    "        sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "        plt.title('LightGBM Features (avg over folds)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lgbm_importances.png')\n",
    "    \n",
    "    def __calc_score(self, params, actuals, preds):\n",
    "        if params[\"metric\"] == \"rmse\":\n",
    "            return np.sqrt(mean_squared_error(actuals, preds))\n",
    "        if params[\"metric\"] in [\"cross_entropy\", \"binary_logloss\"]:\n",
    "            return log_loss(actuals, preds)\n",
    "        if params[\"metric\"] == \"auc\":\n",
    "            return roc_auc_score(actuals, preds)\n",
    "        if params[\"metric\"] == \"f1\":\n",
    "            return f1_score(actuals, preds)\n",
    "\n",
    "    def __seed_everything(self, seed):\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample(FeatureEngineering):\n",
    "    def load_data(self):\n",
    "        self.train = pd.read_pickle(\"./structure_train_01.pkl\")\n",
    "        self.test = pd.read_pickle(\"./structure_train_01.pkl\")\n",
    "        \n",
    "        self.train.columns = range(0, 119)\n",
    "        self.test.columns = range(0, 119)\n",
    "        df = pd.read_pickle(\"./structure_df_01.pkl\")\n",
    "        self.train[\"k_class\"] = df[\"k_class\"]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_features(self):\n",
    "        return self\n",
    "    \n",
    "    def create_topic_text(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/building_structure/scenario.yml\", \"r\") as yml:\n",
    "    scenario = yaml.safe_load(yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = AutoML(engine=Sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: inf:   0%|                                                     | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.830117\tvalid's rmse: 1.10479\n",
      "[200]\ttrain's rmse: 0.603451\tvalid's rmse: 1.00998\n",
      "[300]\ttrain's rmse: 0.493192\tvalid's rmse: 0.95979\n",
      "[400]\ttrain's rmse: 0.426377\tvalid's rmse: 0.943904\n",
      "[500]\ttrain's rmse: 0.374661\tvalid's rmse: 0.928036\n",
      "[600]\ttrain's rmse: 0.330072\tvalid's rmse: 0.918782\n",
      "[700]\ttrain's rmse: 0.294678\tvalid's rmse: 0.91052\n",
      "[800]\ttrain's rmse: 0.265148\tvalid's rmse: 0.907169\n",
      "[900]\ttrain's rmse: 0.243113\tvalid's rmse: 0.904585\n",
      "[1000]\ttrain's rmse: 0.222781\tvalid's rmse: 0.901623\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.222781\tvalid's rmse: 0.901623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.901623:  14%|#####7                                  | 1/7 [00:01<00:07,  1.28s/it][I 2020-03-18 13:02:45,382] Finished trial#0 resulted in value: 0.9016234918023868. Current best value is 0.9016234918023868 with parameters: {'feature_fraction': 0.4}.\n",
      "tune_feature_fraction, val_score: 0.901623:  14%|#####7                                  | 1/7 [00:01<00:07,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717008\tvalid's rmse: 0.9947\n",
      "[200]\ttrain's rmse: 0.510542\tvalid's rmse: 0.90019\n",
      "[300]\ttrain's rmse: 0.412093\tvalid's rmse: 0.872572\n",
      "[400]\ttrain's rmse: 0.341915\tvalid's rmse: 0.854746\n",
      "[500]\ttrain's rmse: 0.289133\tvalid's rmse: 0.847038\n",
      "[600]\ttrain's rmse: 0.24977\tvalid's rmse: 0.847105\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttrain's rmse: 0.276378\tvalid's rmse: 0.845695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.845695:  29%|###########4                            | 2/7 [00:02<00:05,  1.16s/it][I 2020-03-18 13:02:46,279] Finished trial#1 resulted in value: 0.8456946448080302. Current best value is 0.8456946448080302 with parameters: {'feature_fraction': 0.5}.\n",
      "tune_feature_fraction, val_score: 0.845695:  29%|###########4                            | 2/7 [00:02<00:05,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.668418\tvalid's rmse: 0.949756\n",
      "[200]\ttrain's rmse: 0.463033\tvalid's rmse: 0.860157\n",
      "[300]\ttrain's rmse: 0.358682\tvalid's rmse: 0.834237\n",
      "[400]\ttrain's rmse: 0.293623\tvalid's rmse: 0.825614\n",
      "[500]\ttrain's rmse: 0.243511\tvalid's rmse: 0.822328\n",
      "[600]\ttrain's rmse: 0.207364\tvalid's rmse: 0.820271\n",
      "[700]\ttrain's rmse: 0.1788\tvalid's rmse: 0.819644\n",
      "Early stopping, best iteration is:\n",
      "[685]\ttrain's rmse: 0.18371\tvalid's rmse: 0.818535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.818535:  43%|#################1                      | 3/7 [00:03<00:04,  1.14s/it][I 2020-03-18 13:02:47,364] Finished trial#2 resulted in value: 0.81853460318001. Current best value is 0.81853460318001 with parameters: {'feature_fraction': 0.6}.\n",
      "tune_feature_fraction, val_score: 0.818535:  43%|#################1                      | 3/7 [00:03<00:04,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.638604\tvalid's rmse: 0.903236\n",
      "[200]\ttrain's rmse: 0.439914\tvalid's rmse: 0.830509\n",
      "[300]\ttrain's rmse: 0.331557\tvalid's rmse: 0.809347\n",
      "[400]\ttrain's rmse: 0.263428\tvalid's rmse: 0.803908\n",
      "[500]\ttrain's rmse: 0.211848\tvalid's rmse: 0.802454\n",
      "Early stopping, best iteration is:\n",
      "[488]\ttrain's rmse: 0.216988\tvalid's rmse: 0.800255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.800255:  57%|######################8                 | 4/7 [00:04<00:03,  1.03s/it][I 2020-03-18 13:02:48,139] Finished trial#3 resulted in value: 0.8002553360135485. Current best value is 0.8002553360135485 with parameters: {'feature_fraction': 0.7}.\n",
      "tune_feature_fraction, val_score: 0.800255:  57%|######################8                 | 4/7 [00:04<00:03,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.630275\tvalid's rmse: 0.854866\n",
      "[200]\ttrain's rmse: 0.429936\tvalid's rmse: 0.798202\n",
      "[300]\ttrain's rmse: 0.323333\tvalid's rmse: 0.777433\n",
      "[400]\ttrain's rmse: 0.252404\tvalid's rmse: 0.77582\n",
      "[500]\ttrain's rmse: 0.200848\tvalid's rmse: 0.774007\n",
      "Early stopping, best iteration is:\n",
      "[490]\ttrain's rmse: 0.205034\tvalid's rmse: 0.7729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.772900:  71%|############################5           | 5/7 [00:04<00:01,  1.04it/s][I 2020-03-18 13:02:48,969] Finished trial#4 resulted in value: 0.772899946765218. Current best value is 0.772899946765218 with parameters: {'feature_fraction': 0.8}.\n",
      "tune_feature_fraction, val_score: 0.772900:  71%|############################5           | 5/7 [00:04<00:01,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.763381:  86%|##################################2     | 6/7 [00:05<00:00,  1.09it/s][I 2020-03-18 13:02:49,750] Finished trial#5 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'feature_fraction': 0.8999999999999999}.\n",
      "tune_feature_fraction, val_score: 0.763381:  86%|##################################2     | 6/7 [00:05<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.610142\tvalid's rmse: 0.836163\n",
      "[200]\ttrain's rmse: 0.400599\tvalid's rmse: 0.773164\n",
      "[300]\ttrain's rmse: 0.293563\tvalid's rmse: 0.767358\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttrain's rmse: 0.331531\tvalid's rmse: 0.76385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.763381: 100%|########################################| 7/7 [00:06<00:00,  1.22it/s][I 2020-03-18 13:02:50,348] Finished trial#6 resulted in value: 0.7638503538258471. Current best value is 0.7633813850234336 with parameters: {'feature_fraction': 0.8999999999999999}.\n",
      "tune_feature_fraction, val_score: 0.763381: 100%|########################################| 7/7 [00:06<00:00,  1.10it/s]\n",
      "tune_num_leaves, val_score: 0.763381:   0%|                                                     | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:   5%|##2                                          | 1/20 [00:00<00:10,  1.76it/s][I 2020-03-18 13:02:51,075] Finished trial#0 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:   5%|##2                                          | 1/20 [00:00<00:10,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  10%|####5                                        | 2/20 [00:01<00:11,  1.56it/s][I 2020-03-18 13:02:51,845] Finished trial#1 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  10%|####5                                        | 2/20 [00:01<00:11,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.747976\tvalid's rmse: 0.911023\n",
      "[200]\ttrain's rmse: 0.574708\tvalid's rmse: 0.844917\n",
      "[300]\ttrain's rmse: 0.478761\tvalid's rmse: 0.824784\n",
      "[400]\ttrain's rmse: 0.413457\tvalid's rmse: 0.816532\n",
      "[500]\ttrain's rmse: 0.365275\tvalid's rmse: 0.804376\n",
      "[600]\ttrain's rmse: 0.32873\tvalid's rmse: 0.800932\n",
      "[700]\ttrain's rmse: 0.296518\tvalid's rmse: 0.80116\n",
      "[800]\ttrain's rmse: 0.270285\tvalid's rmse: 0.796823\n",
      "[900]\ttrain's rmse: 0.248387\tvalid's rmse: 0.793351\n",
      "Early stopping, best iteration is:\n",
      "[896]\ttrain's rmse: 0.249191\tvalid's rmse: 0.792789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  15%|######7                                      | 3/20 [00:02<00:11,  1.48it/s][I 2020-03-18 13:02:52,627] Finished trial#2 resulted in value: 0.7927889107944261. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  15%|######7                                      | 3/20 [00:02<00:11,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  20%|#########                                    | 4/20 [00:02<00:11,  1.39it/s][I 2020-03-18 13:02:53,446] Finished trial#3 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  20%|#########                                    | 4/20 [00:03<00:11,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  25%|###########2                                 | 5/20 [00:03<00:11,  1.28it/s][I 2020-03-18 13:02:54,355] Finished trial#4 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  25%|###########2                                 | 5/20 [00:04<00:11,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  30%|#############5                               | 6/20 [00:04<00:10,  1.30it/s][I 2020-03-18 13:02:55,100] Finished trial#5 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  30%|#############5                               | 6/20 [00:04<00:10,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  35%|###############7                             | 7/20 [00:05<00:09,  1.32it/s][I 2020-03-18 13:02:55,840] Finished trial#6 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  35%|###############7                             | 7/20 [00:05<00:09,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  40%|##################                           | 8/20 [00:06<00:09,  1.33it/s][I 2020-03-18 13:02:56,605] Finished trial#7 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  40%|##################                           | 8/20 [00:06<00:09,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  45%|####################2                        | 9/20 [00:06<00:08,  1.26it/s][I 2020-03-18 13:02:57,476] Finished trial#8 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  45%|####################2                        | 9/20 [00:07<00:08,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  50%|######################                      | 10/20 [00:07<00:08,  1.24it/s][I 2020-03-18 13:02:58,296] Finished trial#9 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  50%|######################                      | 10/20 [00:07<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.06461\tvalid's rmse: 1.20275\n",
      "[200]\ttrain's rmse: 0.922679\tvalid's rmse: 1.08514\n",
      "[300]\ttrain's rmse: 0.843982\tvalid's rmse: 1.03378\n",
      "[400]\ttrain's rmse: 0.781455\tvalid's rmse: 1.01964\n",
      "[500]\ttrain's rmse: 0.736163\tvalid's rmse: 1.00604\n",
      "[600]\ttrain's rmse: 0.701868\tvalid's rmse: 0.999944\n",
      "[700]\ttrain's rmse: 0.668647\tvalid's rmse: 0.999561\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttrain's rmse: 0.682001\tvalid's rmse: 0.996619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  55%|########################2                   | 11/20 [00:08<00:06,  1.40it/s][I 2020-03-18 13:02:58,805] Finished trial#10 resulted in value: 0.9966194917507515. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  55%|########################2                   | 11/20 [00:08<00:06,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  60%|##########################4                 | 12/20 [00:09<00:05,  1.39it/s][I 2020-03-18 13:02:59,529] Finished trial#11 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  60%|##########################4                 | 12/20 [00:09<00:05,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  65%|############################6               | 13/20 [00:09<00:05,  1.37it/s][I 2020-03-18 13:03:00,295] Finished trial#12 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  65%|############################6               | 13/20 [00:09<00:05,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  70%|##############################8             | 14/20 [00:10<00:04,  1.33it/s][I 2020-03-18 13:03:01,095] Finished trial#13 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  70%|##############################8             | 14/20 [00:10<00:04,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  75%|#################################           | 15/20 [00:11<00:03,  1.40it/s][I 2020-03-18 13:03:01,692] Finished trial#14 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  75%|#################################           | 15/20 [00:11<00:03,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  80%|###################################2        | 16/20 [00:12<00:02,  1.37it/s][I 2020-03-18 13:03:02,481] Finished trial#15 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  80%|###################################2        | 16/20 [00:12<00:02,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  85%|#####################################4      | 17/20 [00:12<00:02,  1.28it/s][I 2020-03-18 13:03:03,402] Finished trial#16 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  85%|#####################################4      | 17/20 [00:13<00:02,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  90%|#######################################6    | 18/20 [00:13<00:01,  1.23it/s][I 2020-03-18 13:03:04,316] Finished trial#17 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  90%|#######################################6    | 18/20 [00:13<00:01,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381:  95%|#########################################8  | 19/20 [00:14<00:00,  1.30it/s][I 2020-03-18 13:03:04,943] Finished trial#18 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381:  95%|#########################################8  | 19/20 [00:14<00:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.763381: 100%|############################################| 20/20 [00:15<00:00,  1.35it/s][I 2020-03-18 13:03:05,604] Finished trial#19 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'num_leaves': 31}.\n",
      "tune_num_leaves, val_score: 0.763381: 100%|############################################| 20/20 [00:15<00:00,  1.31it/s]\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:   0%|                              | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.18891\tvalid's rmse: 1.1909\n",
      "[200]\ttrain's rmse: 0.986267\tvalid's rmse: 1.11943\n",
      "[300]\ttrain's rmse: 0.864312\tvalid's rmse: 1.07915\n",
      "[400]\ttrain's rmse: 0.766096\tvalid's rmse: 1.07194\n",
      "[500]\ttrain's rmse: 0.70184\tvalid's rmse: 1.02265\n",
      "[600]\ttrain's rmse: 0.648452\tvalid's rmse: 1.01942\n",
      "[700]\ttrain's rmse: 0.602117\tvalid's rmse: 1.02996\n",
      "Early stopping, best iteration is:\n",
      "[662]\ttrain's rmse: 0.617704\tvalid's rmse: 0.988044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  10%|##2                   | 1/10 [00:00<00:05,  1.71it/s][I 2020-03-18 13:03:06,293] Finished trial#0 resulted in value: 0.9880441144545407. Current best value is 0.9880441144545407 with parameters: {'bagging_fraction': 0.43211646497991746, 'bagging_freq': 5}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  10%|##2                   | 1/10 [00:00<00:05,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.752211\tvalid's rmse: 0.959612\n",
      "[200]\ttrain's rmse: 0.580519\tvalid's rmse: 0.898353\n",
      "[300]\ttrain's rmse: 0.479832\tvalid's rmse: 0.865544\n",
      "[400]\ttrain's rmse: 0.413075\tvalid's rmse: 0.855456\n",
      "[500]\ttrain's rmse: 0.356506\tvalid's rmse: 0.843602\n",
      "[600]\ttrain's rmse: 0.310064\tvalid's rmse: 0.842531\n",
      "Early stopping, best iteration is:\n",
      "[502]\ttrain's rmse: 0.355204\tvalid's rmse: 0.84132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  20%|####4                 | 2/10 [00:01<00:04,  1.65it/s][I 2020-03-18 13:03:06,958] Finished trial#1 resulted in value: 0.8413198259232945. Current best value is 0.8413198259232945 with parameters: {'bagging_fraction': 0.6829043317024043, 'bagging_freq': 1}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  20%|####4                 | 2/10 [00:01<00:04,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.690202\tvalid's rmse: 0.90167\n",
      "[200]\ttrain's rmse: 0.488128\tvalid's rmse: 0.83706\n",
      "[300]\ttrain's rmse: 0.379701\tvalid's rmse: 0.804162\n",
      "[400]\ttrain's rmse: 0.304796\tvalid's rmse: 0.794405\n",
      "[500]\ttrain's rmse: 0.250779\tvalid's rmse: 0.784461\n",
      "[600]\ttrain's rmse: 0.208119\tvalid's rmse: 0.780577\n",
      "[700]\ttrain's rmse: 0.176153\tvalid's rmse: 0.778829\n",
      "[800]\ttrain's rmse: 0.149772\tvalid's rmse: 0.782938\n",
      "Early stopping, best iteration is:\n",
      "[700]\ttrain's rmse: 0.176153\tvalid's rmse: 0.778829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  30%|######6               | 3/10 [00:02<00:04,  1.41it/s][I 2020-03-18 13:03:07,919] Finished trial#2 resulted in value: 0.7788285276914089. Current best value is 0.7788285276914089 with parameters: {'bagging_fraction': 0.8303849484265573, 'bagging_freq': 1}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  30%|######6               | 3/10 [00:02<00:04,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.82668\tvalid's rmse: 0.989118\n",
      "[200]\ttrain's rmse: 0.640211\tvalid's rmse: 0.932643\n",
      "[300]\ttrain's rmse: 0.536584\tvalid's rmse: 0.908333\n",
      "[400]\ttrain's rmse: 0.468319\tvalid's rmse: 0.896587\n",
      "[500]\ttrain's rmse: 0.412627\tvalid's rmse: 0.883604\n",
      "[600]\ttrain's rmse: 0.367086\tvalid's rmse: 0.883239\n",
      "Early stopping, best iteration is:\n",
      "[540]\ttrain's rmse: 0.394021\tvalid's rmse: 0.879359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  40%|########8             | 4/10 [00:02<00:04,  1.42it/s][I 2020-03-18 13:03:08,606] Finished trial#3 resulted in value: 0.8793588107634605. Current best value is 0.7788285276914089 with parameters: {'bagging_fraction': 0.8303849484265573, 'bagging_freq': 1}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  40%|########8             | 4/10 [00:03<00:04,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.708592\tvalid's rmse: 0.923696\n",
      "[200]\ttrain's rmse: 0.518527\tvalid's rmse: 0.849458\n",
      "[300]\ttrain's rmse: 0.414002\tvalid's rmse: 0.830107\n",
      "[400]\ttrain's rmse: 0.341224\tvalid's rmse: 0.813209\n",
      "[500]\ttrain's rmse: 0.285909\tvalid's rmse: 0.808737\n",
      "[600]\ttrain's rmse: 0.24009\tvalid's rmse: 0.809182\n",
      "[700]\ttrain's rmse: 0.207895\tvalid's rmse: 0.804586\n",
      "[800]\ttrain's rmse: 0.178981\tvalid's rmse: 0.806206\n",
      "Early stopping, best iteration is:\n",
      "[738]\ttrain's rmse: 0.196258\tvalid's rmse: 0.802363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  50%|###########           | 5/10 [00:03<00:03,  1.30it/s][I 2020-03-18 13:03:09,547] Finished trial#4 resulted in value: 0.8023631553724085. Current best value is 0.7788285276914089 with parameters: {'bagging_fraction': 0.8303849484265573, 'bagging_freq': 1}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  50%|###########           | 5/10 [00:03<00:03,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.675009\tvalid's rmse: 0.878973\n",
      "[200]\ttrain's rmse: 0.488191\tvalid's rmse: 0.828445\n",
      "[300]\ttrain's rmse: 0.37989\tvalid's rmse: 0.796098\n",
      "[400]\ttrain's rmse: 0.30324\tvalid's rmse: 0.783892\n",
      "[500]\ttrain's rmse: 0.249499\tvalid's rmse: 0.778186\n",
      "[600]\ttrain's rmse: 0.207181\tvalid's rmse: 0.778582\n",
      "[700]\ttrain's rmse: 0.174614\tvalid's rmse: 0.774768\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttrain's rmse: 0.175692\tvalid's rmse: 0.774515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  60%|#############2        | 6/10 [00:04<00:03,  1.19it/s][I 2020-03-18 13:03:10,554] Finished trial#5 resulted in value: 0.7745152081062727. Current best value is 0.7745152081062727 with parameters: {'bagging_fraction': 0.8403146609351392, 'bagging_freq': 5}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  60%|#############2        | 6/10 [00:04<00:03,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.30609\tvalid's rmse: 1.30871\n",
      "[200]\ttrain's rmse: 1.09368\tvalid's rmse: 1.20969\n",
      "[300]\ttrain's rmse: 0.962741\tvalid's rmse: 1.15056\n",
      "[400]\ttrain's rmse: 0.878173\tvalid's rmse: 1.13209\n",
      "[500]\ttrain's rmse: 0.79688\tvalid's rmse: 1.13036\n",
      "Early stopping, best iteration is:\n",
      "[413]\ttrain's rmse: 0.869658\tvalid's rmse: 1.12214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  70%|###############4      | 7/10 [00:05<00:02,  1.35it/s][I 2020-03-18 13:03:11,061] Finished trial#6 resulted in value: 1.1221361262560283. Current best value is 0.7745152081062727 with parameters: {'bagging_fraction': 0.8403146609351392, 'bagging_freq': 5}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  70%|###############4      | 7/10 [00:05<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.879299\tvalid's rmse: 0.985092\n",
      "[200]\ttrain's rmse: 0.641992\tvalid's rmse: 0.874995\n",
      "[300]\ttrain's rmse: 0.529563\tvalid's rmse: 0.846695\n",
      "[400]\ttrain's rmse: 0.458248\tvalid's rmse: 0.830817\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttrain's rmse: 0.466777\tvalid's rmse: 0.826843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  80%|#################6    | 8/10 [00:05<00:01,  1.44it/s][I 2020-03-18 13:03:11,633] Finished trial#7 resulted in value: 0.8268433515829214. Current best value is 0.7745152081062727 with parameters: {'bagging_fraction': 0.8403146609351392, 'bagging_freq': 5}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  80%|#################6    | 8/10 [00:06<00:01,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.890118\tvalid's rmse: 0.99683\n",
      "[200]\ttrain's rmse: 0.657442\tvalid's rmse: 0.879958\n",
      "[300]\ttrain's rmse: 0.53566\tvalid's rmse: 0.852638\n",
      "[400]\ttrain's rmse: 0.465007\tvalid's rmse: 0.836655\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttrain's rmse: 0.47234\tvalid's rmse: 0.828064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  90%|###################8  | 9/10 [00:06<00:00,  1.52it/s][I 2020-03-18 13:03:12,211] Finished trial#8 resulted in value: 0.8280641736561583. Current best value is 0.7745152081062727 with parameters: {'bagging_fraction': 0.8403146609351392, 'bagging_freq': 5}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381:  90%|###################8  | 9/10 [00:06<00:00,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.713457\tvalid's rmse: 0.922264\n",
      "[200]\ttrain's rmse: 0.52671\tvalid's rmse: 0.852819\n",
      "[300]\ttrain's rmse: 0.426147\tvalid's rmse: 0.825551\n",
      "[400]\ttrain's rmse: 0.358199\tvalid's rmse: 0.820955\n",
      "[500]\ttrain's rmse: 0.304414\tvalid's rmse: 0.812911\n",
      "[600]\ttrain's rmse: 0.262944\tvalid's rmse: 0.8106\n",
      "Early stopping, best iteration is:\n",
      "[507]\ttrain's rmse: 0.300822\tvalid's rmse: 0.807545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381: 100%|#####################| 10/10 [00:07<00:00,  1.48it/s][I 2020-03-18 13:03:12,930] Finished trial#9 resulted in value: 0.8075449954928322. Current best value is 0.7745152081062727 with parameters: {'bagging_fraction': 0.8403146609351392, 'bagging_freq': 5}.\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 0.763381: 100%|#####################| 10/10 [00:07<00:00,  1.37it/s]\n",
      "tune_feature_fraction, val_score: 0.763381:   0%|                                                | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.630275\tvalid's rmse: 0.854866\n",
      "[200]\ttrain's rmse: 0.429936\tvalid's rmse: 0.798202\n",
      "[300]\ttrain's rmse: 0.323333\tvalid's rmse: 0.777433\n",
      "[400]\ttrain's rmse: 0.252404\tvalid's rmse: 0.77582\n",
      "[500]\ttrain's rmse: 0.200848\tvalid's rmse: 0.774007\n",
      "Early stopping, best iteration is:\n",
      "[490]\ttrain's rmse: 0.205034\tvalid's rmse: 0.7729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.763381:  17%|######6                                 | 1/6 [00:00<00:02,  1.68it/s][I 2020-03-18 13:03:13,657] Finished trial#0 resulted in value: 0.772899946765218. Current best value is 0.772899946765218 with parameters: {'feature_fraction': 0.82}.\n",
      "tune_feature_fraction, val_score: 0.763381:  17%|######6                                 | 1/6 [00:00<00:02,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.763381:  33%|#############3                          | 2/6 [00:01<00:02,  1.64it/s][I 2020-03-18 13:03:14,280] Finished trial#1 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'feature_fraction': 0.852}.\n",
      "tune_feature_fraction, val_score: 0.763381:  33%|#############3                          | 2/6 [00:01<00:02,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.622742\tvalid's rmse: 0.852623\n",
      "[200]\ttrain's rmse: 0.418567\tvalid's rmse: 0.794514\n",
      "[300]\ttrain's rmse: 0.314443\tvalid's rmse: 0.773602\n",
      "[400]\ttrain's rmse: 0.242575\tvalid's rmse: 0.764055\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttrain's rmse: 0.244022\tvalid's rmse: 0.763381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.763381:  50%|####################                    | 3/6 [00:01<00:01,  1.62it/s][I 2020-03-18 13:03:14,930] Finished trial#2 resulted in value: 0.7633813850234336. Current best value is 0.7633813850234336 with parameters: {'feature_fraction': 0.852}.\n",
      "tune_feature_fraction, val_score: 0.763381:  50%|####################                    | 3/6 [00:01<00:01,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.587526\tvalid's rmse: 0.833595\n",
      "[200]\ttrain's rmse: 0.393671\tvalid's rmse: 0.779861\n",
      "[300]\ttrain's rmse: 0.29286\tvalid's rmse: 0.770219\n",
      "[400]\ttrain's rmse: 0.229612\tvalid's rmse: 0.762937\n",
      "[500]\ttrain's rmse: 0.183869\tvalid's rmse: 0.763722\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttrain's rmse: 0.20707\tvalid's rmse: 0.761955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.761955:  67%|##########################6             | 4/6 [00:02<00:01,  1.61it/s][I 2020-03-18 13:03:15,560] Finished trial#3 resulted in value: 0.7619546424925553. Current best value is 0.7619546424925553 with parameters: {'feature_fraction': 0.9159999999999999}.\n",
      "tune_feature_fraction, val_score: 0.761955:  67%|##########################6             | 4/6 [00:02<00:01,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.587526\tvalid's rmse: 0.833595\n",
      "[200]\ttrain's rmse: 0.393671\tvalid's rmse: 0.779861\n",
      "[300]\ttrain's rmse: 0.29286\tvalid's rmse: 0.770219\n",
      "[400]\ttrain's rmse: 0.229612\tvalid's rmse: 0.762937\n",
      "[500]\ttrain's rmse: 0.183869\tvalid's rmse: 0.763722\n",
      "Early stopping, best iteration is:\n",
      "[444]\ttrain's rmse: 0.20707\tvalid's rmse: 0.761955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.761955:  83%|#################################3      | 5/6 [00:03<00:00,  1.56it/s][I 2020-03-18 13:03:16,252] Finished trial#4 resulted in value: 0.7619546424925553. Current best value is 0.7619546424925553 with parameters: {'feature_fraction': 0.9159999999999999}.\n",
      "tune_feature_fraction, val_score: 0.761955:  83%|#################################3      | 5/6 [00:03<00:00,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.610142\tvalid's rmse: 0.836163\n",
      "[200]\ttrain's rmse: 0.400599\tvalid's rmse: 0.773164\n",
      "[300]\ttrain's rmse: 0.293563\tvalid's rmse: 0.767358\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttrain's rmse: 0.331531\tvalid's rmse: 0.76385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.761955: 100%|########################################| 6/6 [00:03<00:00,  1.64it/s][I 2020-03-18 13:03:16,781] Finished trial#5 resulted in value: 0.7638503538258471. Current best value is 0.7619546424925553 with parameters: {'feature_fraction': 0.9159999999999999}.\n",
      "tune_feature_fraction, val_score: 0.761955: 100%|########################################| 6/6 [00:03<00:00,  1.56it/s]\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.761955:   0%|                                        | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.602989\tvalid's rmse: 0.831706\n",
      "[200]\ttrain's rmse: 0.39744\tvalid's rmse: 0.787701\n",
      "[300]\ttrain's rmse: 0.297307\tvalid's rmse: 0.771261\n",
      "[400]\ttrain's rmse: 0.231887\tvalid's rmse: 0.762535\n",
      "[500]\ttrain's rmse: 0.185208\tvalid's rmse: 0.76105\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttrain's rmse: 0.218112\tvalid's rmse: 0.760386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.760386:   5%|#6                              | 1/20 [00:00<00:10,  1.89it/s][I 2020-03-18 13:03:17,452] Finished trial#0 resulted in value: 0.7603856416084017. Current best value is 0.7603856416084017 with parameters: {'lambda_l1': 1.1505300412454787e-06, 'lambda_l2': 0.0002715529204049868}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.760386:   5%|#6                              | 1/20 [00:00<00:10,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.596889\tvalid's rmse: 0.84464\n",
      "[200]\ttrain's rmse: 0.397566\tvalid's rmse: 0.793028\n",
      "[300]\ttrain's rmse: 0.294859\tvalid's rmse: 0.776913\n",
      "[400]\ttrain's rmse: 0.229114\tvalid's rmse: 0.77023\n",
      "[500]\ttrain's rmse: 0.182723\tvalid's rmse: 0.767943\n",
      "[600]\ttrain's rmse: 0.149341\tvalid's rmse: 0.772763\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttrain's rmse: 0.182249\tvalid's rmse: 0.767739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.760386:  10%|###2                            | 2/20 [00:01<00:10,  1.64it/s][I 2020-03-18 13:03:18,227] Finished trial#1 resulted in value: 0.7677394026996059. Current best value is 0.7603856416084017 with parameters: {'lambda_l1': 1.1505300412454787e-06, 'lambda_l2': 0.0002715529204049868}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.760386:  10%|###2                            | 2/20 [00:01<00:10,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.600862\tvalid's rmse: 0.837042\n",
      "[200]\ttrain's rmse: 0.40598\tvalid's rmse: 0.78372\n",
      "[300]\ttrain's rmse: 0.296943\tvalid's rmse: 0.765395\n",
      "[400]\ttrain's rmse: 0.227874\tvalid's rmse: 0.75673\n",
      "[500]\ttrain's rmse: 0.18013\tvalid's rmse: 0.751785\n",
      "[600]\ttrain's rmse: 0.14608\tvalid's rmse: 0.754787\n",
      "Early stopping, best iteration is:\n",
      "[502]\ttrain's rmse: 0.179316\tvalid's rmse: 0.751564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.751564:  15%|####8                           | 3/20 [00:02<00:10,  1.55it/s][I 2020-03-18 13:03:18,953] Finished trial#2 resulted in value: 0.7515637425230617. Current best value is 0.7515637425230617 with parameters: {'lambda_l1': 1.5872507444779662e-08, 'lambda_l2': 0.005528705146888955}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.751564:  15%|####8                           | 3/20 [00:02<00:10,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.606149\tvalid's rmse: 0.831663\n",
      "[200]\ttrain's rmse: 0.400845\tvalid's rmse: 0.770189\n",
      "[300]\ttrain's rmse: 0.303324\tvalid's rmse: 0.748414\n",
      "[400]\ttrain's rmse: 0.237737\tvalid's rmse: 0.743877\n",
      "Early stopping, best iteration is:\n",
      "[392]\ttrain's rmse: 0.242244\tvalid's rmse: 0.742811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  20%|######4                         | 4/20 [00:02<00:09,  1.60it/s][I 2020-03-18 13:03:19,544] Finished trial#3 resulted in value: 0.7428112480377671. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  20%|######4                         | 4/20 [00:02<00:09,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.606877\tvalid's rmse: 0.839453\n",
      "[200]\ttrain's rmse: 0.410283\tvalid's rmse: 0.787396\n",
      "[300]\ttrain's rmse: 0.312477\tvalid's rmse: 0.774573\n",
      "[400]\ttrain's rmse: 0.251116\tvalid's rmse: 0.771699\n",
      "[500]\ttrain's rmse: 0.20527\tvalid's rmse: 0.771502\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttrain's rmse: 0.23749\tvalid's rmse: 0.77012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  25%|########                        | 5/20 [00:03<00:09,  1.60it/s][I 2020-03-18 13:03:20,174] Finished trial#4 resulted in value: 0.7701204524916602. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  25%|########                        | 5/20 [00:03<00:09,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.590168\tvalid's rmse: 0.83528\n",
      "[200]\ttrain's rmse: 0.386582\tvalid's rmse: 0.781803\n",
      "[300]\ttrain's rmse: 0.285526\tvalid's rmse: 0.768904\n",
      "[400]\ttrain's rmse: 0.222166\tvalid's rmse: 0.765159\n",
      "[500]\ttrain's rmse: 0.176601\tvalid's rmse: 0.76341\n",
      "[600]\ttrain's rmse: 0.140439\tvalid's rmse: 0.762321\n",
      "Early stopping, best iteration is:\n",
      "[543]\ttrain's rmse: 0.159524\tvalid's rmse: 0.761352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  30%|#########6                      | 6/20 [00:04<00:09,  1.48it/s][I 2020-03-18 13:03:20,965] Finished trial#5 resulted in value: 0.7613522042872454. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  30%|#########6                      | 6/20 [00:04<00:09,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.624964\tvalid's rmse: 0.842736\n",
      "[200]\ttrain's rmse: 0.421523\tvalid's rmse: 0.777415\n",
      "[300]\ttrain's rmse: 0.315102\tvalid's rmse: 0.753577\n",
      "[400]\ttrain's rmse: 0.244575\tvalid's rmse: 0.750899\n",
      "[500]\ttrain's rmse: 0.196383\tvalid's rmse: 0.746668\n",
      "Early stopping, best iteration is:\n",
      "[473]\ttrain's rmse: 0.207649\tvalid's rmse: 0.745355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  35%|###########2                    | 7/20 [00:04<00:08,  1.48it/s][I 2020-03-18 13:03:21,631] Finished trial#6 resulted in value: 0.7453547326946461. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  35%|###########2                    | 7/20 [00:04<00:08,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.953044\tvalid's rmse: 1.04578\n",
      "[200]\ttrain's rmse: 0.949241\tvalid's rmse: 1.04171\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttrain's rmse: 0.949656\tvalid's rmse: 1.04161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  40%|############8                   | 8/20 [00:04<00:06,  1.81it/s][I 2020-03-18 13:03:21,892] Finished trial#7 resulted in value: 1.0416117286938174. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  40%|############8                   | 8/20 [00:05<00:06,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.5883\tvalid's rmse: 0.832659\n",
      "[200]\ttrain's rmse: 0.387926\tvalid's rmse: 0.789372\n",
      "[300]\ttrain's rmse: 0.287224\tvalid's rmse: 0.775267\n",
      "[400]\ttrain's rmse: 0.221415\tvalid's rmse: 0.770279\n",
      "[500]\ttrain's rmse: 0.177199\tvalid's rmse: 0.768941\n",
      "[600]\ttrain's rmse: 0.143928\tvalid's rmse: 0.770504\n",
      "Early stopping, best iteration is:\n",
      "[565]\ttrain's rmse: 0.154283\tvalid's rmse: 0.768242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  45%|##############4                 | 9/20 [00:05<00:06,  1.60it/s][I 2020-03-18 13:03:22,701] Finished trial#8 resulted in value: 0.7682423962277642. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  45%|##############4                 | 9/20 [00:05<00:06,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.595349\tvalid's rmse: 0.839646\n",
      "[200]\ttrain's rmse: 0.391846\tvalid's rmse: 0.785513\n",
      "[300]\ttrain's rmse: 0.287428\tvalid's rmse: 0.764576\n",
      "[400]\ttrain's rmse: 0.223804\tvalid's rmse: 0.761891\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttrain's rmse: 0.242316\tvalid's rmse: 0.760268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  50%|###############5               | 10/20 [00:06<00:06,  1.60it/s][I 2020-03-18 13:03:23,324] Finished trial#9 resulted in value: 0.7602676816634779. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  50%|###############5               | 10/20 [00:06<00:06,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.594569\tvalid's rmse: 0.834265\n",
      "[200]\ttrain's rmse: 0.396409\tvalid's rmse: 0.786824\n",
      "[300]\ttrain's rmse: 0.293737\tvalid's rmse: 0.769198\n",
      "[400]\ttrain's rmse: 0.226242\tvalid's rmse: 0.761975\n",
      "[500]\ttrain's rmse: 0.180167\tvalid's rmse: 0.762721\n",
      "Early stopping, best iteration is:\n",
      "[478]\ttrain's rmse: 0.189447\tvalid's rmse: 0.759983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  55%|#################              | 11/20 [00:07<00:05,  1.53it/s][I 2020-03-18 13:03:24,042] Finished trial#10 resulted in value: 0.7599833308874472. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  55%|#################              | 11/20 [00:07<00:05,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.669249\tvalid's rmse: 0.871192\n",
      "[200]\ttrain's rmse: 0.466481\tvalid's rmse: 0.811125\n",
      "[300]\ttrain's rmse: 0.355332\tvalid's rmse: 0.788735\n",
      "[400]\ttrain's rmse: 0.283646\tvalid's rmse: 0.781829\n",
      "[500]\ttrain's rmse: 0.231385\tvalid's rmse: 0.780353\n",
      "[600]\ttrain's rmse: 0.189613\tvalid's rmse: 0.778952\n",
      "[700]\ttrain's rmse: 0.158224\tvalid's rmse: 0.779153\n",
      "Early stopping, best iteration is:\n",
      "[652]\ttrain's rmse: 0.172249\tvalid's rmse: 0.777388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  60%|##################5            | 12/20 [00:08<00:05,  1.38it/s][I 2020-03-18 13:03:24,937] Finished trial#11 resulted in value: 0.7773884291169659. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  60%|##################5            | 12/20 [00:08<00:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.669106\tvalid's rmse: 0.868621\n",
      "[200]\ttrain's rmse: 0.458525\tvalid's rmse: 0.800622\n",
      "[300]\ttrain's rmse: 0.345768\tvalid's rmse: 0.772934\n",
      "[400]\ttrain's rmse: 0.271896\tvalid's rmse: 0.764363\n",
      "[500]\ttrain's rmse: 0.220053\tvalid's rmse: 0.759385\n",
      "Early stopping, best iteration is:\n",
      "[476]\ttrain's rmse: 0.231048\tvalid's rmse: 0.757754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  65%|####################1          | 13/20 [00:08<00:05,  1.38it/s][I 2020-03-18 13:03:25,662] Finished trial#12 resulted in value: 0.7577539369239867. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  65%|####################1          | 13/20 [00:08<00:05,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.647201\tvalid's rmse: 0.867677\n",
      "[200]\ttrain's rmse: 0.461661\tvalid's rmse: 0.811828\n",
      "[300]\ttrain's rmse: 0.378229\tvalid's rmse: 0.797213\n",
      "[400]\ttrain's rmse: 0.323654\tvalid's rmse: 0.792292\n",
      "Early stopping, best iteration is:\n",
      "[384]\ttrain's rmse: 0.330501\tvalid's rmse: 0.791079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  70%|#####################7         | 14/20 [00:09<00:04,  1.44it/s][I 2020-03-18 13:03:26,262] Finished trial#13 resulted in value: 0.7910789092760615. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  70%|#####################7         | 14/20 [00:09<00:04,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.596394\tvalid's rmse: 0.832561\n",
      "[200]\ttrain's rmse: 0.393167\tvalid's rmse: 0.783288\n",
      "[300]\ttrain's rmse: 0.292616\tvalid's rmse: 0.762739\n",
      "[400]\ttrain's rmse: 0.225698\tvalid's rmse: 0.760937\n",
      "[500]\ttrain's rmse: 0.178672\tvalid's rmse: 0.757577\n",
      "Early stopping, best iteration is:\n",
      "[488]\ttrain's rmse: 0.183674\tvalid's rmse: 0.756925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  75%|#######################2       | 15/20 [00:10<00:03,  1.45it/s][I 2020-03-18 13:03:26,952] Finished trial#14 resulted in value: 0.756925477198871. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  75%|#######################2       | 15/20 [00:10<00:03,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.590383\tvalid's rmse: 0.846964\n",
      "[200]\ttrain's rmse: 0.398098\tvalid's rmse: 0.799523\n",
      "[300]\ttrain's rmse: 0.292184\tvalid's rmse: 0.781581\n",
      "[400]\ttrain's rmse: 0.225757\tvalid's rmse: 0.775276\n",
      "[500]\ttrain's rmse: 0.180131\tvalid's rmse: 0.775251\n",
      "Early stopping, best iteration is:\n",
      "[458]\ttrain's rmse: 0.197525\tvalid's rmse: 0.773509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  80%|########################8      | 16/20 [00:10<00:02,  1.43it/s][I 2020-03-18 13:03:27,685] Finished trial#15 resulted in value: 0.7735088336135932. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  80%|########################8      | 16/20 [00:10<00:02,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.603349\tvalid's rmse: 0.841966\n",
      "[200]\ttrain's rmse: 0.396326\tvalid's rmse: 0.795587\n",
      "[300]\ttrain's rmse: 0.29329\tvalid's rmse: 0.776198\n",
      "[400]\ttrain's rmse: 0.230744\tvalid's rmse: 0.771782\n",
      "[500]\ttrain's rmse: 0.183791\tvalid's rmse: 0.770799\n",
      "Early stopping, best iteration is:\n",
      "[478]\ttrain's rmse: 0.192921\tvalid's rmse: 0.770398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  85%|##########################3    | 17/20 [00:11<00:02,  1.42it/s][I 2020-03-18 13:03:28,419] Finished trial#16 resulted in value: 0.7703976046515326. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  85%|##########################3    | 17/20 [00:11<00:02,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.610099\tvalid's rmse: 0.84518\n",
      "[200]\ttrain's rmse: 0.413936\tvalid's rmse: 0.785518\n",
      "[300]\ttrain's rmse: 0.316243\tvalid's rmse: 0.770822\n",
      "[400]\ttrain's rmse: 0.254766\tvalid's rmse: 0.768082\n",
      "[500]\ttrain's rmse: 0.213087\tvalid's rmse: 0.766834\n",
      "[600]\ttrain's rmse: 0.182609\tvalid's rmse: 0.767546\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttrain's rmse: 0.196234\tvalid's rmse: 0.765781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  90%|###########################9   | 18/20 [00:12<00:01,  1.38it/s][I 2020-03-18 13:03:29,178] Finished trial#17 resulted in value: 0.7657805219102153. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  90%|###########################9   | 18/20 [00:12<00:01,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.596889\tvalid's rmse: 0.84464\n",
      "[200]\ttrain's rmse: 0.392491\tvalid's rmse: 0.791082\n",
      "[300]\ttrain's rmse: 0.294749\tvalid's rmse: 0.768527\n",
      "[400]\ttrain's rmse: 0.22798\tvalid's rmse: 0.761211\n",
      "Early stopping, best iteration is:\n",
      "[379]\ttrain's rmse: 0.241135\tvalid's rmse: 0.759809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  95%|#############################4 | 19/20 [00:12<00:00,  1.45it/s][I 2020-03-18 13:03:29,790] Finished trial#18 resulted in value: 0.7598094456377075. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811:  95%|#############################4 | 19/20 [00:13<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.606319\tvalid's rmse: 0.83768\n",
      "[200]\ttrain's rmse: 0.404847\tvalid's rmse: 0.779272\n",
      "[300]\ttrain's rmse: 0.301894\tvalid's rmse: 0.763409\n",
      "[400]\ttrain's rmse: 0.237651\tvalid's rmse: 0.760209\n",
      "[500]\ttrain's rmse: 0.191321\tvalid's rmse: 0.757105\n",
      "[600]\ttrain's rmse: 0.156643\tvalid's rmse: 0.758221\n",
      "Early stopping, best iteration is:\n",
      "[512]\ttrain's rmse: 0.186313\tvalid's rmse: 0.756439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811: 100%|###############################| 20/20 [00:13<00:00,  1.40it/s][I 2020-03-18 13:03:30,563] Finished trial#19 resulted in value: 0.7564389129522415. Current best value is 0.7428112480377671 with parameters: {'lambda_l1': 0.04014538631290826, 'lambda_l2': 2.912312881036379e-06}.\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 0.742811: 100%|###############################| 20/20 [00:13<00:00,  1.45it/s]\n",
      "tune_min_child_samples, val_score: 0.742811:   0%|                                               | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.146297\tvalid's rmse: 0.722384\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttrain's rmse: 0.237961\tvalid's rmse: 0.714999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 0.714999:  20%|#######8                               | 1/5 [00:00<00:00,  6.04it/s][I 2020-03-18 13:03:30,846] Finished trial#0 resulted in value: 0.7149990483803649. Current best value is 0.7149990483803649 with parameters: {'min_child_samples': 5}.\n",
      "tune_min_child_samples, val_score: 0.714999:  20%|#######8                               | 1/5 [00:00<00:00,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.296748\tvalid's rmse: 0.707478\n",
      "[200]\ttrain's rmse: 0.170728\tvalid's rmse: 0.709086\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttrain's rmse: 0.263646\tvalid's rmse: 0.70492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 0.704920:  40%|###############6                       | 2/5 [00:00<00:00,  4.58it/s][I 2020-03-18 13:03:31,203] Finished trial#1 resulted in value: 0.7049200875534505. Current best value is 0.7049200875534505 with parameters: {'min_child_samples': 10}.\n",
      "tune_min_child_samples, val_score: 0.704920:  40%|###############6                       | 2/5 [00:00<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.708182\tvalid's rmse: 0.887013\n",
      "[200]\ttrain's rmse: 0.519908\tvalid's rmse: 0.818309\n",
      "[300]\ttrain's rmse: 0.403921\tvalid's rmse: 0.78764\n",
      "[400]\ttrain's rmse: 0.331515\tvalid's rmse: 0.781471\n",
      "[500]\ttrain's rmse: 0.278157\tvalid's rmse: 0.778868\n",
      "[600]\ttrain's rmse: 0.239897\tvalid's rmse: 0.781333\n",
      "Early stopping, best iteration is:\n",
      "[531]\ttrain's rmse: 0.264369\tvalid's rmse: 0.777804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 0.704920:  60%|#######################4               | 3/5 [00:01<00:00,  2.54it/s][I 2020-03-18 13:03:32,034] Finished trial#2 resulted in value: 0.7778039897885928. Current best value is 0.7049200875534505 with parameters: {'min_child_samples': 10}.\n",
      "tune_min_child_samples, val_score: 0.704920:  60%|#######################4               | 3/5 [00:01<00:00,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.19136\tvalid's rmse: 1.19296\n",
      "[200]\ttrain's rmse: 1.02729\tvalid's rmse: 1.12193\n",
      "[300]\ttrain's rmse: 0.934858\tvalid's rmse: 1.09723\n",
      "[400]\ttrain's rmse: 0.870333\tvalid's rmse: 1.0817\n",
      "Early stopping, best iteration is:\n",
      "[387]\ttrain's rmse: 0.878032\tvalid's rmse: 1.0812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 0.704920:  80%|###############################2       | 4/5 [00:01<00:00,  2.19it/s][I 2020-03-18 13:03:32,605] Finished trial#3 resulted in value: 1.0812046841186416. Current best value is 0.7049200875534505 with parameters: {'min_child_samples': 10}.\n",
      "tune_min_child_samples, val_score: 0.704920:  80%|###############################2       | 4/5 [00:02<00:00,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.88576\tvalid's rmse: 1.88119\n",
      "[200]\ttrain's rmse: 1.8275\tvalid's rmse: 1.87301\n",
      "[300]\ttrain's rmse: 1.78547\tvalid's rmse: 1.87251\n",
      "Early stopping, best iteration is:\n",
      "[221]\ttrain's rmse: 1.81701\tvalid's rmse: 1.86506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 0.704920: 100%|#######################################| 5/5 [00:02<00:00,  2.37it/s][I 2020-03-18 13:03:32,948] Finished trial#4 resulted in value: 1.8650629111849417. Current best value is 0.7049200875534505 with parameters: {'min_child_samples': 10}.\n",
      "tune_min_child_samples, val_score: 0.704920: 100%|#######################################| 5/5 [00:02<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.26323\tvalid's rmse: 0.777389\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttrain's rmse: 0.418121\tvalid's rmse: 0.762902\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.316465\tvalid's rmse: 0.629983\n",
      "[200]\ttrain's rmse: 0.178699\tvalid's rmse: 0.623664\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttrain's rmse: 0.284551\tvalid's rmse: 0.621304\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.306364\tvalid's rmse: 0.760874\n",
      "[200]\ttrain's rmse: 0.178189\tvalid's rmse: 0.74062\n",
      "[300]\ttrain's rmse: 0.118347\tvalid's rmse: 0.738241\n",
      "Early stopping, best iteration is:\n",
      "[285]\ttrain's rmse: 0.124702\tvalid's rmse: 0.737039\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.268337\tvalid's rmse: 0.893566\n",
      "[200]\ttrain's rmse: 0.152101\tvalid's rmse: 0.897839\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttrain's rmse: 0.245467\tvalid's rmse: 0.891095\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.297376\tvalid's rmse: 0.886947\n",
      "[200]\ttrain's rmse: 0.167003\tvalid's rmse: 0.882035\n",
      "[300]\ttrain's rmse: 0.102752\tvalid's rmse: 0.878963\n",
      "[400]\ttrain's rmse: 0.0655032\tvalid's rmse: 0.874534\n",
      "[500]\ttrain's rmse: 0.0463567\tvalid's rmse: 0.87297\n",
      "[600]\ttrain's rmse: 0.0354044\tvalid's rmse: 0.87125\n",
      "[700]\ttrain's rmse: 0.028126\tvalid's rmse: 0.870954\n",
      "[800]\ttrain's rmse: 0.0239603\tvalid's rmse: 0.870743\n",
      "[900]\ttrain's rmse: 0.0211264\tvalid's rmse: 0.870579\n",
      "[1000]\ttrain's rmse: 0.0192832\tvalid's rmse: 0.870447\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.0192832\tvalid's rmse: 0.870447\n",
      "CV : 0.776557\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml.run(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.engine.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pd.read_csv(\"../input/vortex/vortex_actual_05.csv\")\n",
    "actual[\"pred\"] = ml.predicts\n",
    "actual.to_csv(\"actual_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"selected.pkl\", \"rb\") as f:\n",
    "    hoge = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train[[\"Age\", \"Fare\"]])\n",
    "\n",
    "train[[\"Age\", \"Fare\"]] = scaler.transform(train[[\"Age\", \"Fare\"]])\n",
    "train[\"Age\"].fillna(-9999, inplace=True)\n",
    "train[\"Fare\"].fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "um = umap.UMAP()\n",
    "um.fit(train[[\"Age\", \"Fare\"]])\n",
    "\n",
    "d = um.transform(train[[\"Age\", \"Fare\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Age\", \"Fare\"]] = train[[\"Age\", \"Fare\"]].replace(np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ml.engine.train, ml.engine.test], ignore_index=True)\n",
    "skip_columns = [\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in df.columns if f not in skip_columns]\n",
    "num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS and df[col].unique().shape[0] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_columns:\n",
    "    df[col] = df[col].replace(np.inf, np.nan)\n",
    "    df[col].fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = umap.UMAP()\n",
    "um.fit(df[num_columns])\n",
    "df[num_columns] = um.transform(df[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um.transform(df[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./\"\n",
    "base_score = 0.7681353456669913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "selected = set([])\n",
    "params = None\n",
    "scenario = None\n",
    "with open(f\"{base_path}/param_{base_score}.json\") as f:\n",
    "    params = json.load(f)\n",
    "with open(f\"{base_path}/scenario_{base_score}.yml\", \"r\") as yml:\n",
    "    scenario = yaml.safe_load(yml)\n",
    "\n",
    "train = pd.read_pickle(f\"{base_path}/train_{base_score}.pkl\")\n",
    "test = pd.read_pickle(f\"{base_path}/test_{base_score}.pkl\")\n",
    "\n",
    "train_x = [f for f in train.columns if f not in [\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for col in train_x:\n",
    "    if col not in selected:\n",
    "        feats = list(selected) + [col]\n",
    "        param_with_score = 1\n",
    "        scores.append((col, param_with_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_feature, b_score = sorted(scores, key=lambda tpl: tpl[1])[0]\n",
    "if b_score > best_score:\n",
    "    selected.add(b_feature)\n",
    "    best_score = b_score\n",
    "    print(f'selected:{b_feature}')\n",
    "    print(f'score:{b_score}')\n",
    "else:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
