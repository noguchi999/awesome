{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime, time, re, warnings, gc, json, random, yaml, umap\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score\n",
    "from sklearn import datasets, manifold, mixture, model_selection\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz, hstack\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as tuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    print(f'[{title}] start')\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(metaclass=ABCMeta):\n",
    "    BASE_DIR = \".\"\n",
    "    NUMERICS = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = self.__class__.__name__\n",
    "        self.train = pd.DataFrame()\n",
    "        self.test = pd.DataFrame()\n",
    "        self.train_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_train\"\n",
    "        self.test_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_test\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_features(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def run(self, use_columns=[], skip_columns=[]):\n",
    "        with timer(self.name):\n",
    "            self.load_data()\n",
    "            self.replace_na(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.onehot_encode(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.create_features()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def onehot_encode(self, use_columns=[], skip_columns=[], sparse=False):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        self.label_encode(use_columns, skip_columns)\n",
    "        if sparse:\n",
    "            encoder = OneHotEncoder(categories='auto', sparse=sparse, dtype='uint8').fit(pd.concat([self.train.loc[:, use_columns], self.test.loc[:, use_columns]]))\n",
    "            m = 100000\n",
    "            train = vstack([encoder.transform(self.train[i*m:(i+1)*m].loc[:, use_columns]) for i in range(self.train.shape[0] // m + 1)])\n",
    "            test  = vstack([encoder.transform(self.test[i*m:(i+1)*m].loc[:, use_columns])  for i in range(self.test.shape[0] // m +  1)])\n",
    "            save_npz(f\"{self.train_file_path}.npz\", train, compressed=True)\n",
    "            save_npz(f\"{self.test_file_path}.npz\",  test,  compressed=True)\n",
    "        else:\n",
    "            self.train[\"is_train_date\"] = 1\n",
    "            self.test[\"is_train_date\"]  = 0\n",
    "            df = pd.concat([self.train, self.test])\n",
    "            del self.train, self.test\n",
    "            gc.collect()\n",
    "            for col in use_columns:\n",
    "                df = df.join(pd.get_dummies(df[col], prefix=col))\n",
    "            \n",
    "            self.train = df[df[\"is_train_date\"]==1]\n",
    "            self.test = df[df[\"is_train_date\"]==0]\n",
    "            self.train.drop(columns=\"is_train_date\", inplace=True)\n",
    "            self.test.drop(columns=\"is_train_date\", inplace=True)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def label_encode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        \n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "        \n",
    "        for col in use_columns:\n",
    "            if df[col].dtype.name in [\"object\", \"category\"]:\n",
    "                df[col] = df[col].astype(str)\n",
    "                le = LabelEncoder().fit(df[col])\n",
    "                df[col] = le.transform(df[col])+1\n",
    "    \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def target_encode(self, col_name, target_name, min_samples_leaf=1, smoothing=1, noise_level=0):\n",
    "        trn_series = self.train[col_name]\n",
    "        tst_series = self.test[col_name]\n",
    "        target = self.train[target_name]\n",
    "        \n",
    "        assert len(trn_series) == len(target)\n",
    "\n",
    "        temp = pd.concat([trn_series, target], axis=1)\n",
    "        averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "        smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "        prior = target.mean()\n",
    "        averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "        averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "        ft_trn_series = pd.merge(\n",
    "            trn_series.to_frame(trn_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=trn_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_trn_series.index = trn_series.index \n",
    "        ft_tst_series = pd.merge(\n",
    "            tst_series.to_frame(tst_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=tst_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_tst_series.index = tst_series.index\n",
    "\n",
    "        self.train[f\"te_smoothing_{col_name}\"], self.test[f\"te_smoothing_{col_name}\"] = self.__add_noise(ft_trn_series, noise_level), self.__add_noise(ft_tst_series, noise_level)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "            \n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                df[f\"{prefix}{k}_{v}\"] = df.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    df[f\"{prefix}{k}_{vv}\"] = df.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform_ratio(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "        prefix = f\"ratio_{prefix}\"\n",
    "        \n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                self.train[f\"{prefix}{k}_{v}\"] = self.train[k] / self.train.groupby(group)[k].transform(v)\n",
    "                self.test[f\"{prefix}{k}_{v}\"] = self.test[k] / self.test.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    self.train[f\"{prefix}{k}_{vv}\"] = self.train[k] / self.train.groupby(group)[k].transform(vv)\n",
    "                    self.test[f\"{prefix}{k}_{vv}\"] = self.test[k] / self.test.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def replace_na(self, use_columns=[], skip_columns=[], fill_value=-1):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mode().values[0])\n",
    "            self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mode().values[0])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mean(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mean())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mean())\n",
    "\n",
    "        return self\n",
    "\n",
    "    def replace_na_median(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].median())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].median())\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_topic_score(self, topic_text_columns, num_topics=5):\n",
    "        df = pd.concat([self.train.loc[:, topic_text_columns], self.test.loc[:, topic_text_columns]])\n",
    "        \n",
    "        for col in topic_text_columns:\n",
    "            texts = [[word for word in document.lower().split()] for document in df[col].values]\n",
    "            dictionary = corpora.Dictionary(texts)\n",
    "            bow_corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "            lda = models.LdaModel(bow_corpus, id2word=dictionary, num_topics=num_topics)\n",
    "                        \n",
    "            size = df.shape[0]\n",
    "            topics = {i:[-1]*size for i in range(num_topics)}\n",
    "            for i, row in enumerate(lda[bow_corpus]):\n",
    "                for (topic_num, prop_topic) in row:\n",
    "                    topics[topic_num][i] = prop_topic\n",
    "            \n",
    "            for i in range(num_topics):\n",
    "                self.train[f\"{col}_topic_{i}\"] = topics[i][:self.train.shape[0]]\n",
    "                self.test[f\"{col}_topic_{i}\"] = topics[i][self.train.shape[0]:]\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_scdv_word2vec_score(self, text_col_name):\n",
    "        features_num = 20\n",
    "        min_word_count = 10\n",
    "        context = 5\n",
    "        downsampling = 1e-3\n",
    "        epoch_num = 10\n",
    "        clusters_num = 6\n",
    "        \n",
    "        df = pd.concat([self.train.loc[:, [text_col_name]], self.test.loc[:, [text_col_name]]])\n",
    "        df[text_col_name] = df[text_col_name].fillna(\"\")\n",
    "        \n",
    "        corpus = [self.__analyzer_cat(text) for text in df[text_col_name]]\n",
    "        word2vecs = Word2Vec(sentences=corpus, iter=epoch_num, size=features_num, min_count=min_word_count, window=context, sample=downsampling)\n",
    "        word_vectors = word2vecs.wv.vectors\n",
    "        \n",
    "        gmm = mixture.GaussianMixture(n_components=clusters_num, covariance_type='tied', max_iter=50)\n",
    "        gmm.fit(word_vectors)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer=self.__analyzer_cat, min_df=min_word_count)\n",
    "        tfidfs = tfidf_vectorizer.fit_transform(df[text_col_name])\n",
    "        \n",
    "        idf_dic = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer._tfidf.idf_))\n",
    "        assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict(word_vectors)))\n",
    "        soft_assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict_proba(word_vectors)))\n",
    "        \n",
    "        word_topic_vecs = {}\n",
    "        for word in assign_dic:\n",
    "            word_topic_vecs[word] = np.zeros(features_num*clusters_num, dtype=np.float32)\n",
    "            for i in range(0, clusters_num):\n",
    "                try:\n",
    "                    word_topic_vecs[word][i*features_num:(i+1)*features_num] = word2vecs.wv[word]*soft_assign_dic[word][i]*idf_dic[word]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        scdvs = np.zeros((len(df[text_col_name]), clusters_num*features_num), dtype=np.float32)\n",
    "\n",
    "        a_min = 0\n",
    "        a_max = 0\n",
    "\n",
    "        for i, text in enumerate(df[text_col_name]):\n",
    "            tmp = np.zeros(clusters_num*features_num, dtype=np.float32)\n",
    "            words = self.__analyzer_cat(text)\n",
    "            for word in words:\n",
    "                if word in word_topic_vecs:\n",
    "                    tmp += word_topic_vecs[word]\n",
    "            norm = np.sqrt(np.sum(tmp**2))\n",
    "            if norm > 0:\n",
    "                tmp /= norm\n",
    "            a_min += min(tmp)\n",
    "            a_max += max(tmp)\n",
    "            scdvs[i] = tmp\n",
    "\n",
    "        p = 0.04\n",
    "        a_min = a_min*1.0 / len(df[text_col_name])\n",
    "        a_max = a_max*1.0 / len(df[text_col_name])\n",
    "        thres = (abs(a_min)+abs(a_max)) / 2\n",
    "        thres *= p\n",
    "        scdvs[abs(scdvs) < thres] = 0\n",
    "        \n",
    "        tsne_scdv = manifold.TSNE(n_components=2).fit_transform(scdvs)\n",
    "        \n",
    "        self.train[f\"scdv_{text_col_name}_x\"] = tsne_scdv[:self.train.shape[0], 0]\n",
    "        self.train[f\"scdv_{text_col_name}_y\"] = tsne_scdv[:self.train.shape[0], 1]        \n",
    "        self.test[f\"scdv_{text_col_name}_x\"] = tsne_scdv[self.train.shape[0]:, 0]\n",
    "        self.test[f\"scdv_{text_col_name}_y\"] = tsne_scdv[self.train.shape[0]:, 1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def yeo_johnson(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "        \n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        pt.fit(df[num_columns])\n",
    "\n",
    "        df[num_columns] = pt.transform(df[num_columns])\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def umap_scaler(self, skip_columns=[]):\n",
    "        self.yeo_johnson(skip_columns=skip_columns)\n",
    "        \n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS and df[col].unique().shape[0] > 100]\n",
    "        for col in num_columns:\n",
    "            df[col] = df[col].replace(np.inf, np.nan)\n",
    "            df[col].fillna(-9999, inplace=True)\n",
    "        \n",
    "        um = umap.UMAP()\n",
    "        um.fit(df[num_columns])\n",
    "        d = um.transform(df[num_columns])\n",
    "        df[\"umap_d1\"] = d[:, 0]\n",
    "        df[\"umap_d2\"] = d[:, 1]\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_kmean_features(self, seed, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        for col in num_columns:\n",
    "            df[col].fillna(-9999, inplace=True)\n",
    "        X = df[num_columns]\n",
    "        \n",
    "        kmeans = MiniBatchKMeans(n_clusters=10, random_state=seed)\n",
    "        kmeans.fit(X)\n",
    "\n",
    "        df[\"k_class\"] = kmeans.predict(X)\n",
    "        train_distances = kmeans.transform(X)\n",
    "        for i in range(10):\n",
    "            df[f\"k_distance_{i}\"] = train_distances[:, i]\n",
    "    \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def min_max_scaling(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df[num_columns])\n",
    "        df[num_columns] = scaler.transform(df[num_columns])\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def two_by_two(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        targets = num_columns.copy()\n",
    "        for col in num_columns:\n",
    "            targets.remove(col)\n",
    "            for t in targets:\n",
    "                df[f\"{col}_{t}_mul\"] = df[col] * df[t]\n",
    "                df[f\"{col}_{t}_sub_left\"] = df[col] / df[t]\n",
    "                df[f\"{col}_{t}_sub_right\"] = df[t] / df[col]\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def columns_1d(self):\n",
    "        self.train.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.train.columns.tolist()])\n",
    "        self.test.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.test.columns.tolist()])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def head(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train head: {title}\")\n",
    "        print(self.train.loc[:, train_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test head: {title}\")\n",
    "        print(self.test.loc[:, test_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tail(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train tail: {title}\")\n",
    "        print(self.train.loc[:, train_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test tail: {title}\")\n",
    "        print(self.test.loc[:, test_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def save(self, format=\"feather\", index=False):\n",
    "        if format == \"feather\":\n",
    "            self.train.to_feather(f\"{self.train_file_path}.ftr\")\n",
    "            self.test.to_feather(f\"{self.test_file_path}.ftr\")\n",
    "        elif format == \"csv\":\n",
    "            self.train.to_csv(f\"{self.train_file_path}.csv\", index=index)\n",
    "            self.test.to_csv(f\"{self.test_file_path}.csv\", index=index)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __add_noise(self, series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "    def __analyzer_nlp(self, text):\n",
    "        stop_words = ['i', 'a', 'an', 'the', 'to', 'and', 'or', 'if', 'is', 'are', 'am', 'it', 'this', 'that', 'of', 'from', 'in', 'on']\n",
    "        text = text.lower()\n",
    "        text = text.replace('\\n', '')\n",
    "        text = text.replace('\\t', '')\n",
    "        text = re.sub(re.compile(r'[!-\\/:-@[-`{-~]'), ' ', text)\n",
    "        text = text.split(' ')\n",
    "\n",
    "        words = []\n",
    "        for word in text:\n",
    "            if (re.compile(r'^.*[0-9]+.*$').fullmatch(word) is not None):\n",
    "                continue\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            words.append(word)\n",
    "\n",
    "        return words\n",
    "\n",
    "    def __analyzer_cat(self, text):\n",
    "        return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample(FeatureEngineering):\n",
    "    def load_data(self):\n",
    "        self.train = pd.read_csv(\"../input/train.csv\")\n",
    "        self.test = pd.read_csv(\"../input/test.csv\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_features(self):\n",
    "        return self\n",
    "    \n",
    "    def create_topic_text(self):\n",
    "        self.train[\"count_1\"] = self.train[\"first_active_month\"].astype(\"str\") + self.train.groupby(\"first_active_month\")[\"first_active_month\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.train[\"count_2\"] = self.train[\"feature_1\"].astype(\"int\").astype(\"str\") + self.train.groupby(\"feature_1\")[\"feature_1\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.train[\"topic_text\"] = \"A\"+self.train[\"count_1\"].astype(str) \\\n",
    "                            +\" B\"+self.train[\"count_2\"].astype(str)\n",
    "        \n",
    "        self.test[\"count_1\"] = self.test[\"first_active_month\"].astype(\"str\") + self.test.groupby(\"first_active_month\")[\"first_active_month\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.test[\"count_2\"] = self.test[\"feature_1\"].astype(\"int\").astype(\"str\") + self.test.groupby(\"feature_1\")[\"feature_1\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.test[\"topic_text\"] = \"A\"+self.test[\"count_1\"].astype(str) \\\n",
    "                            +\" B\"+self.test[\"count_2\"].astype(str)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoML():\n",
    "    SEED = 42\n",
    "    EVAL_COLUMN = \"_preds\"\n",
    "    NUMERICS = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        if not isinstance(engine, FeatureEngineering): raise TypeError\n",
    "        self.engine = engine\n",
    "    \n",
    "    def run(self, scenario):\n",
    "        self.__seed_everything(AutoML.SEED)\n",
    "        self.target = scenario[\"target\"]\n",
    "        self.engine.load_data()\n",
    "\n",
    "        if \"drop_features\" in scenario:\n",
    "            self.__drop_features(scenario[\"drop_features\"])\n",
    "\n",
    "        self.engine.label_encode(skip_columns=[self.target])        \n",
    "        self.__set_column_type()\n",
    "\n",
    "        for command in scenario[\"feature_engineering\"]:\n",
    "            self.__do(command)\n",
    "\n",
    "        if \"feature_selection\" in scenario:\n",
    "            self.__feature_selection(scenario[\"feature_selection\"])\n",
    "\n",
    "        if \"drop_features\" in scenario:\n",
    "            self.__drop_features(scenario[\"drop_features\"])\n",
    "\n",
    "#         adv_score, importance = self.__adversarial_validation()\n",
    "#         if adv_score > 0.7:\n",
    "#             v = importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:5].index.values\n",
    "#             self.__drop_features(v)\n",
    "        \n",
    "        params = {\n",
    "            'objective': scenario[\"objective\"],\n",
    "            'boosting_type': scenario[\"boosting_type\"], \n",
    "            'metric': scenario[\"metric\"],\n",
    "            'n_jobs': -1,\n",
    "            'seed': AutoML.SEED\n",
    "        }\n",
    "        tuned = self.__hyper_parameter_tuning(params)\n",
    "        params = dict(params, **tuned)\n",
    "\n",
    "        for i in range(1, 6):\n",
    "            AutoML.SEED = 42**i\n",
    "            self.__seed_everything(AutoML.SEED)\n",
    "            params[\"seed\"] = AutoML.SEED\n",
    "            self.predicts, importance = self.__train(params)\n",
    "            param_with_score = self.__evaluate(params, pd.read_csv(scenario[\"eval_file_path\"]))\n",
    "            with open(f\"./param_{param_with_score['score']}.json\", \"w\") as fw:\n",
    "                json.dump(param_with_score, fw)\n",
    "            with open(f\"./scenario_{param_with_score['score']}.yml\", \"w\") as fw:\n",
    "                fw.write(yaml.dump(scenario, default_flow_style=False))\n",
    "            self.engine.train.to_pickle(f\"./train_{param_with_score['score']}.pkl\")\n",
    "            self.engine.test.to_pickle(f\"./test_{param_with_score['score']}.pkl\")\n",
    "    \n",
    "    def greedy_forward_selection(self, base_score, base_path=\"./\"):\n",
    "        self.__seed_everything(AutoML.SEED)\n",
    "        best_score = 0.0\n",
    "        selected = set([])\n",
    "        params = None\n",
    "        scenario = None\n",
    "        del self.engine.train, self.engine.test\n",
    "        with open(f\"{base_path}/param_{base_score}.json\") as f:\n",
    "            params = json.load(f)\n",
    "        with open(f\"{base_path}/scenario_{base_score}.yml\", \"r\") as yml:\n",
    "            scenario = yaml.safe_load(yml)\n",
    "        self.target = scenario[\"target\"]\n",
    "        \n",
    "        train = pd.read_pickle(f\"{base_path}/train_{base_score}.pkl\")\n",
    "        test = pd.read_pickle(f\"{base_path}/test_{base_score}.pkl\")\n",
    "        \n",
    "        train_x = [f for f in train.columns if f not in self.target]\n",
    "        while True:\n",
    "            if len(selected) == len(train_x): break\n",
    "            \n",
    "            scores = []\n",
    "            for col in train_x:\n",
    "                if col not in selected:\n",
    "                    feats = list(selected) + [col]\n",
    "                    self.engine.train = train[list(feats)+[self.target]]\n",
    "                    self.engine.test = test[feats]\n",
    "                    self.predicts, importance = self.__train(params)\n",
    "                    param_with_score = self.__evaluate(params, pd.read_csv(scenario[\"eval_file_path\"]))\n",
    "                    scores.append((col, param_with_score[\"score\"]))\n",
    "            \n",
    "            b_feature, b_score = sorted(scores, key=lambda tpl: tpl[1], reverse=True)[0]\n",
    "            print(f\"b_score: {b_score}\")\n",
    "            print(f\"best_score: {best_score}\")\n",
    "            if b_score > best_score:\n",
    "                selected.add(b_feature)\n",
    "                best_score = b_score\n",
    "                print(f'selected:{b_feature}')\n",
    "                print(f'score:{b_score}')\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        print(f'selected features: {selected}')\n",
    "            \n",
    "    def __do(self, command):\n",
    "        if command == \"fill_numeric_na\":\n",
    "            self.__fill_numeric_na()\n",
    "        if command == \"binning\":\n",
    "            self.__binning()\n",
    "        if command == \"transformation\":\n",
    "            self.__transformation()\n",
    "        if command == \"topic_encoding\":\n",
    "            self.__topic_encoding()\n",
    "        if command == \"umap\":\n",
    "            self.engine.umap_scaler(skip_columns=[self.target])\n",
    "        if command == \"kmean_features\":\n",
    "            self.engine.create_kmean_features(skip_columns=[self.target], seed=AutoML.SEED)\n",
    "        if command == \"min_max_scaling\":\n",
    "            self.engine.min_max_scaling(skip_columns=[self.target])\n",
    "        if command == \"two_by_two\":\n",
    "            self.engine.two_by_two(skip_columns=[self.target])\n",
    "    \n",
    "    def __evaluate(self, params, actuals):\n",
    "        calc_score_param = {}\n",
    "        actuals[AutoML.EVAL_COLUMN] = self.predicts\n",
    "        if params[\"objective\"] == \"binary\":\n",
    "            actuals.loc[actuals[AutoML.EVAL_COLUMN]>=0.5, AutoML.EVAL_COLUMN] = 1\n",
    "            actuals.loc[actuals[AutoML.EVAL_COLUMN]<0.5, AutoML.EVAL_COLUMN] = 0\n",
    "            actuals[AutoML.EVAL_COLUMN] = actuals[AutoML.EVAL_COLUMN].astype(\"int\")\n",
    "            calc_score_param[\"metric\"] = \"auc\"\n",
    "        \n",
    "        score = self.__calc_score(calc_score_param, actuals[self.target], actuals[AutoML.EVAL_COLUMN])\n",
    "        params[\"score\"] = score\n",
    "        print(f\"Score: {score}\")\n",
    "        return params\n",
    "    \n",
    "    def __transformation(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        aggs = [\"min\", \"max\", \"mean\", \"std\"]\n",
    "        for col in feats:\n",
    "            if self.engine.train[col].dtype.name == \"category\":\n",
    "                self.engine.agg_transform(group=[col], agg={f\"{col}\": [\"count\"]})\n",
    "            for c in num_columns:\n",
    "                if c == col: continue\n",
    "                self.engine.agg_transform(group=[col], agg={f\"{c}\": aggs})\n",
    "                for agg in aggs:\n",
    "                    if self.engine.train[self.engine.train[f\"{col}_{c}_{agg}\"].isnull()].shape[0] > 0:\n",
    "                        self.engine.train.drop(columns=[f\"{col}_{c}_{agg}\"], inplace=True)\n",
    "                        self.engine.test.drop(columns=[f\"{col}_{c}_{agg}\"], inplace=True)\n",
    "\n",
    "    def __fill_numeric_na(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        cat_columns = [col for col in feats if self.engine.train[col].dtype.name == \"category\"]\n",
    "        groups = []\n",
    "        for c in cat_columns:\n",
    "            if self.engine.train[self.engine.train[c].isnull()].shape[0] == 0:\n",
    "                if self.engine.train.groupby(c).size().shape[0] / self.engine.train.shape[0] < 0.1:\n",
    "                    groups.append(c)\n",
    "        for n in num_columns:\n",
    "            if len(groups) > 0:\n",
    "                self.engine.agg_transform(group=groups, agg={f\"{n}\": [\"mean\"]}, prefix=\"_tmp\")\n",
    "                self.engine.train[n].fillna(self.engine.train[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.test[n].fillna(self.engine.test[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.train.drop(columns=[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.test.drop(columns=[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "\n",
    "    def __binning(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        border = self.engine.train.shape[0]\n",
    "        df = pd.concat([self.engine.train, self.engine.test], ignore_index=True)\n",
    "        del self.engine.train, self.engine.test\n",
    "        gc.collect()\n",
    "\n",
    "        for c in num_columns:\n",
    "            if df[c].unique().shape[0] > 100:\n",
    "                df[f\"{c}_bin\"] = pd.cut(df[c], 10, labels=False)\n",
    "        self.engine.train = df.iloc[:border]\n",
    "        self.engine.test = df.iloc[border:]\n",
    "    \n",
    "    def __topic_encoding(self):\n",
    "        self.__create_topic_text()\n",
    "        self.engine.calc_topic_score(topic_text_columns=[\"topic_text\"], num_topics=5)\n",
    "        self.__drop_features([\"topic_text\"])\n",
    "\n",
    "    def __create_topic_text(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        border = self.engine.train.shape[0]\n",
    "        df = pd.concat([self.engine.train, self.engine.test], ignore_index=True)\n",
    "        del self.engine.train, self.engine.test\n",
    "        gc.collect()\n",
    "        \n",
    "        df[\"topic_text\"] = \"\"\n",
    "        for c in num_columns:\n",
    "            df[\"topic_text\"] = df[\"topic_text\"].astype(str) + \" \" + df[c].astype(str)\n",
    "\n",
    "        self.engine.train = df.iloc[:border]\n",
    "        self.engine.test = df.iloc[border:]\n",
    "    \n",
    "    def __set_column_type(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        for col in feats:\n",
    "            col_type = self.engine.train[col].dtypes\n",
    "            if self.engine.train[col].unique().shape[0] < 20:\n",
    "                self.engine.train[col] = self.engine.train[col].astype(\"category\")\n",
    "                self.engine.test[col] = self.engine.test[col].astype(\"category\")\n",
    "\n",
    "    def __drop_features(self, cols):\n",
    "        feats = [f for f in self.engine.train.columns if f in cols]\n",
    "        self.engine.train.drop(columns=feats, inplace=True)\n",
    "        self.engine.test.drop(columns=feats, inplace=True)\n",
    "    \n",
    "    def __feature_selection(self, cols):\n",
    "        self.engine.train = self.engine.train.loc[:, list(cols)+[self.target]]\n",
    "        self.engine.test = self.engine.test.loc[:, cols]\n",
    "    \n",
    "    def __hyper_parameter_tuning(self, params):\n",
    "        train, valid = model_selection.train_test_split(self.engine.train, test_size=0.33, random_state=AutoML.SEED, shuffle=True)\n",
    "        feats = [f for f in train.columns if f not in self.target]\n",
    "        \n",
    "        lgb_train = tuna.Dataset(train[feats], label=train[self.target].values)\n",
    "        lgb_valid = tuna.Dataset(valid[feats], label=valid[self.target].values)\n",
    "        best_params, tuning_history = dict(), list()\n",
    "\n",
    "        model = tuna.train(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_valid],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        num_boost_round=1000, \n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=100,\n",
    "                        best_params=best_params,\n",
    "                        tuning_history=tuning_history\n",
    "                        )\n",
    "\n",
    "        return best_params\n",
    "    \n",
    "    def __adversarial_validation(self, num_folds=5):\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        train = self.engine.train[feats]\n",
    "        test = self.engine.test[feats]\n",
    "        train[self.target] = 0\n",
    "        test[self.target] = 1\n",
    "        \n",
    "        df = pd.concat([train, test], ignore_index=True)\n",
    "        del train, test\n",
    "        gc.collect()\n",
    "        \n",
    "        oof_preds = np.zeros(df.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        scores = []\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[feats], df[self.target])):\n",
    "            train_x, train_y = df[feats].iloc[train_idx], df[self.target].iloc[train_idx]\n",
    "            valid_x, valid_y = df[feats].iloc[valid_idx], df[self.target].iloc[valid_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_x,\n",
    "                                    label=train_y,\n",
    "                                    free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(valid_x,\n",
    "                                   label=valid_y,\n",
    "                                   free_raw_data=False)\n",
    "            params = {'num_leaves': 50,\n",
    "                     'min_data_in_leaf': 30, \n",
    "                     'objective':'binary',\n",
    "                     'max_depth': 5,\n",
    "                     'learning_rate': 0.1,\n",
    "                     \"min_child_samples\": 20,\n",
    "                     \"boosting\": \"gbdt\",\n",
    "                     \"feature_fraction\": 0.9,\n",
    "                     \"bagging_freq\": 1,\n",
    "                     \"bagging_fraction\": 0.9 ,\n",
    "                     \"bagging_seed\": 44,\n",
    "                     \"metric\": 'auc',\n",
    "                     \"verbosity\": -1}\n",
    "\n",
    "            model = lgb.train(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_valid],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        num_boost_round=1000, \n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=100\n",
    "                        )\n",
    "\n",
    "            oof_preds[valid_idx] = model.predict(valid_x, num_iteration=model.best_iteration)\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = np.log1p(model.feature_importance(importance_type='gain', iteration=model.best_iteration))\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            scores.append(self.__calc_score(params, valid_y, oof_preds[valid_idx]))\n",
    "\n",
    "        self.__display_importances(feature_importance_df)\n",
    "        \n",
    "        return sum(scores)/len(scores), feature_importance_df\n",
    "        \n",
    "    def __train(self, params, num_folds=5, stratified=False):\n",
    "        if stratified:\n",
    "            folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "        else:\n",
    "            folds = KFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        oof_preds = np.zeros(self.engine.train.shape[0])\n",
    "        sub_preds = np.zeros(self.engine.test.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        scores = []\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(self.engine.train[feats], self.engine.train[self.target])):\n",
    "            train_x, train_y = self.engine.train[feats].iloc[train_idx], self.engine.train[self.target].iloc[train_idx]\n",
    "            valid_x, valid_y = self.engine.train[feats].iloc[valid_idx], self.engine.train[self.target].iloc[valid_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_x,\n",
    "                                    label=train_y,\n",
    "                                    free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(valid_x,\n",
    "                                   label=valid_y,\n",
    "                                   free_raw_data=False)\n",
    "            model = lgb.train(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            valid_sets=[lgb_train, lgb_valid],\n",
    "                            valid_names=['train', 'valid'],\n",
    "                            num_boost_round=1000, \n",
    "                            early_stopping_rounds=100,\n",
    "                            verbose_eval=100\n",
    "                            )\n",
    "\n",
    "            oof_preds[valid_idx] = model.predict(valid_x, num_iteration=model.best_iteration)\n",
    "            sub_preds += model.predict(self.engine.test[feats], num_iteration=model.best_iteration) / folds.n_splits\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = np.log1p(model.feature_importance(importance_type='gain', iteration=model.best_iteration))\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            scores.append(self.__calc_score(params, valid_y, oof_preds[valid_idx]))\n",
    "\n",
    "        print('CV : %.6f' % (sum(scores)/len(scores)))\n",
    "        self.__display_importances(feature_importance_df)\n",
    "\n",
    "        return sub_preds, feature_importance_df\n",
    "    \n",
    "    def __display_importances(self, feature_importance_df_):\n",
    "        all_cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).index\n",
    "        feature_importance_df_.loc[feature_importance_df_.feature.isin(all_cols)].to_csv(\"feature_importance.csv\", index=False)\n",
    "\n",
    "        cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "        best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "        plt.figure(figsize=(8, 10))\n",
    "        sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "        plt.title('LightGBM Features (avg over folds)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lgbm_importances.png')\n",
    "    \n",
    "    def __calc_score(self, params, actuals, preds):\n",
    "        if params[\"metric\"] == \"rmse\":\n",
    "            return np.sqrt(mean_squared_error(actuals, preds))\n",
    "        if params[\"metric\"] in [\"cross_entropy\", \"binary_logloss\"]:\n",
    "            return log_loss(actuals, preds)\n",
    "        if params[\"metric\"] == \"auc\":\n",
    "            return roc_auc_score(actuals, preds)\n",
    "\n",
    "    def __seed_everything(self, seed):\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/scenario.yml\", \"r\") as yml:\n",
    "    scenario = yaml.safe_load(yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = AutoML(engine=Sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml.greedy_forward_selection(base_score=0.7681353456669913)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noguchi.osamu\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:121: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "C:\\Users\\noguchi.osamu\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:122: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n",
      "C:\\Users\\noguchi.osamu\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n",
      "C:\\Users\\noguchi.osamu\\Anaconda3\\lib\\site-packages\\umap\\spectral.py:229: UserWarning: Embedding a total of 4 separate connected components using meta-embedding (experimental)\n",
      "  n_components\n",
      "tune_feature_fraction, val_score: inf:   0%|                                                     | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00720977\tvalid's cross_entropy: 0.685748\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttrain's cross_entropy: 0.213831\tvalid's cross_entropy: 0.449632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.449632:  14%|#####5                                 | 1/7 [08:59<53:59, 539.99s/it][I 2020-02-12 17:06:42,323] Finished trial#0 resulted in value: 0.4496320159649029. Current best value is 0.4496320159649029 with parameters: {'feature_fraction': 0.4}.\n",
      "tune_feature_fraction, val_score: 0.449632:  14%|#####5                                 | 1/7 [09:00<53:59, 539.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00716835\tvalid's cross_entropy: 0.696588\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttrain's cross_entropy: 0.235498\tvalid's cross_entropy: 0.451419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.449632:  29%|###########1                           | 2/7 [10:05<33:07, 397.59s/it][I 2020-02-12 17:07:47,644] Finished trial#1 resulted in value: 0.4514193743687081. Current best value is 0.4496320159649029 with parameters: {'feature_fraction': 0.4}.\n",
      "tune_feature_fraction, val_score: 0.449632:  29%|###########1                           | 2/7 [10:05<33:07, 397.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00701236\tvalid's cross_entropy: 0.689221\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttrain's cross_entropy: 0.225228\tvalid's cross_entropy: 0.450237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.449632:  43%|################7                      | 3/7 [11:21<20:04, 301.20s/it][I 2020-02-12 17:09:03,979] Finished trial#2 resulted in value: 0.45023722164653973. Current best value is 0.4496320159649029 with parameters: {'feature_fraction': 0.4}.\n",
      "tune_feature_fraction, val_score: 0.449632:  43%|################7                      | 3/7 [11:21<20:04, 301.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00682348\tvalid's cross_entropy: 0.722194\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttrain's cross_entropy: 0.213294\tvalid's cross_entropy: 0.451945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.449632:  57%|######################2                | 4/7 [13:03<12:03, 241.27s/it][I 2020-02-12 17:10:45,368] Finished trial#3 resulted in value: 0.4519447514871878. Current best value is 0.4496320159649029 with parameters: {'feature_fraction': 0.4}.\n",
      "tune_feature_fraction, val_score: 0.449632:  57%|######################2                | 4/7 [13:03<12:03, 241.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00689639\tvalid's cross_entropy: 0.699788\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttrain's cross_entropy: 0.204231\tvalid's cross_entropy: 0.457409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.449632:  71%|###########################8           | 5/7 [14:38<06:35, 197.66s/it][I 2020-02-12 17:12:21,272] Finished trial#4 resulted in value: 0.4574094976409901. Current best value is 0.4496320159649029 with parameters: {'feature_fraction': 0.4}.\n",
      "tune_feature_fraction, val_score: 0.449632:  71%|###########################8           | 5/7 [14:39<06:35, 197.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00666125\tvalid's cross_entropy: 0.704575\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttrain's cross_entropy: 0.20414\tvalid's cross_entropy: 0.449559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.449559:  86%|#################################4     | 6/7 [16:23<02:49, 169.82s/it][I 2020-02-12 17:14:06,143] Finished trial#5 resulted in value: 0.44955897339437245. Current best value is 0.44955897339437245 with parameters: {'feature_fraction': 0.8999999999999999}.\n",
      "tune_feature_fraction, val_score: 0.449559:  86%|#################################4     | 6/7 [16:23<02:49, 169.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00681016\tvalid's cross_entropy: 0.713576\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's cross_entropy: 0.179882\tvalid's cross_entropy: 0.451868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 0.449559: 100%|#######################################| 7/7 [18:20<00:00, 153.81s/it][I 2020-02-12 17:16:02,608] Finished trial#6 resulted in value: 0.45186842294183427. Current best value is 0.44955897339437245 with parameters: {'feature_fraction': 0.8999999999999999}.\n",
      "tune_feature_fraction, val_score: 0.449559: 100%|#######################################| 7/7 [18:20<00:00, 157.20s/it]\n",
      "tune_num_leaves, val_score: 0.449559:   0%|                                                     | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's cross_entropy: 0.00666125\tvalid's cross_entropy: 0.704575\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttrain's cross_entropy: 0.20414\tvalid's cross_entropy: 0.449559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 0.449559:   5%|##2                                         | 1/20 [01:57<37:11, 117.45s/it][I 2020-02-12 17:18:02,716] Finished trial#0 resulted in value: 0.44955897339437245. Current best value is 0.44955897339437245 with parameters: {'num_leaves': 74}.\n",
      "tune_num_leaves, val_score: 0.449559:   5%|##2                                         | 1/20 [01:59<37:11, 117.45s/it]"
     ]
    }
   ],
   "source": [
    "ml.run(scenario)\n",
    "# for i in range(0, 10):\n",
    "#     ml.run(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.engine.train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.engine.train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.engine.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train[[\"Age\", \"Fare\"]])\n",
    "\n",
    "train[[\"Age\", \"Fare\"]] = scaler.transform(train[[\"Age\", \"Fare\"]])\n",
    "train[\"Age\"].fillna(-9999, inplace=True)\n",
    "train[\"Fare\"].fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "um = umap.UMAP()\n",
    "um.fit(train[[\"Age\", \"Fare\"]])\n",
    "\n",
    "d = um.transform(train[[\"Age\", \"Fare\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Age\", \"Fare\"]] = train[[\"Age\", \"Fare\"]].replace(np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ml.engine.train, ml.engine.test], ignore_index=True)\n",
    "skip_columns = [\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in df.columns if f not in skip_columns]\n",
    "num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS and df[col].unique().shape[0] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_columns:\n",
    "    df[col] = df[col].replace(np.inf, np.nan)\n",
    "    df[col].fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = umap.UMAP()\n",
    "um.fit(df[num_columns])\n",
    "df[num_columns] = um.transform(df[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um.transform(df[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./\"\n",
    "base_score = 0.7681353456669913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "selected = set([])\n",
    "params = None\n",
    "scenario = None\n",
    "with open(f\"{base_path}/param_{base_score}.json\") as f:\n",
    "    params = json.load(f)\n",
    "with open(f\"{base_path}/scenario_{base_score}.yml\", \"r\") as yml:\n",
    "    scenario = yaml.safe_load(yml)\n",
    "\n",
    "train = pd.read_pickle(f\"{base_path}/train_{base_score}.pkl\")\n",
    "test = pd.read_pickle(f\"{base_path}/test_{base_score}.pkl\")\n",
    "\n",
    "train_x = [f for f in train.columns if f not in [\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for col in train_x:\n",
    "    if col not in selected:\n",
    "        feats = list(selected) + [col]\n",
    "        param_with_score = 1\n",
    "        scores.append((col, param_with_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_feature, b_score = sorted(scores, key=lambda tpl: tpl[1])[0]\n",
    "if b_score > best_score:\n",
    "    selected.add(b_feature)\n",
    "    best_score = b_score\n",
    "    print(f'selected:{b_feature}')\n",
    "    print(f'score:{b_score}')\n",
    "else:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
