{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime, time, re, warnings, gc, json, random, yaml, pickle\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, log_loss, roc_auc_score, f1_score\n",
    "from sklearn import datasets, manifold, mixture, model_selection\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, PowerTransformer, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz, hstack\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as tuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 256)\n",
    "pd.set_option(\"display.max_rows\", 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    print(f'[{title}] start')\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(metaclass=ABCMeta):\n",
    "    BASE_DIR = \".\"\n",
    "    NUMERICS = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = self.__class__.__name__\n",
    "        self.train = pd.DataFrame()\n",
    "        self.test = pd.DataFrame()\n",
    "        self.train_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_train\"\n",
    "        self.test_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_test\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_features(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def run(self, use_columns=[], skip_columns=[]):\n",
    "        with timer(self.name):\n",
    "            self.load_data()\n",
    "            self.replace_na(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.onehot_encode(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.create_features()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def onehot_encode(self, use_columns=[], skip_columns=[], sparse=False):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        self.label_encode(use_columns, skip_columns)\n",
    "        if sparse:\n",
    "            encoder = OneHotEncoder(categories='auto', sparse=sparse, dtype='uint8').fit(pd.concat([self.train.loc[:, use_columns], self.test.loc[:, use_columns]]))\n",
    "            m = 100000\n",
    "            train = vstack([encoder.transform(self.train[i*m:(i+1)*m].loc[:, use_columns]) for i in range(self.train.shape[0] // m + 1)])\n",
    "            test  = vstack([encoder.transform(self.test[i*m:(i+1)*m].loc[:, use_columns])  for i in range(self.test.shape[0] // m +  1)])\n",
    "            save_npz(f\"{self.train_file_path}.npz\", train, compressed=True)\n",
    "            save_npz(f\"{self.test_file_path}.npz\",  test,  compressed=True)\n",
    "        else:\n",
    "            self.train[\"is_train_date\"] = 1\n",
    "            self.test[\"is_train_date\"]  = 0\n",
    "            df = pd.concat([self.train, self.test])\n",
    "            del self.train, self.test\n",
    "            gc.collect()\n",
    "            for col in use_columns:\n",
    "                df = df.join(pd.get_dummies(df[col], prefix=col))\n",
    "            \n",
    "            self.train = df[df[\"is_train_date\"]==1]\n",
    "            self.test = df[df[\"is_train_date\"]==0]\n",
    "            self.train.drop(columns=\"is_train_date\", inplace=True)\n",
    "            self.test.drop(columns=\"is_train_date\", inplace=True)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def label_encode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        \n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "        \n",
    "        for col in use_columns:\n",
    "            if df[col].dtype.name in [\"object\", \"category\"]:\n",
    "                df[col] = df[col].astype(str)\n",
    "                le = LabelEncoder().fit(df[col])\n",
    "                df[col] = le.transform(df[col])+1\n",
    "    \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def target_encode(self, col_name, target_name, min_samples_leaf=1, smoothing=1, noise_level=0):\n",
    "        trn_series = self.train[col_name]\n",
    "        tst_series = self.test[col_name]\n",
    "        target = self.train[target_name]\n",
    "        \n",
    "        assert len(trn_series) == len(target)\n",
    "\n",
    "        temp = pd.concat([trn_series, target], axis=1)\n",
    "        averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "        smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "        prior = target.mean()\n",
    "        averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "        averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "        ft_trn_series = pd.merge(\n",
    "            trn_series.to_frame(trn_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=trn_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_trn_series.index = trn_series.index \n",
    "        ft_tst_series = pd.merge(\n",
    "            tst_series.to_frame(tst_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=tst_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_tst_series.index = tst_series.index\n",
    "\n",
    "        self.train[f\"te_smoothing_{col_name}\"], self.test[f\"te_smoothing_{col_name}\"] = self.__add_noise(ft_trn_series, noise_level), self.__add_noise(ft_tst_series, noise_level)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "            \n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                df[f\"{prefix}{k}_{v}\"] = df.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    df[f\"{prefix}{k}_{vv}\"] = df.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform_ratio(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "        prefix = f\"ratio_{prefix}\"\n",
    "        \n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                self.train[f\"{prefix}{k}_{v}\"] = self.train[k] / self.train.groupby(group)[k].transform(v)\n",
    "                self.test[f\"{prefix}{k}_{v}\"] = self.test[k] / self.test.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    self.train[f\"{prefix}{k}_{vv}\"] = self.train[k] / self.train.groupby(group)[k].transform(vv)\n",
    "                    self.test[f\"{prefix}{k}_{vv}\"] = self.test[k] / self.test.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def replace_na(self, use_columns=[], skip_columns=[], fill_value=-1):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mode().values[0])\n",
    "            self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mode().values[0])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mean(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mean())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mean())\n",
    "\n",
    "        return self\n",
    "\n",
    "    def replace_na_median(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].median())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].median())\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_topic_score(self, topic_text_columns, num_topics=5):\n",
    "        df = pd.concat([self.train.loc[:, topic_text_columns], self.test.loc[:, topic_text_columns]])\n",
    "        \n",
    "        for col in topic_text_columns:\n",
    "            texts = [[word for word in document.lower().split()] for document in df[col].values]\n",
    "            dictionary = corpora.Dictionary(texts)\n",
    "            bow_corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "            lda = models.LdaModel(bow_corpus, id2word=dictionary, num_topics=num_topics)\n",
    "                        \n",
    "            size = df.shape[0]\n",
    "            topics = {i:[-1]*size for i in range(num_topics)}\n",
    "            for i, row in enumerate(lda[bow_corpus]):\n",
    "                for (topic_num, prop_topic) in row:\n",
    "                    topics[topic_num][i] = prop_topic\n",
    "            \n",
    "            for i in range(num_topics):\n",
    "                self.train[f\"{col}_topic_{i}\"] = topics[i][:self.train.shape[0]]\n",
    "                self.test[f\"{col}_topic_{i}\"] = topics[i][self.train.shape[0]:]\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_scdv_word2vec_score(self, text_col_name):\n",
    "        features_num = 20\n",
    "        min_word_count = 10\n",
    "        context = 5\n",
    "        downsampling = 1e-3\n",
    "        epoch_num = 10\n",
    "        clusters_num = 6\n",
    "        \n",
    "        df = pd.concat([self.train.loc[:, [text_col_name]], self.test.loc[:, [text_col_name]]])\n",
    "        df[text_col_name] = df[text_col_name].fillna(\"\")\n",
    "        \n",
    "        corpus = [self.__analyzer_cat(text) for text in df[text_col_name]]\n",
    "        word2vecs = Word2Vec(sentences=corpus, iter=epoch_num, size=features_num, min_count=min_word_count, window=context, sample=downsampling)\n",
    "        word_vectors = word2vecs.wv.vectors\n",
    "        \n",
    "        gmm = mixture.GaussianMixture(n_components=clusters_num, covariance_type='tied', max_iter=50)\n",
    "        gmm.fit(word_vectors)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer=self.__analyzer_cat, min_df=min_word_count)\n",
    "        tfidfs = tfidf_vectorizer.fit_transform(df[text_col_name])\n",
    "        \n",
    "        idf_dic = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer._tfidf.idf_))\n",
    "        assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict(word_vectors)))\n",
    "        soft_assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict_proba(word_vectors)))\n",
    "        \n",
    "        word_topic_vecs = {}\n",
    "        for word in assign_dic:\n",
    "            word_topic_vecs[word] = np.zeros(features_num*clusters_num, dtype=np.float32)\n",
    "            for i in range(0, clusters_num):\n",
    "                try:\n",
    "                    word_topic_vecs[word][i*features_num:(i+1)*features_num] = word2vecs.wv[word]*soft_assign_dic[word][i]*idf_dic[word]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        scdvs = np.zeros((len(df[text_col_name]), clusters_num*features_num), dtype=np.float32)\n",
    "\n",
    "        a_min = 0\n",
    "        a_max = 0\n",
    "\n",
    "        for i, text in enumerate(df[text_col_name]):\n",
    "            tmp = np.zeros(clusters_num*features_num, dtype=np.float32)\n",
    "            words = self.__analyzer_cat(text)\n",
    "            for word in words:\n",
    "                if word in word_topic_vecs:\n",
    "                    tmp += word_topic_vecs[word]\n",
    "            norm = np.sqrt(np.sum(tmp**2))\n",
    "            if norm > 0:\n",
    "                tmp /= norm\n",
    "            a_min += min(tmp)\n",
    "            a_max += max(tmp)\n",
    "            scdvs[i] = tmp\n",
    "\n",
    "        p = 0.04\n",
    "        a_min = a_min*1.0 / len(df[text_col_name])\n",
    "        a_max = a_max*1.0 / len(df[text_col_name])\n",
    "        thres = (abs(a_min)+abs(a_max)) / 2\n",
    "        thres *= p\n",
    "        scdvs[abs(scdvs) < thres] = 0\n",
    "        \n",
    "        tsne_scdv = manifold.TSNE(n_components=2).fit_transform(scdvs)\n",
    "        \n",
    "        self.train[f\"scdv_{text_col_name}_x\"] = tsne_scdv[:self.train.shape[0], 0]\n",
    "        self.train[f\"scdv_{text_col_name}_y\"] = tsne_scdv[:self.train.shape[0], 1]        \n",
    "        self.test[f\"scdv_{text_col_name}_x\"] = tsne_scdv[self.train.shape[0]:, 0]\n",
    "        self.test[f\"scdv_{text_col_name}_y\"] = tsne_scdv[self.train.shape[0]:, 1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def yeo_johnson(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "        \n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "        pt.fit(df[num_columns])\n",
    "\n",
    "        df[num_columns] = pt.transform(df[num_columns])\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def umap_scaler(self, skip_columns=[]):\n",
    "        self.yeo_johnson(skip_columns=skip_columns)\n",
    "        \n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS and df[col].unique().shape[0] > 100]\n",
    "        for col in num_columns:\n",
    "            df[col] = df[col].replace(np.inf, np.nan)\n",
    "            df[col].fillna(-9999, inplace=True)\n",
    "        \n",
    "        um = umap.UMAP()\n",
    "        um.fit(df[num_columns])\n",
    "        d = um.transform(df[num_columns])\n",
    "        df[\"umap_d1\"] = d[:, 0]\n",
    "        df[\"umap_d2\"] = d[:, 1]\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_kmean_features(self, seed, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        for col in num_columns:\n",
    "            df[col].fillna(-9999, inplace=True)\n",
    "        X = df[num_columns]\n",
    "        \n",
    "        kmeans = MiniBatchKMeans(n_clusters=10, random_state=seed)\n",
    "        kmeans.fit(X)\n",
    "\n",
    "        df[\"k_class\"] = kmeans.predict(X)\n",
    "        train_distances = kmeans.transform(X)\n",
    "        for i in range(10):\n",
    "            df[f\"k_distance_{i}\"] = train_distances[:, i]\n",
    "    \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def min_max_scaling(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(df[num_columns])\n",
    "        df[num_columns] = scaler.transform(df[num_columns])\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def two_by_two(self, skip_columns=[]):\n",
    "        border = self.train.shape[0]\n",
    "        df = pd.concat([self.train, self.test], ignore_index=True)\n",
    "        del self.train, self.test\n",
    "        gc.collect()\n",
    "\n",
    "        feats = [f for f in df.columns if f not in skip_columns]\n",
    "        num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS]\n",
    "        targets = num_columns.copy()\n",
    "        for col in num_columns:\n",
    "            targets.remove(col)\n",
    "            for t in targets:\n",
    "                df[f\"{col}_{t}_mul\"] = df[col] * df[t]\n",
    "                df[f\"{col}_{t}_sub_left\"] = df[col] / df[t]\n",
    "                df[f\"{col}_{t}_sub_right\"] = df[t] / df[col]\n",
    "        \n",
    "        self.train = df.iloc[:border]\n",
    "        self.test = df.iloc[border:]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def columns_1d(self):\n",
    "        self.train.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.train.columns.tolist()])\n",
    "        self.test.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.test.columns.tolist()])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def head(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train head: {title}\")\n",
    "        print(self.train.loc[:, train_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test head: {title}\")\n",
    "        print(self.test.loc[:, test_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tail(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train tail: {title}\")\n",
    "        print(self.train.loc[:, train_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test tail: {title}\")\n",
    "        print(self.test.loc[:, test_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def save(self, format=\"feather\", index=False):\n",
    "        if format == \"feather\":\n",
    "            self.train.to_feather(f\"{self.train_file_path}.ftr\")\n",
    "            self.test.to_feather(f\"{self.test_file_path}.ftr\")\n",
    "        elif format == \"csv\":\n",
    "            self.train.to_csv(f\"{self.train_file_path}.csv\", index=index)\n",
    "            self.test.to_csv(f\"{self.test_file_path}.csv\", index=index)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __add_noise(self, series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "    def __analyzer_nlp(self, text):\n",
    "        stop_words = ['i', 'a', 'an', 'the', 'to', 'and', 'or', 'if', 'is', 'are', 'am', 'it', 'this', 'that', 'of', 'from', 'in', 'on']\n",
    "        text = text.lower()\n",
    "        text = text.replace('\\n', '')\n",
    "        text = text.replace('\\t', '')\n",
    "        text = re.sub(re.compile(r'[!-\\/:-@[-`{-~]'), ' ', text)\n",
    "        text = text.split(' ')\n",
    "\n",
    "        words = []\n",
    "        for word in text:\n",
    "            if (re.compile(r'^.*[0-9]+.*$').fullmatch(word) is not None):\n",
    "                continue\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            words.append(word)\n",
    "\n",
    "        return words\n",
    "\n",
    "    def __analyzer_cat(self, text):\n",
    "        return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoML():\n",
    "    SEED = 42\n",
    "    EVAL_COLUMN = \"_preds\"\n",
    "    NUMERICS = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        if not isinstance(engine, FeatureEngineering): raise TypeError\n",
    "        self.engine = engine\n",
    "    \n",
    "    def run(self, scenario):\n",
    "        self.__seed_everything(AutoML.SEED)\n",
    "        self.target = scenario[\"target\"]\n",
    "        self.engine.load_data()\n",
    "        \n",
    "        params = {\n",
    "            'objective': scenario[\"objective\"],\n",
    "            'boosting_type': scenario[\"boosting_type\"], \n",
    "            'metric': scenario[\"metric\"],\n",
    "            'n_jobs': -1,\n",
    "            'seed': AutoML.SEED\n",
    "        }\n",
    "        tuned = self.__hyper_parameter_tuning(params)\n",
    "        params = dict(params, **tuned)\n",
    "        \n",
    "        self.predicts, importance = self.__train(params)\n",
    "        \n",
    "    def greedy_forward_selection(self, base_score, base_path=\"./\"):\n",
    "        self.__seed_everything(AutoML.SEED)\n",
    "        best_score = 0.0\n",
    "        selected = set([])\n",
    "        params = None\n",
    "        scenario = None\n",
    "        del self.engine.train, self.engine.test\n",
    "        with open(f\"{base_path}/param_{base_score}.json\") as f:\n",
    "            params = json.load(f)\n",
    "        with open(f\"{base_path}/scenario_{base_score}.yml\", \"r\") as yml:\n",
    "            scenario = yaml.safe_load(yml)\n",
    "        self.target = scenario[\"target\"]\n",
    "        \n",
    "        train = pd.read_pickle(f\"{base_path}/train_{base_score}.pkl\")\n",
    "        test = pd.read_pickle(f\"{base_path}/test_{base_score}.pkl\")\n",
    "        \n",
    "        train_x = [f for f in train.columns if f not in self.target]\n",
    "        while True:\n",
    "            if len(selected) == len(train_x): break\n",
    "            \n",
    "            scores = []\n",
    "            for col in train_x:\n",
    "                if col not in selected:\n",
    "                    feats = list(selected) + [col]\n",
    "                    self.engine.train = train[list(feats)+[self.target]]\n",
    "                    self.engine.test = test[feats]\n",
    "                    self.predicts, importance = self.__train(params)\n",
    "                    param_with_score = self.__evaluate(params, pd.read_csv(scenario[\"eval_file_path\"]))\n",
    "                    scores.append((col, param_with_score[\"score\"]))\n",
    "            \n",
    "            b_feature, b_score = sorted(scores, key=lambda tpl: tpl[1], reverse=True)[0]\n",
    "            print(f\"b_score: {b_score}\")\n",
    "            print(f\"best_score: {best_score}\")\n",
    "            if b_score > best_score:\n",
    "                selected.add(b_feature)\n",
    "                best_score = b_score\n",
    "                print(f'selected:{b_feature}')\n",
    "                print(f'score:{b_score}')\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        print(f'selected features: {selected}')\n",
    "        with open(\"selected.pkl\", \"wb\") as fw:\n",
    "            pickle.dump(selected, fw)\n",
    "            \n",
    "    def __do(self, command):\n",
    "        if command == \"fill_numeric_na\":\n",
    "            self.__fill_numeric_na()\n",
    "        if command == \"binning\":\n",
    "            self.__binning()\n",
    "        if command == \"transformation\":\n",
    "            self.__transformation()\n",
    "        if command == \"topic_encoding\":\n",
    "            self.__topic_encoding()\n",
    "        if command == \"umap\":\n",
    "            self.engine.umap_scaler(skip_columns=[self.target])\n",
    "        if command == \"kmean_features\":\n",
    "            self.engine.create_kmean_features(skip_columns=[self.target], seed=AutoML.SEED)\n",
    "        if command == \"min_max_scaling\":\n",
    "            self.engine.min_max_scaling(skip_columns=[self.target])\n",
    "        if command == \"two_by_two\":\n",
    "            self.engine.two_by_two(skip_columns=[self.target])\n",
    "    \n",
    "    def __evaluate(self, params, actuals, metric):\n",
    "        calc_score_param = {\"metric\": metric}\n",
    "        actuals[AutoML.EVAL_COLUMN] = self.predicts\n",
    "        if params[\"objective\"] == \"binary\":\n",
    "            actuals.loc[actuals[AutoML.EVAL_COLUMN]>=0.5, AutoML.EVAL_COLUMN] = 1\n",
    "            actuals.loc[actuals[AutoML.EVAL_COLUMN]<0.5, AutoML.EVAL_COLUMN] = 0\n",
    "            actuals[AutoML.EVAL_COLUMN] = actuals[AutoML.EVAL_COLUMN].astype(\"int\")\n",
    "        \n",
    "        score = self.__calc_score(calc_score_param, actuals[self.target], actuals[AutoML.EVAL_COLUMN])\n",
    "        params[\"score\"] = score\n",
    "        print(f\"Score: {score}\")\n",
    "        return params\n",
    "    \n",
    "    def __transformation(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        aggs = [\"min\", \"max\", \"mean\", \"std\"]\n",
    "        for col in feats:\n",
    "            if self.engine.train[col].dtype.name == \"category\":\n",
    "                self.engine.agg_transform(group=[col], agg={f\"{col}\": [\"count\"]})\n",
    "            for c in num_columns:\n",
    "                if c == col: continue\n",
    "                self.engine.agg_transform(group=[col], agg={f\"{c}\": aggs})\n",
    "                for agg in aggs:\n",
    "                    if self.engine.train[self.engine.train[f\"{col}_{c}_{agg}\"].isnull()].shape[0] > 0:\n",
    "                        self.engine.train.drop(columns=[f\"{col}_{c}_{agg}\"], inplace=True)\n",
    "                        self.engine.test.drop(columns=[f\"{col}_{c}_{agg}\"], inplace=True)\n",
    "\n",
    "    def __fill_numeric_na(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        cat_columns = [col for col in feats if self.engine.train[col].dtype.name == \"category\"]\n",
    "        groups = []\n",
    "        for c in cat_columns:\n",
    "            if self.engine.train[self.engine.train[c].isnull()].shape[0] == 0:\n",
    "                if self.engine.train.groupby(c).size().shape[0] / self.engine.train.shape[0] < 0.1:\n",
    "                    groups.append(c)\n",
    "        for n in num_columns:\n",
    "            if len(groups) > 0:\n",
    "                self.engine.agg_transform(group=groups, agg={f\"{n}\": [\"mean\"]}, prefix=\"_tmp\")\n",
    "                self.engine.train[n].fillna(self.engine.train[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.test[n].fillna(self.engine.test[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.train.drop(columns=[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "                self.engine.test.drop(columns=[f\"_tmp_{n}_mean\"], inplace=True)\n",
    "\n",
    "    def __binning(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        border = self.engine.train.shape[0]\n",
    "        df = pd.concat([self.engine.train, self.engine.test], ignore_index=True)\n",
    "        del self.engine.train, self.engine.test\n",
    "        gc.collect()\n",
    "\n",
    "        for c in num_columns:\n",
    "            if df[c].unique().shape[0] > 100:\n",
    "                df[f\"{c}_bin\"] = pd.cut(df[c], 10, labels=False)\n",
    "        self.engine.train = df.iloc[:border]\n",
    "        self.engine.test = df.iloc[border:]\n",
    "    \n",
    "    def __topic_encoding(self):\n",
    "        self.__create_topic_text()\n",
    "        self.engine.calc_topic_score(topic_text_columns=[\"topic_text\"], num_topics=5)\n",
    "        self.__drop_features([\"topic_text\"])\n",
    "\n",
    "    def __create_topic_text(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        num_columns = [col for col in feats if self.engine.train[col].dtype.name in AutoML.NUMERICS]\n",
    "        border = self.engine.train.shape[0]\n",
    "        df = pd.concat([self.engine.train, self.engine.test], ignore_index=True)\n",
    "        del self.engine.train, self.engine.test\n",
    "        gc.collect()\n",
    "        \n",
    "        df[\"topic_text\"] = \"\"\n",
    "        for c in num_columns:\n",
    "            df[\"topic_text\"] = df[\"topic_text\"].astype(str) + \" \" + df[c].astype(str)\n",
    "\n",
    "        self.engine.train = df.iloc[:border]\n",
    "        self.engine.test = df.iloc[border:]\n",
    "    \n",
    "    def __set_column_type(self):\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        for col in feats:\n",
    "            col_type = self.engine.train[col].dtypes\n",
    "            if self.engine.train[col].unique().shape[0] < 20:\n",
    "                self.engine.train[col] = self.engine.train[col].astype(\"category\")\n",
    "                self.engine.test[col] = self.engine.test[col].astype(\"category\")\n",
    "\n",
    "    def __drop_features(self, cols):\n",
    "        feats = [f for f in self.engine.train.columns if f in cols]\n",
    "        self.engine.train.drop(columns=feats, inplace=True)\n",
    "        self.engine.test.drop(columns=feats, inplace=True)\n",
    "    \n",
    "    def __feature_selection(self, cols):\n",
    "        self.engine.train = self.engine.train.loc[:, list(cols)+[self.target]]\n",
    "        self.engine.test = self.engine.test.loc[:, cols]\n",
    "    \n",
    "    def __hyper_parameter_tuning(self, params):\n",
    "        train, valid = model_selection.train_test_split(self.engine.train, test_size=0.33, random_state=AutoML.SEED, shuffle=True)\n",
    "        feats = list(range(0, 38))\n",
    "        \n",
    "        lgb_train = tuna.Dataset(train[feats], label=train[self.target].values)\n",
    "        lgb_valid = tuna.Dataset(valid[feats], label=valid[self.target].values)\n",
    "        best_params, tuning_history = dict(), list()\n",
    "\n",
    "        model = tuna.train(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_valid],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        num_boost_round=1000, \n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=100,\n",
    "                        best_params=best_params,\n",
    "                        tuning_history=tuning_history\n",
    "                        )\n",
    "\n",
    "        return best_params\n",
    "    \n",
    "    def __adversarial_validation(self, num_folds=5):\n",
    "        folds = KFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "        feats = [f for f in self.engine.train.columns if f not in self.target]\n",
    "        train = self.engine.train[feats]\n",
    "        test = self.engine.test[feats]\n",
    "        train[self.target] = 0\n",
    "        test[self.target] = 1\n",
    "        \n",
    "        df = pd.concat([train, test], ignore_index=True)\n",
    "        del train, test\n",
    "        gc.collect()\n",
    "        \n",
    "        oof_preds = np.zeros(df.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        scores = []\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(df[feats], df[self.target])):\n",
    "            train_x, train_y = df[feats].iloc[train_idx], df[self.target].iloc[train_idx]\n",
    "            valid_x, valid_y = df[feats].iloc[valid_idx], df[self.target].iloc[valid_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_x,\n",
    "                                    label=train_y,\n",
    "                                    free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(valid_x,\n",
    "                                   label=valid_y,\n",
    "                                   free_raw_data=False)\n",
    "            params = {'num_leaves': 50,\n",
    "                     'min_data_in_leaf': 30, \n",
    "                     'objective':'binary',\n",
    "                     'max_depth': 5,\n",
    "                     'learning_rate': 0.1,\n",
    "                     \"min_child_samples\": 20,\n",
    "                     \"boosting\": \"gbdt\",\n",
    "                     \"feature_fraction\": 0.9,\n",
    "                     \"bagging_freq\": 1,\n",
    "                     \"bagging_fraction\": 0.9 ,\n",
    "                     \"bagging_seed\": 44,\n",
    "                     \"metric\": 'auc',\n",
    "                     \"verbosity\": -1}\n",
    "\n",
    "            model = lgb.train(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_valid],\n",
    "                        valid_names=['train', 'valid'],\n",
    "                        num_boost_round=1000, \n",
    "                        early_stopping_rounds=100,\n",
    "                        verbose_eval=100\n",
    "                        )\n",
    "\n",
    "            oof_preds[valid_idx] = model.predict(valid_x, num_iteration=model.best_iteration)\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = np.log1p(model.feature_importance(importance_type='gain', iteration=model.best_iteration))\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            scores.append(self.__calc_score(params, valid_y, oof_preds[valid_idx]))\n",
    "\n",
    "        self.__display_importances(feature_importance_df)\n",
    "        \n",
    "        return sum(scores)/len(scores), feature_importance_df\n",
    "        \n",
    "    def __train(self, params, num_folds=5, stratified=False):\n",
    "        if stratified:\n",
    "            folds = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "        else:\n",
    "            folds = KFold(n_splits=num_folds, shuffle=True, random_state=AutoML.SEED)\n",
    "\n",
    "        feats = list(range(0, 38))\n",
    "        oof_preds = np.zeros(self.engine.train.shape[0])\n",
    "        sub_preds = np.zeros(self.engine.test.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "\n",
    "        scores = []\n",
    "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(self.engine.train[feats], self.engine.train[self.target])):\n",
    "            train_x, train_y = self.engine.train[feats].iloc[train_idx], self.engine.train[self.target].iloc[train_idx]\n",
    "            valid_x, valid_y = self.engine.train[feats].iloc[valid_idx], self.engine.train[self.target].iloc[valid_idx]\n",
    "\n",
    "            lgb_train = lgb.Dataset(train_x,\n",
    "                                    label=train_y,\n",
    "                                    free_raw_data=False)\n",
    "            lgb_valid = lgb.Dataset(valid_x,\n",
    "                                   label=valid_y,\n",
    "                                   free_raw_data=False)\n",
    "            model = lgb.train(\n",
    "                            params,\n",
    "                            lgb_train,\n",
    "                            valid_sets=[lgb_train, lgb_valid],\n",
    "                            valid_names=['train', 'valid'],\n",
    "                            num_boost_round=1000, \n",
    "                            early_stopping_rounds=100,\n",
    "                            verbose_eval=100\n",
    "                            )\n",
    "\n",
    "            oof_preds[valid_idx] = model.predict(valid_x, num_iteration=model.best_iteration)\n",
    "            sub_preds += model.predict(self.engine.test[feats], num_iteration=model.best_iteration) / folds.n_splits\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"feature\"] = feats\n",
    "            fold_importance_df[\"importance\"] = np.log1p(model.feature_importance(importance_type='gain', iteration=model.best_iteration))\n",
    "            fold_importance_df[\"fold\"] = n_fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "            scores.append(self.__calc_score(params, valid_y, oof_preds[valid_idx]))\n",
    "\n",
    "        print('CV : %.6f' % (sum(scores)/len(scores)))\n",
    "        self.__display_importances(feature_importance_df)\n",
    "\n",
    "        return sub_preds, feature_importance_df\n",
    "    \n",
    "    def __display_importances(self, feature_importance_df_):\n",
    "        all_cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).index\n",
    "        feature_importance_df_.loc[feature_importance_df_.feature.isin(all_cols)].to_csv(\"feature_importance.csv\", index=False)\n",
    "\n",
    "        cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False)[:40].index\n",
    "        best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "        plt.figure(figsize=(8, 10))\n",
    "        sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "        plt.title('LightGBM Features (avg over folds)')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('lgbm_importances.png')\n",
    "    \n",
    "    def __calc_score(self, params, actuals, preds):\n",
    "        if params[\"metric\"] == \"rmse\":\n",
    "            return np.sqrt(mean_squared_error(actuals, preds))\n",
    "        if params[\"metric\"] in [\"cross_entropy\", \"binary_logloss\"]:\n",
    "            return log_loss(actuals, preds)\n",
    "        if params[\"metric\"] == \"auc\":\n",
    "            return roc_auc_score(actuals, preds)\n",
    "        if params[\"metric\"] == \"f1\":\n",
    "            return f1_score(actuals, preds)\n",
    "\n",
    "    def __seed_everything(self, seed):\n",
    "        random.seed(seed)\n",
    "        os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "        np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample(FeatureEngineering):\n",
    "    def load_data(self):\n",
    "        self.train = pd.read_pickle(\"./structure_train_01.pkl\")\n",
    "        self.test = pd.read_pickle(\"./structure_train_01.pkl\")\n",
    "        \n",
    "        self.train.columns = range(0, 38)\n",
    "        self.test.columns = range(0, 38)\n",
    "        df = pd.read_pickle(\"./structure_df_01.pkl\")\n",
    "        self.train[\"k_class\"] = df[\"k_class\"]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_features(self):\n",
    "        return self\n",
    "    \n",
    "    def create_topic_text(self):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../input/building_structure/scenario.yml\", \"r\") as yml:\n",
    "    scenario = yaml.safe_load(yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = AutoML(engine=Sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noguchi/.pyenv/versions/3.6.9/lib/python3.6/site-packages/optuna/_experimental.py:87: ExperimentalWarning: train is experimental (supported from v0.18.0). The interface can change in the future.\n",
      "  ExperimentalWarning\n",
      "tune_feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.840828\tvalid's rmse: 1.43749\n",
      "[200]\ttrain's rmse: 0.643549\tvalid's rmse: 1.3875\n",
      "[300]\ttrain's rmse: 0.541128\tvalid's rmse: 1.36481\n",
      "[400]\ttrain's rmse: 0.469407\tvalid's rmse: 1.34843\n",
      "[500]\ttrain's rmse: 0.415724\tvalid's rmse: 1.34937\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttrain's rmse: 0.431727\tvalid's rmse: 1.34311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.343111:  14%|#4        | 1/7 [00:00<00:03,  1.51it/s]\u001b[32m[I 2020-03-24 13:54:19,647]\u001b[0m Finished trial#0 resulted in value: 1.3431114711501821. Current best value is 1.3431114711501821 with parameters: {'feature_fraction': 0.4}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.343111:  14%|#4        | 1/7 [00:00<00:03,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.78625\tvalid's rmse: 1.38709\n",
      "[200]\ttrain's rmse: 0.584155\tvalid's rmse: 1.34524\n",
      "[300]\ttrain's rmse: 0.479024\tvalid's rmse: 1.32631\n",
      "[400]\ttrain's rmse: 0.416154\tvalid's rmse: 1.32233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.318905:  29%|##8       | 2/7 [00:01<00:03,  1.43it/s]\u001b[32m[I 2020-03-24 13:54:20,418]\u001b[0m Finished trial#1 resulted in value: 1.3189051494574913. Current best value is 1.3189051494574913 with parameters: {'feature_fraction': 0.5}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.318905:  29%|##8       | 2/7 [00:01<00:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain's rmse: 0.370263\tvalid's rmse: 1.32223\n",
      "Early stopping, best iteration is:\n",
      "[483]\ttrain's rmse: 0.377563\tvalid's rmse: 1.31891\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.744827\tvalid's rmse: 1.34727\n",
      "[200]\ttrain's rmse: 0.54219\tvalid's rmse: 1.30212\n",
      "[300]\ttrain's rmse: 0.438215\tvalid's rmse: 1.29107\n",
      "[400]\ttrain's rmse: 0.37924\tvalid's rmse: 1.2868\n",
      "[500]\ttrain's rmse: 0.336097\tvalid's rmse: 1.29018\n",
      "Early stopping, best iteration is:\n",
      "[443]\ttrain's rmse: 0.358718\tvalid's rmse: 1.28487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.284872:  43%|####2     | 3/7 [00:02<00:02,  1.50it/s]\u001b[32m[I 2020-03-24 13:54:21,019]\u001b[0m Finished trial#2 resulted in value: 1.2848723407574885. Current best value is 1.2848723407574885 with parameters: {'feature_fraction': 0.6}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.284872:  43%|####2     | 3/7 [00:02<00:02,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.281388:  57%|#####7    | 4/7 [00:03<00:02,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:22,562]\u001b[0m Finished trial#3 resulted in value: 1.2813883921028735. Current best value is 1.2813883921028735 with parameters: {'feature_fraction': 0.7}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.281388:  57%|#####7    | 4/7 [00:03<00:02,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.69527\tvalid's rmse: 1.4052\n",
      "[200]\ttrain's rmse: 0.501272\tvalid's rmse: 1.34085\n",
      "[300]\ttrain's rmse: 0.397727\tvalid's rmse: 1.30075\n",
      "[400]\ttrain's rmse: 0.33748\tvalid's rmse: 1.29081\n",
      "[500]\ttrain's rmse: 0.299897\tvalid's rmse: 1.28889\n",
      "[600]\ttrain's rmse: 0.275037\tvalid's rmse: 1.28817\n",
      "[700]\ttrain's rmse: 0.257388\tvalid's rmse: 1.28839\n",
      "Early stopping, best iteration is:\n",
      "[663]\ttrain's rmse: 0.263593\tvalid's rmse: 1.28716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.281388:  71%|#######1  | 5/7 [00:05<00:02,  1.16s/it]\u001b[32m[I 2020-03-24 13:54:24,263]\u001b[0m Finished trial#4 resulted in value: 1.2871623062138486. Current best value is 1.2813883921028735 with parameters: {'feature_fraction': 0.7}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.281388:  71%|#######1  | 5/7 [00:05<00:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.671021\tvalid's rmse: 1.36212\n",
      "[200]\ttrain's rmse: 0.476094\tvalid's rmse: 1.31703\n",
      "[300]\ttrain's rmse: 0.376739\tvalid's rmse: 1.2892\n",
      "[400]\ttrain's rmse: 0.319017\tvalid's rmse: 1.28408\n",
      "Early stopping, best iteration is:\n",
      "[375]\ttrain's rmse: 0.330303\tvalid's rmse: 1.28193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.281388:  86%|########5 | 6/7 [00:06<00:01,  1.16s/it]\u001b[32m[I 2020-03-24 13:54:25,391]\u001b[0m Finished trial#5 resulted in value: 1.2819345942423312. Current best value is 1.2813883921028735 with parameters: {'feature_fraction': 0.7}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.281388:  86%|########5 | 6/7 [00:06<00:01,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.67137\tvalid's rmse: 1.32282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.281388: 100%|##########| 7/7 [00:07<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain's rmse: 0.477038\tvalid's rmse: 1.30453\n",
      "[300]\ttrain's rmse: 0.377769\tvalid's rmse: 1.29169\n",
      "[400]\ttrain's rmse: 0.320991\tvalid's rmse: 1.29364\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttrain's rmse: 0.358083\tvalid's rmse: 1.28973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:26,010]\u001b[0m Finished trial#6 resulted in value: 1.289725108335747. Current best value is 1.2813883921028735 with parameters: {'feature_fraction': 0.7}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.281388: 100%|##########| 7/7 [00:07<00:00,  1.02s/it]\n",
      "tune_num_leaves, val_score: 1.281388:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.281388:   5%|5         | 1/20 [00:00<00:15,  1.20it/s]\u001b[32m[I 2020-03-24 13:54:26,941]\u001b[0m Finished trial#0 resulted in value: 1.2813883921028735. Current best value is 1.2813883921028735 with parameters: {'num_leaves': 155}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.281388:   5%|5         | 1/20 [00:00<00:15,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.281388:  10%|#         | 2/20 [00:01<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:27,720]\u001b[0m Finished trial#1 resulted in value: 1.2813883921028735. Current best value is 1.2813883921028735 with parameters: {'num_leaves': 155}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.281388:  10%|#         | 2/20 [00:01<00:14,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.281388:  15%|#5        | 3/20 [00:02<00:13,  1.22it/s]\u001b[32m[I 2020-03-24 13:54:28,543]\u001b[0m Finished trial#2 resulted in value: 1.2813883921028735. Current best value is 1.2813883921028735 with parameters: {'num_leaves': 155}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.281388:  15%|#5        | 3/20 [00:02<00:13,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.281388:  20%|##        | 4/20 [00:03<00:13,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:29,386]\u001b[0m Finished trial#3 resulted in value: 1.2813883921028735. Current best value is 1.2813883921028735 with parameters: {'num_leaves': 155}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.281388:  20%|##        | 4/20 [00:03<00:13,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.716005\tvalid's rmse: 1.35427\n",
      "[200]\ttrain's rmse: 0.50968\tvalid's rmse: 1.31361\n",
      "[300]\ttrain's rmse: 0.40913\tvalid's rmse: 1.29267\n",
      "[400]\ttrain's rmse: 0.34942\tvalid's rmse: 1.27951\n",
      "[500]\ttrain's rmse: 0.308682\tvalid's rmse: 1.27782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.275692:  25%|##5       | 5/20 [00:03<00:11,  1.28it/s]\u001b[32m[I 2020-03-24 13:54:30,057]\u001b[0m Finished trial#4 resulted in value: 1.2756915029917772. Current best value is 1.2756915029917772 with parameters: {'num_leaves': 22}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.275692:  25%|##5       | 5/20 [00:04<00:11,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[467]\ttrain's rmse: 0.319666\tvalid's rmse: 1.27569\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.275692:  30%|###       | 6/20 [00:04<00:11,  1.20it/s]\u001b[32m[I 2020-03-24 13:54:31,012]\u001b[0m Finished trial#5 resulted in value: 1.2813883921028735. Current best value is 1.2756915029917772 with parameters: {'num_leaves': 22}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.275692:  30%|###       | 6/20 [00:04<00:11,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.560823\tvalid's rmse: 1.27655\n",
      "[300]\ttrain's rmse: 0.465161\tvalid's rmse: 1.24608\n",
      "[400]\ttrain's rmse: 0.402823\tvalid's rmse: 1.23529\n",
      "[500]\ttrain's rmse: 0.357473\tvalid's rmse: 1.23515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  35%|###5      | 7/20 [00:05<00:09,  1.35it/s]\u001b[32m[I 2020-03-24 13:54:31,533]\u001b[0m Finished trial#6 resulted in value: 1.2332035849167224. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  35%|###5      | 7/20 [00:05<00:09,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.324919\tvalid's rmse: 1.23515\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttrain's rmse: 0.352458\tvalid's rmse: 1.2332\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  40%|####      | 8/20 [00:06<00:09,  1.24it/s]\u001b[32m[I 2020-03-24 13:54:32,501]\u001b[0m Finished trial#7 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  40%|####      | 8/20 [00:06<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  45%|####5     | 9/20 [00:07<00:09,  1.20it/s]\u001b[32m[I 2020-03-24 13:54:33,397]\u001b[0m Finished trial#8 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  45%|####5     | 9/20 [00:07<00:09,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  50%|#####     | 10/20 [00:08<00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:34,367]\u001b[0m Finished trial#9 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  50%|#####     | 10/20 [00:08<00:08,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  55%|#####5    | 11/20 [00:09<00:08,  1.12it/s]\u001b[32m[I 2020-03-24 13:54:35,312]\u001b[0m Finished trial#10 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  55%|#####5    | 11/20 [00:09<00:08,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.35804\tvalid's rmse: 1.701\n",
      "[200]\ttrain's rmse: 1.20393\tvalid's rmse: 1.61125\n",
      "[300]\ttrain's rmse: 1.12536\tvalid's rmse: 1.57784\n",
      "[400]\ttrain's rmse: 1.07643\tvalid's rmse: 1.55016\n",
      "[500]\ttrain's rmse: 1.01954\tvalid's rmse: 1.48857\n",
      "[600]\ttrain's rmse: 0.989921\tvalid's rmse: 1.47292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  60%|######    | 12/20 [00:09<00:06,  1.31it/s]\u001b[32m[I 2020-03-24 13:54:35,775]\u001b[0m Finished trial#11 resulted in value: 1.420514466639014. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  60%|######    | 12/20 [00:09<00:06,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain's rmse: 0.966137\tvalid's rmse: 1.46389\n",
      "[800]\ttrain's rmse: 0.938619\tvalid's rmse: 1.45093\n",
      "[900]\ttrain's rmse: 0.919288\tvalid's rmse: 1.44342\n",
      "[1000]\ttrain's rmse: 0.89793\tvalid's rmse: 1.42051\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.89793\tvalid's rmse: 1.42051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.35804\tvalid's rmse: 1.701\n",
      "[200]\ttrain's rmse: 1.20393\tvalid's rmse: 1.61125\n",
      "[300]\ttrain's rmse: 1.12536\tvalid's rmse: 1.57784\n",
      "[400]\ttrain's rmse: 1.07643\tvalid's rmse: 1.55016\n",
      "[500]\ttrain's rmse: 1.01954\tvalid's rmse: 1.48857\n",
      "[600]\ttrain's rmse: 0.989921\tvalid's rmse: 1.47292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  65%|######5   | 13/20 [00:10<00:04,  1.48it/s]\u001b[32m[I 2020-03-24 13:54:36,238]\u001b[0m Finished trial#12 resulted in value: 1.420514466639014. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  65%|######5   | 13/20 [00:10<00:04,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain's rmse: 0.966137\tvalid's rmse: 1.46389\n",
      "[800]\ttrain's rmse: 0.938619\tvalid's rmse: 1.45093\n",
      "[900]\ttrain's rmse: 0.919288\tvalid's rmse: 1.44342\n",
      "[1000]\ttrain's rmse: 0.89793\tvalid's rmse: 1.42051\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.89793\tvalid's rmse: 1.42051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  70%|#######   | 14/20 [00:11<00:04,  1.29it/s]\u001b[32m[I 2020-03-24 13:54:37,246]\u001b[0m Finished trial#13 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  70%|#######   | 14/20 [00:11<00:04,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.714855\tvalid's rmse: 1.36357\n",
      "[200]\ttrain's rmse: 0.522436\tvalid's rmse: 1.30429\n",
      "[300]\ttrain's rmse: 0.42219\tvalid's rmse: 1.28261\n",
      "[400]\ttrain's rmse: 0.361588\tvalid's rmse: 1.27888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  75%|#######5  | 15/20 [00:11<00:03,  1.45it/s]\u001b[32m[I 2020-03-24 13:54:37,737]\u001b[0m Finished trial#14 resulted in value: 1.2748154677074752. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  75%|#######5  | 15/20 [00:11<00:03,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[361]\ttrain's rmse: 0.382346\tvalid's rmse: 1.27482\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  80%|########  | 16/20 [00:12<00:03,  1.29it/s]\u001b[32m[I 2020-03-24 13:54:38,701]\u001b[0m Finished trial#15 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  80%|########  | 16/20 [00:12<00:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.14661\tvalid's rmse: 1.55149\n",
      "[200]\ttrain's rmse: 0.993384\tvalid's rmse: 1.43999\n",
      "[300]\ttrain's rmse: 0.906413\tvalid's rmse: 1.37382\n",
      "[400]\ttrain's rmse: 0.852016\tvalid's rmse: 1.34808\n",
      "[500]\ttrain's rmse: 0.806986\tvalid's rmse: 1.32101\n",
      "[600]\ttrain's rmse: 0.768989\tvalid's rmse: 1.29825\n",
      "[700]\ttrain's rmse: 0.731337\tvalid's rmse: 1.28027\n",
      "[800]\ttrain's rmse: 0.697774\tvalid's rmse: 1.2591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  85%|########5 | 17/20 [00:13<00:02,  1.44it/s]\u001b[32m[I 2020-03-24 13:54:39,210]\u001b[0m Finished trial#16 resulted in value: 1.2447847959206733. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  85%|########5 | 17/20 [00:13<00:02,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttrain's rmse: 0.673914\tvalid's rmse: 1.25293\n",
      "[1000]\ttrain's rmse: 0.652759\tvalid's rmse: 1.24478\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.652759\tvalid's rmse: 1.24478\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  90%|######### | 18/20 [00:14<00:01,  1.24it/s]\u001b[32m[I 2020-03-24 13:54:40,292]\u001b[0m Finished trial#17 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  90%|######### | 18/20 [00:14<00:01,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204:  95%|#########5| 19/20 [00:15<00:00,  1.17it/s]\u001b[32m[I 2020-03-24 13:54:41,250]\u001b[0m Finished trial#18 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204:  95%|#########5| 19/20 [00:15<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.717645\tvalid's rmse: 1.38432\n",
      "[200]\ttrain's rmse: 0.517392\tvalid's rmse: 1.31985\n",
      "[300]\ttrain's rmse: 0.41676\tvalid's rmse: 1.2951\n",
      "[400]\ttrain's rmse: 0.355695\tvalid's rmse: 1.28678\n",
      "[500]\ttrain's rmse: 0.314579\tvalid's rmse: 1.2844\n",
      "[600]\ttrain's rmse: 0.28891\tvalid's rmse: 1.28235\n",
      "Early stopping, best iteration is:\n",
      "[592]\ttrain's rmse: 0.290248\tvalid's rmse: 1.28139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_num_leaves, val_score: 1.233204: 100%|##########| 20/20 [00:16<00:00,  1.14it/s]\u001b[32m[I 2020-03-24 13:54:42,190]\u001b[0m Finished trial#19 resulted in value: 1.2813883921028735. Current best value is 1.2332035849167224 with parameters: {'num_leaves': 13}.\u001b[0m\n",
      "tune_num_leaves, val_score: 1.233204: 100%|##########| 20/20 [00:16<00:00,  1.24it/s]\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.14021\tvalid's rmse: 1.64909\n",
      "[200]\ttrain's rmse: 0.973407\tvalid's rmse: 1.54765\n",
      "[300]\ttrain's rmse: 0.859502\tvalid's rmse: 1.52008\n",
      "[400]\ttrain's rmse: 0.764307\tvalid's rmse: 1.47699\n",
      "[500]\ttrain's rmse: 0.686287\tvalid's rmse: 1.44323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  10%|#         | 1/10 [00:00<00:05,  1.78it/s]\u001b[32m[I 2020-03-24 13:54:42,842]\u001b[0m Finished trial#0 resulted in value: 1.435463251970977. Current best value is 1.435463251970977 with parameters: {'bagging_fraction': 0.5071550666486464, 'bagging_freq': 5}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  10%|#         | 1/10 [00:00<00:05,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.637621\tvalid's rmse: 1.43877\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttrain's rmse: 0.685252\tvalid's rmse: 1.43546\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.26874\tvalid's rmse: 1.74715\n",
      "[200]\ttrain's rmse: 1.08343\tvalid's rmse: 1.64206\n",
      "[300]\ttrain's rmse: 0.98726\tvalid's rmse: 1.60836\n",
      "[400]\ttrain's rmse: 0.920905\tvalid's rmse: 1.5473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  20%|##        | 2/10 [00:01<00:04,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain's rmse: 0.856072\tvalid's rmse: 1.5107\n",
      "[600]\ttrain's rmse: 0.812588\tvalid's rmse: 1.50099\n",
      "Early stopping, best iteration is:\n",
      "[561]\ttrain's rmse: 0.827639\tvalid's rmse: 1.49227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:43,513]\u001b[0m Finished trial#1 resulted in value: 1.4922681369539574. Current best value is 1.435463251970977 with parameters: {'bagging_fraction': 0.5071550666486464, 'bagging_freq': 5}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  20%|##        | 2/10 [00:01<00:04,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.18979\tvalid's rmse: 1.67416\n",
      "[200]\ttrain's rmse: 1.02377\tvalid's rmse: 1.57579\n",
      "[300]\ttrain's rmse: 0.907227\tvalid's rmse: 1.54118\n",
      "[400]\ttrain's rmse: 0.810901\tvalid's rmse: 1.49447\n",
      "[500]\ttrain's rmse: 0.741816\tvalid's rmse: 1.44236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  30%|###       | 3/10 [00:01<00:04,  1.62it/s]\u001b[32m[I 2020-03-24 13:54:44,187]\u001b[0m Finished trial#2 resulted in value: 1.4358127207108455. Current best value is 1.435463251970977 with parameters: {'bagging_fraction': 0.5071550666486464, 'bagging_freq': 5}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  30%|###       | 3/10 [00:01<00:04,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.697594\tvalid's rmse: 1.4496\n",
      "Early stopping, best iteration is:\n",
      "[505]\ttrain's rmse: 0.740767\tvalid's rmse: 1.43581\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.796086\tvalid's rmse: 1.38173\n",
      "[200]\ttrain's rmse: 0.596058\tvalid's rmse: 1.2863\n",
      "[300]\ttrain's rmse: 0.493969\tvalid's rmse: 1.27003\n",
      "[400]\ttrain's rmse: 0.423114\tvalid's rmse: 1.26741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  40%|####      | 4/10 [00:02<00:03,  1.73it/s]\u001b[32m[I 2020-03-24 13:54:44,672]\u001b[0m Finished trial#3 resulted in value: 1.2595822934114822. Current best value is 1.2595822934114822 with parameters: {'bagging_fraction': 0.8736983045326786, 'bagging_freq': 4}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  40%|####      | 4/10 [00:02<00:03,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain's rmse: 0.372867\tvalid's rmse: 1.26483\n",
      "Early stopping, best iteration is:\n",
      "[424]\ttrain's rmse: 0.408512\tvalid's rmse: 1.25958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.13788\tvalid's rmse: 1.66803\n",
      "[200]\ttrain's rmse: 0.921076\tvalid's rmse: 1.53536\n",
      "[300]\ttrain's rmse: 0.813915\tvalid's rmse: 1.52309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  50%|#####     | 5/10 [00:02<00:02,  1.80it/s]\u001b[32m[I 2020-03-24 13:54:45,177]\u001b[0m Finished trial#4 resulted in value: 1.4924259266036815. Current best value is 1.2595822934114822 with parameters: {'bagging_fraction': 0.8736983045326786, 'bagging_freq': 4}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  50%|#####     | 5/10 [00:02<00:02,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.729942\tvalid's rmse: 1.50299\n",
      "Early stopping, best iteration is:\n",
      "[330]\ttrain's rmse: 0.791202\tvalid's rmse: 1.49243\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  60%|######    | 6/10 [00:03<00:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's rmse: 1.03916\tvalid's rmse: 1.59748\n",
      "[200]\ttrain's rmse: 0.844201\tvalid's rmse: 1.51015\n",
      "[300]\ttrain's rmse: 0.720369\tvalid's rmse: 1.48515\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttrain's rmse: 0.808119\tvalid's rmse: 1.47944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:45,557]\u001b[0m Finished trial#5 resulted in value: 1.4794385174902123. Current best value is 1.2595822934114822 with parameters: {'bagging_fraction': 0.8736983045326786, 'bagging_freq': 4}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  60%|######    | 6/10 [00:03<00:02,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.03849\tvalid's rmse: 1.60099\n",
      "[200]\ttrain's rmse: 0.840137\tvalid's rmse: 1.5051\n",
      "[300]\ttrain's rmse: 0.718471\tvalid's rmse: 1.46708\n",
      "[400]\ttrain's rmse: 0.624914\tvalid's rmse: 1.46126\n",
      "[500]\ttrain's rmse: 0.557465\tvalid's rmse: 1.45617\n",
      "[600]\ttrain's rmse: 0.510534\tvalid's rmse: 1.43809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  70%|#######   | 7/10 [00:03<00:01,  1.75it/s]\u001b[32m[I 2020-03-24 13:54:46,288]\u001b[0m Finished trial#6 resulted in value: 1.428821544144198. Current best value is 1.2595822934114822 with parameters: {'bagging_fraction': 0.8736983045326786, 'bagging_freq': 4}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  70%|#######   | 7/10 [00:04<00:01,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain's rmse: 0.469192\tvalid's rmse: 1.44079\n",
      "Early stopping, best iteration is:\n",
      "[686]\ttrain's rmse: 0.473356\tvalid's rmse: 1.42882\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.865744\tvalid's rmse: 1.46437\n",
      "[200]\ttrain's rmse: 0.668563\tvalid's rmse: 1.39712\n",
      "[300]\ttrain's rmse: 0.556511\tvalid's rmse: 1.34948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  80%|########  | 8/10 [00:04<00:01,  1.84it/s]\u001b[32m[I 2020-03-24 13:54:46,778]\u001b[0m Finished trial#7 resulted in value: 1.325098085963088. Current best value is 1.2595822934114822 with parameters: {'bagging_fraction': 0.8736983045326786, 'bagging_freq': 4}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.477279\tvalid's rmse: 1.34286\n",
      "[500]\ttrain's rmse: 0.421065\tvalid's rmse: 1.33244\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttrain's rmse: 0.437842\tvalid's rmse: 1.3251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  80%|########  | 8/10 [00:04<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.14865\tvalid's rmse: 1.62891\n",
      "[200]\ttrain's rmse: 0.96641\tvalid's rmse: 1.53519\n",
      "[300]\ttrain's rmse: 0.86287\tvalid's rmse: 1.52045\n",
      "[400]\ttrain's rmse: 0.77608\tvalid's rmse: 1.49478\n",
      "[500]\ttrain's rmse: 0.71774\tvalid's rmse: 1.44984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  90%|######### | 9/10 [00:05<00:00,  1.50it/s]\u001b[32m[I 2020-03-24 13:54:47,720]\u001b[0m Finished trial#8 resulted in value: 1.4455060821402528. Current best value is 1.2595822934114822 with parameters: {'bagging_fraction': 0.8736983045326786, 'bagging_freq': 4}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204:  90%|######### | 9/10 [00:05<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrain's rmse: 0.664572\tvalid's rmse: 1.46625\n",
      "Early stopping, best iteration is:\n",
      "[502]\ttrain's rmse: 0.71753\tvalid's rmse: 1.44551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.10441\tvalid's rmse: 1.64775\n",
      "[200]\ttrain's rmse: 0.899709\tvalid's rmse: 1.53368\n",
      "[300]\ttrain's rmse: 0.786922\tvalid's rmse: 1.51614\n",
      "[400]\ttrain's rmse: 0.701024\tvalid's rmse: 1.48334\n",
      "[500]\ttrain's rmse: 0.627159\tvalid's rmse: 1.47048\n",
      "[600]\ttrain's rmse: 0.574212\tvalid's rmse: 1.45856\n",
      "[700]\ttrain's rmse: 0.531977\tvalid's rmse: 1.45151\n",
      "[800]\ttrain's rmse: 0.494162\tvalid's rmse: 1.44247\n",
      "[900]\ttrain's rmse: 0.462042\tvalid's rmse: 1.44049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204: 100%|##########| 10/10 [00:06<00:00,  1.28it/s]\u001b[32m[I 2020-03-24 13:54:48,771]\u001b[0m Finished trial#9 resulted in value: 1.4325884832511369. Current best value is 1.2595822934114822 with parameters: {'bagging_fraction': 0.8736983045326786, 'bagging_freq': 4}.\u001b[0m\n",
      "tune_bagging_fraction_and_bagging_freq, val_score: 1.233204: 100%|##########| 10/10 [00:06<00:00,  1.52it/s]\n",
      "tune_feature_fraction, val_score: 1.233204:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttrain's rmse: 0.43527\tvalid's rmse: 1.43259\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.43527\tvalid's rmse: 1.43259\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.764471\tvalid's rmse: 1.36437\n",
      "[200]\ttrain's rmse: 0.577671\tvalid's rmse: 1.30294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.233204:  17%|#6        | 1/6 [00:00<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 0.47907\tvalid's rmse: 1.26606\n",
      "[400]\ttrain's rmse: 0.4144\tvalid's rmse: 1.2414\n",
      "[500]\ttrain's rmse: 0.366076\tvalid's rmse: 1.23705\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttrain's rmse: 0.378714\tvalid's rmse: 1.23615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:49,274]\u001b[0m Finished trial#0 resulted in value: 1.236149274657578. Current best value is 1.236149274657578 with parameters: {'feature_fraction': 0.62}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.233204:  17%|#6        | 1/6 [00:00<00:02,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.764471\tvalid's rmse: 1.36437\n",
      "[200]\ttrain's rmse: 0.577671\tvalid's rmse: 1.30294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.233204:  33%|###3      | 2/6 [00:00<00:01,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 0.47907\tvalid's rmse: 1.26606\n",
      "[400]\ttrain's rmse: 0.4144\tvalid's rmse: 1.2414\n",
      "[500]\ttrain's rmse: 0.366076\tvalid's rmse: 1.23705\n",
      "Early stopping, best iteration is:\n",
      "[468]\ttrain's rmse: 0.378714\tvalid's rmse: 1.23615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:49,783]\u001b[0m Finished trial#1 resulted in value: 1.2361492746575777. Current best value is 1.2361492746575777 with parameters: {'feature_fraction': 0.652}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.233204:  33%|###3      | 2/6 [00:01<00:01,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.560823\tvalid's rmse: 1.27655\n",
      "[300]\ttrain's rmse: 0.465161\tvalid's rmse: 1.24608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.233204:  50%|#####     | 3/6 [00:01<00:01,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.402823\tvalid's rmse: 1.23529\n",
      "[500]\ttrain's rmse: 0.357473\tvalid's rmse: 1.23515\n",
      "[600]\ttrain's rmse: 0.324919\tvalid's rmse: 1.23515\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttrain's rmse: 0.352458\tvalid's rmse: 1.2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:50,299]\u001b[0m Finished trial#2 resulted in value: 1.2332035849167224. Current best value is 1.2332035849167224 with parameters: {'feature_fraction': 0.6839999999999999}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.233204:  50%|#####     | 3/6 [00:01<00:01,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.560823\tvalid's rmse: 1.27655\n",
      "[300]\ttrain's rmse: 0.465161\tvalid's rmse: 1.24608\n",
      "[400]\ttrain's rmse: 0.402823\tvalid's rmse: 1.23529\n",
      "[500]\ttrain's rmse: 0.357473\tvalid's rmse: 1.23515\n",
      "[600]\ttrain's rmse: 0.324919\tvalid's rmse: 1.23515\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttrain's rmse: 0.352458\tvalid's rmse: 1.2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.233204:  67%|######6   | 4/6 [00:01<00:00,  2.06it/s]\u001b[32m[I 2020-03-24 13:54:50,836]\u001b[0m Finished trial#3 resulted in value: 1.2332035849167224. Current best value is 1.2332035849167224 with parameters: {'feature_fraction': 0.6839999999999999}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.233204:  67%|######6   | 4/6 [00:02<00:00,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.560823\tvalid's rmse: 1.27655\n",
      "[300]\ttrain's rmse: 0.465161\tvalid's rmse: 1.24608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.233204:  83%|########3 | 5/6 [00:02<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.402823\tvalid's rmse: 1.23529\n",
      "[500]\ttrain's rmse: 0.357473\tvalid's rmse: 1.23515\n",
      "[600]\ttrain's rmse: 0.324919\tvalid's rmse: 1.23515\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttrain's rmse: 0.352458\tvalid's rmse: 1.2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:51,315]\u001b[0m Finished trial#4 resulted in value: 1.2332035849167224. Current best value is 1.2332035849167224 with parameters: {'feature_fraction': 0.6839999999999999}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.233204:  83%|########3 | 5/6 [00:02<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.747998\tvalid's rmse: 1.39456\n",
      "[200]\ttrain's rmse: 0.551592\tvalid's rmse: 1.30786\n",
      "[300]\ttrain's rmse: 0.445147\tvalid's rmse: 1.27474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_feature_fraction, val_score: 1.233204: 100%|##########| 6/6 [00:02<00:00,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.38224\tvalid's rmse: 1.27125\n",
      "[500]\ttrain's rmse: 0.340901\tvalid's rmse: 1.26285\n",
      "Early stopping, best iteration is:\n",
      "[489]\ttrain's rmse: 0.344153\tvalid's rmse: 1.26176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:51,850]\u001b[0m Finished trial#5 resulted in value: 1.2617632675234571. Current best value is 1.2332035849167224 with parameters: {'feature_fraction': 0.6839999999999999}.\u001b[0m\n",
      "tune_feature_fraction, val_score: 1.233204: 100%|##########| 6/6 [00:03<00:00,  1.95it/s]\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.744553\tvalid's rmse: 1.34577\n",
      "[200]\ttrain's rmse: 0.562517\tvalid's rmse: 1.28894\n",
      "[300]\ttrain's rmse: 0.461208\tvalid's rmse: 1.26102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:   5%|5         | 1/20 [00:00<00:07,  2.56it/s]\u001b[32m[I 2020-03-24 13:54:52,338]\u001b[0m Finished trial#0 resulted in value: 1.2399063466217632. Current best value is 1.2399063466217632 with parameters: {'lambda_l1': 3.839647652682402e-06, 'lambda_l2': 2.7007259484128036e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:   5%|5         | 1/20 [00:00<00:07,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.396358\tvalid's rmse: 1.24298\n",
      "[500]\ttrain's rmse: 0.353061\tvalid's rmse: 1.24158\n",
      "Early stopping, best iteration is:\n",
      "[434]\ttrain's rmse: 0.380567\tvalid's rmse: 1.23991\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.750754\tvalid's rmse: 1.36699\n",
      "[200]\ttrain's rmse: 0.567375\tvalid's rmse: 1.32024\n",
      "[300]\ttrain's rmse: 0.464335\tvalid's rmse: 1.2832\n",
      "[400]\ttrain's rmse: 0.401468\tvalid's rmse: 1.26456\n",
      "[500]\ttrain's rmse: 0.355722\tvalid's rmse: 1.26482\n",
      "Early stopping, best iteration is:\n",
      "[416]\ttrain's rmse: 0.392919\tvalid's rmse: 1.26228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  10%|#         | 2/20 [00:00<00:07,  2.47it/s]\u001b[32m[I 2020-03-24 13:54:52,776]\u001b[0m Finished trial#1 resulted in value: 1.2622813512074618. Current best value is 1.2399063466217632 with parameters: {'lambda_l1': 3.839647652682402e-06, 'lambda_l2': 2.7007259484128036e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  10%|#         | 2/20 [00:00<00:07,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.739097\tvalid's rmse: 1.36329\n",
      "[200]\ttrain's rmse: 0.55784\tvalid's rmse: 1.30593\n",
      "[300]\ttrain's rmse: 0.460363\tvalid's rmse: 1.26887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  15%|#5        | 3/20 [00:01<00:07,  2.34it/s]\u001b[32m[I 2020-03-24 13:54:53,255]\u001b[0m Finished trial#2 resulted in value: 1.2391551072145601. Current best value is 1.2391551072145601 with parameters: {'lambda_l1': 0.00020662839003372855, 'lambda_l2': 0.1801451761997221}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.397107\tvalid's rmse: 1.25263\n",
      "[500]\ttrain's rmse: 0.35247\tvalid's rmse: 1.24495\n",
      "Early stopping, best iteration is:\n",
      "[472]\ttrain's rmse: 0.36224\tvalid's rmse: 1.23916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  15%|#5        | 3/20 [00:01<00:07,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.757554\tvalid's rmse: 1.36653\n",
      "[200]\ttrain's rmse: 0.564251\tvalid's rmse: 1.29833\n",
      "[300]\ttrain's rmse: 0.467654\tvalid's rmse: 1.25994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  20%|##        | 4/20 [00:01<00:07,  2.27it/s]\u001b[32m[I 2020-03-24 13:54:53,722]\u001b[0m Finished trial#3 resulted in value: 1.241305058690631. Current best value is 1.2391551072145601 with parameters: {'lambda_l1': 0.00020662839003372855, 'lambda_l2': 0.1801451761997221}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  20%|##        | 4/20 [00:01<00:07,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.402255\tvalid's rmse: 1.24607\n",
      "[500]\ttrain's rmse: 0.357952\tvalid's rmse: 1.24378\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttrain's rmse: 0.37218\tvalid's rmse: 1.24131\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.757553\tvalid's rmse: 1.36653\n",
      "[200]\ttrain's rmse: 0.56425\tvalid's rmse: 1.29833\n",
      "[300]\ttrain's rmse: 0.467654\tvalid's rmse: 1.25994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  25%|##5       | 5/20 [00:02<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.402255\tvalid's rmse: 1.24607\n",
      "[500]\ttrain's rmse: 0.357952\tvalid's rmse: 1.24378\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttrain's rmse: 0.37218\tvalid's rmse: 1.24131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:54,246]\u001b[0m Finished trial#4 resulted in value: 1.2413050790134843. Current best value is 1.2391551072145601 with parameters: {'lambda_l1': 0.00020662839003372855, 'lambda_l2': 0.1801451761997221}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  25%|##5       | 5/20 [00:02<00:06,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754646\tvalid's rmse: 1.36438\n",
      "[200]\ttrain's rmse: 0.569384\tvalid's rmse: 1.31568\n",
      "[300]\ttrain's rmse: 0.46941\tvalid's rmse: 1.27446\n",
      "[400]\ttrain's rmse: 0.409545\tvalid's rmse: 1.25903\n",
      "[500]\ttrain's rmse: 0.366521\tvalid's rmse: 1.25191\n",
      "[600]\ttrain's rmse: 0.334084\tvalid's rmse: 1.252\n",
      "[700]\ttrain's rmse: 0.311332\tvalid's rmse: 1.24918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  30%|###       | 6/20 [00:02<00:07,  1.88it/s]\u001b[32m[I 2020-03-24 13:54:54,935]\u001b[0m Finished trial#5 resulted in value: 1.2487079293448569. Current best value is 1.2391551072145601 with parameters: {'lambda_l1': 0.00020662839003372855, 'lambda_l2': 0.1801451761997221}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.233204:  30%|###       | 6/20 [00:03<00:07,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800]\ttrain's rmse: 0.293994\tvalid's rmse: 1.25191\n",
      "Early stopping, best iteration is:\n",
      "[707]\ttrain's rmse: 0.309995\tvalid's rmse: 1.24871\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.561107\tvalid's rmse: 1.27865\n",
      "[300]\ttrain's rmse: 0.462679\tvalid's rmse: 1.24169\n",
      "[400]\ttrain's rmse: 0.401197\tvalid's rmse: 1.23274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  35%|###5      | 7/20 [00:03<00:07,  1.85it/s]\u001b[32m[I 2020-03-24 13:54:55,491]\u001b[0m Finished trial#6 resulted in value: 1.2238636620069248. Current best value is 1.2238636620069248 with parameters: {'lambda_l1': 1.0889545032564084e-06, 'lambda_l2': 2.0856119619157083e-06}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain's rmse: 0.356771\tvalid's rmse: 1.22516\n",
      "[600]\ttrain's rmse: 0.325104\tvalid's rmse: 1.22706\n",
      "Early stopping, best iteration is:\n",
      "[508]\ttrain's rmse: 0.353579\tvalid's rmse: 1.22386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  35%|###5      | 7/20 [00:03<00:07,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.779927\tvalid's rmse: 1.40188\n",
      "[200]\ttrain's rmse: 0.621737\tvalid's rmse: 1.34473\n",
      "[300]\ttrain's rmse: 0.538438\tvalid's rmse: 1.32209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  40%|####      | 8/20 [00:04<00:06,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.485968\tvalid's rmse: 1.30583\n",
      "[500]\ttrain's rmse: 0.445665\tvalid's rmse: 1.30214\n",
      "[600]\ttrain's rmse: 0.425693\tvalid's rmse: 1.30085\n",
      "Early stopping, best iteration is:\n",
      "[564]\ttrain's rmse: 0.427849\tvalid's rmse: 1.29955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:56,054]\u001b[0m Finished trial#7 resulted in value: 1.2995521139514852. Current best value is 1.2238636620069248 with parameters: {'lambda_l1': 1.0889545032564084e-06, 'lambda_l2': 2.0856119619157083e-06}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  40%|####      | 8/20 [00:04<00:06,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.788776\tvalid's rmse: 1.39397\n",
      "[200]\ttrain's rmse: 0.600806\tvalid's rmse: 1.33791\n",
      "[300]\ttrain's rmse: 0.497545\tvalid's rmse: 1.29516\n",
      "[400]\ttrain's rmse: 0.432457\tvalid's rmse: 1.27015\n",
      "[500]\ttrain's rmse: 0.38181\tvalid's rmse: 1.26033\n",
      "[600]\ttrain's rmse: 0.347971\tvalid's rmse: 1.25795\n",
      "[700]\ttrain's rmse: 0.322229\tvalid's rmse: 1.25436\n",
      "[800]\ttrain's rmse: 0.301431\tvalid's rmse: 1.25349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  45%|####5     | 9/20 [00:04<00:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttrain's rmse: 0.28534\tvalid's rmse: 1.24982\n",
      "[1000]\ttrain's rmse: 0.272195\tvalid's rmse: 1.24828\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.272195\tvalid's rmse: 1.24828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:56,866]\u001b[0m Finished trial#8 resulted in value: 1.2482768636223893. Current best value is 1.2238636620069248 with parameters: {'lambda_l1': 1.0889545032564084e-06, 'lambda_l2': 2.0856119619157083e-06}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  45%|####5     | 9/20 [00:05<00:06,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.561107\tvalid's rmse: 1.27865\n",
      "[300]\ttrain's rmse: 0.462679\tvalid's rmse: 1.24169\n",
      "[400]\ttrain's rmse: 0.401197\tvalid's rmse: 1.23274\n",
      "[500]\ttrain's rmse: 0.356771\tvalid's rmse: 1.22516\n",
      "[600]\ttrain's rmse: 0.325118\tvalid's rmse: 1.22594\n",
      "Early stopping, best iteration is:\n",
      "[508]\ttrain's rmse: 0.353579\tvalid's rmse: 1.22386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  50%|#####     | 10/20 [00:05<00:06,  1.63it/s]\u001b[32m[I 2020-03-24 13:54:57,453]\u001b[0m Finished trial#9 resulted in value: 1.2238636578325388. Current best value is 1.2238636578325388 with parameters: {'lambda_l1': 5.6146079110789515e-08, 'lambda_l2': 3.427415135437599e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  50%|#####     | 10/20 [00:05<00:06,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.560823\tvalid's rmse: 1.27655\n",
      "[300]\ttrain's rmse: 0.465161\tvalid's rmse: 1.24608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  55%|#####5    | 11/20 [00:06<00:05,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.402823\tvalid's rmse: 1.23529\n",
      "[500]\ttrain's rmse: 0.357473\tvalid's rmse: 1.23515\n",
      "[600]\ttrain's rmse: 0.324919\tvalid's rmse: 1.23515\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttrain's rmse: 0.352458\tvalid's rmse: 1.2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:57,987]\u001b[0m Finished trial#10 resulted in value: 1.2332035850970597. Current best value is 1.2238636578325388 with parameters: {'lambda_l1': 5.6146079110789515e-08, 'lambda_l2': 3.427415135437599e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  55%|#####5    | 11/20 [00:06<00:05,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.560823\tvalid's rmse: 1.27655\n",
      "[300]\ttrain's rmse: 0.465161\tvalid's rmse: 1.24608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  60%|######    | 12/20 [00:06<00:04,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.402823\tvalid's rmse: 1.23529\n",
      "[500]\ttrain's rmse: 0.357473\tvalid's rmse: 1.23515\n",
      "[600]\ttrain's rmse: 0.324919\tvalid's rmse: 1.23515\n",
      "Early stopping, best iteration is:\n",
      "[511]\ttrain's rmse: 0.352458\tvalid's rmse: 1.2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:58,498]\u001b[0m Finished trial#11 resulted in value: 1.2332035852013874. Current best value is 1.2238636578325388 with parameters: {'lambda_l1': 5.6146079110789515e-08, 'lambda_l2': 3.427415135437599e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  60%|######    | 12/20 [00:06<00:04,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.757547\tvalid's rmse: 1.36653\n",
      "[200]\ttrain's rmse: 0.564244\tvalid's rmse: 1.29833\n",
      "[300]\ttrain's rmse: 0.465773\tvalid's rmse: 1.26706\n",
      "[400]\ttrain's rmse: 0.401011\tvalid's rmse: 1.25705\n",
      "[500]\ttrain's rmse: 0.355385\tvalid's rmse: 1.24947\n",
      "[600]\ttrain's rmse: 0.323417\tvalid's rmse: 1.24669\n",
      "[700]\ttrain's rmse: 0.299698\tvalid's rmse: 1.24623\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttrain's rmse: 0.313585\tvalid's rmse: 1.24247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  65%|######5   | 13/20 [00:07<00:04,  1.74it/s]\u001b[32m[I 2020-03-24 13:54:59,102]\u001b[0m Finished trial#12 resulted in value: 1.2424708639174336. Current best value is 1.2238636578325388 with parameters: {'lambda_l1': 5.6146079110789515e-08, 'lambda_l2': 3.427415135437599e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  65%|######5   | 13/20 [00:07<00:04,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.561107\tvalid's rmse: 1.27865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  70%|#######   | 14/20 [00:07<00:03,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\ttrain's rmse: 0.462679\tvalid's rmse: 1.24169\n",
      "[400]\ttrain's rmse: 0.401197\tvalid's rmse: 1.23274\n",
      "[500]\ttrain's rmse: 0.356771\tvalid's rmse: 1.22516\n",
      "[600]\ttrain's rmse: 0.325118\tvalid's rmse: 1.22594\n",
      "Early stopping, best iteration is:\n",
      "[508]\ttrain's rmse: 0.353579\tvalid's rmse: 1.22386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2020-03-24 13:54:59,633]\u001b[0m Finished trial#13 resulted in value: 1.2238636560782874. Current best value is 1.2238636560782874 with parameters: {'lambda_l1': 1.5900933084631792e-07, 'lambda_l2': 1.0321387512426268e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  70%|#######   | 14/20 [00:07<00:03,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.561107\tvalid's rmse: 1.27865\n",
      "[300]\ttrain's rmse: 0.462679\tvalid's rmse: 1.24169\n",
      "[400]\ttrain's rmse: 0.401197\tvalid's rmse: 1.23274\n",
      "[500]\ttrain's rmse: 0.356771\tvalid's rmse: 1.22516\n",
      "[600]\ttrain's rmse: 0.325118\tvalid's rmse: 1.22594\n",
      "Early stopping, best iteration is:\n",
      "[508]\ttrain's rmse: 0.353579\tvalid's rmse: 1.22386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  75%|#######5  | 15/20 [00:08<00:02,  1.81it/s]\u001b[32m[I 2020-03-24 13:55:00,162]\u001b[0m Finished trial#14 resulted in value: 1.223863658035248. Current best value is 1.2238636560782874 with parameters: {'lambda_l1': 1.5900933084631792e-07, 'lambda_l2': 1.0321387512426268e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  75%|#######5  | 15/20 [00:08<00:02,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754748\tvalid's rmse: 1.36609\n",
      "[200]\ttrain's rmse: 0.564177\tvalid's rmse: 1.29044\n",
      "[300]\ttrain's rmse: 0.464937\tvalid's rmse: 1.25282\n",
      "[400]\ttrain's rmse: 0.401612\tvalid's rmse: 1.24383\n",
      "[500]\ttrain's rmse: 0.357265\tvalid's rmse: 1.23291\n",
      "[600]\ttrain's rmse: 0.326871\tvalid's rmse: 1.23002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  80%|########  | 16/20 [00:08<00:02,  1.72it/s]\u001b[32m[I 2020-03-24 13:55:00,803]\u001b[0m Finished trial#15 resulted in value: 1.2283904144172129. Current best value is 1.2238636560782874 with parameters: {'lambda_l1': 1.5900933084631792e-07, 'lambda_l2': 1.0321387512426268e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  80%|########  | 16/20 [00:08<00:02,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain's rmse: 0.30466\tvalid's rmse: 1.22891\n",
      "Early stopping, best iteration is:\n",
      "[648]\ttrain's rmse: 0.315965\tvalid's rmse: 1.22839\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.757547\tvalid's rmse: 1.36653\n",
      "[200]\ttrain's rmse: 0.564244\tvalid's rmse: 1.29833\n",
      "[300]\ttrain's rmse: 0.465772\tvalid's rmse: 1.26706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  85%|########5 | 17/20 [00:09<00:01,  1.81it/s]\u001b[32m[I 2020-03-24 13:55:01,293]\u001b[0m Finished trial#16 resulted in value: 1.2530789333928387. Current best value is 1.2238636560782874 with parameters: {'lambda_l1': 1.5900933084631792e-07, 'lambda_l2': 1.0321387512426268e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  85%|########5 | 17/20 [00:09<00:01,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttrain's rmse: 0.401885\tvalid's rmse: 1.25762\n",
      "[500]\ttrain's rmse: 0.35748\tvalid's rmse: 1.25531\n",
      "Early stopping, best iteration is:\n",
      "[440]\ttrain's rmse: 0.383399\tvalid's rmse: 1.25308\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.754559\tvalid's rmse: 1.35355\n",
      "[200]\ttrain's rmse: 0.560823\tvalid's rmse: 1.27655\n",
      "[300]\ttrain's rmse: 0.465161\tvalid's rmse: 1.24608\n",
      "[400]\ttrain's rmse: 0.402659\tvalid's rmse: 1.23909\n",
      "[500]\ttrain's rmse: 0.356657\tvalid's rmse: 1.23114\n",
      "[600]\ttrain's rmse: 0.324432\tvalid's rmse: 1.23157\n",
      "Early stopping, best iteration is:\n",
      "[539]\ttrain's rmse: 0.341573\tvalid's rmse: 1.23001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  90%|######### | 18/20 [00:09<00:01,  1.80it/s]\u001b[32m[I 2020-03-24 13:55:01,857]\u001b[0m Finished trial#17 resulted in value: 1.2300101123103993. Current best value is 1.2238636560782874 with parameters: {'lambda_l1': 1.5900933084631792e-07, 'lambda_l2': 1.0321387512426268e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  90%|######### | 18/20 [00:10<00:01,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.757548\tvalid's rmse: 1.36653\n",
      "[200]\ttrain's rmse: 0.564246\tvalid's rmse: 1.29833\n",
      "[300]\ttrain's rmse: 0.464683\tvalid's rmse: 1.26908\n",
      "[400]\ttrain's rmse: 0.40089\tvalid's rmse: 1.25144\n",
      "[500]\ttrain's rmse: 0.355372\tvalid's rmse: 1.24504\n",
      "[600]\ttrain's rmse: 0.323093\tvalid's rmse: 1.24276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  95%|#########5| 19/20 [00:10<00:00,  1.69it/s]\u001b[32m[I 2020-03-24 13:55:02,530]\u001b[0m Finished trial#18 resulted in value: 1.2416689375225332. Current best value is 1.2238636560782874 with parameters: {'lambda_l1': 1.5900933084631792e-07, 'lambda_l2': 1.0321387512426268e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864:  95%|#########5| 19/20 [00:10<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[700]\ttrain's rmse: 0.300703\tvalid's rmse: 1.24376\n",
      "Early stopping, best iteration is:\n",
      "[633]\ttrain's rmse: 0.314399\tvalid's rmse: 1.24167\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.744554\tvalid's rmse: 1.34577\n",
      "[200]\ttrain's rmse: 0.562517\tvalid's rmse: 1.28894\n",
      "[300]\ttrain's rmse: 0.461208\tvalid's rmse: 1.26102\n",
      "[400]\ttrain's rmse: 0.396359\tvalid's rmse: 1.24298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864: 100%|##########| 20/20 [00:11<00:00,  1.74it/s]\u001b[32m[I 2020-03-24 13:55:03,064]\u001b[0m Finished trial#19 resulted in value: 1.2399062985499654. Current best value is 1.2238636560782874 with parameters: {'lambda_l1': 1.5900933084631792e-07, 'lambda_l2': 1.0321387512426268e-05}.\u001b[0m\n",
      "tune_lambda_l1_and_lambda_l2, val_score: 1.223864: 100%|##########| 20/20 [00:11<00:00,  1.78it/s]\n",
      "tune_min_child_samples, val_score: 1.223864:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttrain's rmse: 0.353062\tvalid's rmse: 1.24158\n",
      "Early stopping, best iteration is:\n",
      "[434]\ttrain's rmse: 0.380567\tvalid's rmse: 1.23991\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 1.081522:  20%|##        | 1/5 [00:00<00:00,  5.63it/s]\u001b[32m[I 2020-03-24 13:55:03,336]\u001b[0m Finished trial#0 resulted in value: 1.081522211838535. Current best value is 1.081522211838535 with parameters: {'min_child_samples': 5}.\u001b[0m\n",
      "tune_min_child_samples, val_score: 1.081522:  20%|##        | 1/5 [00:00<00:00,  5.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's rmse: 0.315435\tvalid's rmse: 1.08996\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttrain's rmse: 0.422631\tvalid's rmse: 1.08152\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 1.056777:  40%|####      | 2/5 [00:00<00:00,  4.45it/s]\u001b[32m[I 2020-03-24 13:55:03,667]\u001b[0m Finished trial#1 resulted in value: 1.0567770067675997. Current best value is 1.0567770067675997 with parameters: {'min_child_samples': 10}.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's rmse: 0.508848\tvalid's rmse: 1.0943\n",
      "[200]\ttrain's rmse: 0.355113\tvalid's rmse: 1.0633\n",
      "[300]\ttrain's rmse: 0.272712\tvalid's rmse: 1.05973\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttrain's rmse: 0.300264\tvalid's rmse: 1.05678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 1.056777:  40%|####      | 2/5 [00:00<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.86532\tvalid's rmse: 1.4922\n",
      "[200]\ttrain's rmse: 0.669659\tvalid's rmse: 1.4243\n",
      "[300]\ttrain's rmse: 0.549775\tvalid's rmse: 1.37912\n",
      "[400]\ttrain's rmse: 0.472949\tvalid's rmse: 1.35911\n",
      "[500]\ttrain's rmse: 0.418548\tvalid's rmse: 1.34986\n",
      "[600]\ttrain's rmse: 0.380557\tvalid's rmse: 1.34905\n",
      "[700]\ttrain's rmse: 0.353767\tvalid's rmse: 1.35021\n",
      "Early stopping, best iteration is:\n",
      "[649]\ttrain's rmse: 0.367378\tvalid's rmse: 1.34752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 1.056777:  60%|######    | 3/5 [00:01<00:00,  2.86it/s]\u001b[32m[I 2020-03-24 13:55:04,313]\u001b[0m Finished trial#2 resulted in value: 1.3475189614831418. Current best value is 1.0567770067675997 with parameters: {'min_child_samples': 10}.\u001b[0m\n",
      "tune_min_child_samples, val_score: 1.056777:  60%|######    | 3/5 [00:01<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.35014\tvalid's rmse: 1.80619\n",
      "[200]\ttrain's rmse: 1.20426\tvalid's rmse: 1.70729\n",
      "[300]\ttrain's rmse: 1.08274\tvalid's rmse: 1.64065\n",
      "[400]\ttrain's rmse: 0.995132\tvalid's rmse: 1.58098\n",
      "[500]\ttrain's rmse: 0.923945\tvalid's rmse: 1.53432\n",
      "[600]\ttrain's rmse: 0.869136\tvalid's rmse: 1.50418\n",
      "[700]\ttrain's rmse: 0.822957\tvalid's rmse: 1.48174\n",
      "[800]\ttrain's rmse: 0.784505\tvalid's rmse: 1.46025\n",
      "[900]\ttrain's rmse: 0.751576\tvalid's rmse: 1.44726\n",
      "[1000]\ttrain's rmse: 0.723918\tvalid's rmse: 1.44217\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.723918\tvalid's rmse: 1.44217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 1.056777:  80%|########  | 4/5 [00:02<00:00,  1.91it/s]\u001b[32m[I 2020-03-24 13:55:05,235]\u001b[0m Finished trial#3 resulted in value: 1.4421743263739428. Current best value is 1.0567770067675997 with parameters: {'min_child_samples': 10}.\u001b[0m\n",
      "tune_min_child_samples, val_score: 1.056777:  80%|########  | 4/5 [00:02<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 1.84389\tvalid's rmse: 2.00994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tune_min_child_samples, val_score: 1.056777: 100%|##########| 5/5 [00:02<00:00,  2.19it/s]\u001b[32m[I 2020-03-24 13:55:05,548]\u001b[0m Finished trial#4 resulted in value: 1.9900834833715277. Current best value is 1.0567770067675997 with parameters: {'min_child_samples': 10}.\u001b[0m\n",
      "tune_min_child_samples, val_score: 1.056777: 100%|##########| 5/5 [00:02<00:00,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\ttrain's rmse: 1.95408\tvalid's rmse: 1.99008\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain's rmse: 0.405513\tvalid's rmse: 1.00767\n",
      "[200]\ttrain's rmse: 0.265\tvalid's rmse: 0.969726\n",
      "[300]\ttrain's rmse: 0.2005\tvalid's rmse: 0.951149\n",
      "[400]\ttrain's rmse: 0.161677\tvalid's rmse: 0.946218\n",
      "[500]\ttrain's rmse: 0.132237\tvalid's rmse: 0.942191\n",
      "[600]\ttrain's rmse: 0.110322\tvalid's rmse: 0.939833\n",
      "[700]\ttrain's rmse: 0.0937357\tvalid's rmse: 0.936926\n",
      "[800]\ttrain's rmse: 0.0805643\tvalid's rmse: 0.935438\n",
      "[900]\ttrain's rmse: 0.0707018\tvalid's rmse: 0.934616\n",
      "[1000]\ttrain's rmse: 0.0615551\tvalid's rmse: 0.934382\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.0615551\tvalid's rmse: 0.934382\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.443973\tvalid's rmse: 0.884163\n",
      "[200]\ttrain's rmse: 0.307093\tvalid's rmse: 0.834893\n",
      "[300]\ttrain's rmse: 0.232273\tvalid's rmse: 0.820357\n",
      "[400]\ttrain's rmse: 0.184382\tvalid's rmse: 0.816332\n",
      "[500]\ttrain's rmse: 0.152105\tvalid's rmse: 0.808029\n",
      "[600]\ttrain's rmse: 0.126569\tvalid's rmse: 0.802485\n",
      "[700]\ttrain's rmse: 0.108596\tvalid's rmse: 0.800922\n",
      "[800]\ttrain's rmse: 0.0936274\tvalid's rmse: 0.7983\n",
      "[900]\ttrain's rmse: 0.0815902\tvalid's rmse: 0.795617\n",
      "[1000]\ttrain's rmse: 0.071901\tvalid's rmse: 0.795064\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttrain's rmse: 0.071901\tvalid's rmse: 0.795064\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.429564\tvalid's rmse: 0.722231\n",
      "[200]\ttrain's rmse: 0.300272\tvalid's rmse: 0.711641\n",
      "[300]\ttrain's rmse: 0.232507\tvalid's rmse: 0.70972\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttrain's rmse: 0.295152\tvalid's rmse: 0.707525\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.417342\tvalid's rmse: 1.08535\n",
      "[200]\ttrain's rmse: 0.286407\tvalid's rmse: 1.01229\n",
      "[300]\ttrain's rmse: 0.222228\tvalid's rmse: 0.997962\n",
      "[400]\ttrain's rmse: 0.1733\tvalid's rmse: 0.983165\n",
      "[500]\ttrain's rmse: 0.141017\tvalid's rmse: 0.978994\n",
      "[600]\ttrain's rmse: 0.116234\tvalid's rmse: 0.975214\n",
      "[700]\ttrain's rmse: 0.0975715\tvalid's rmse: 0.975339\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttrain's rmse: 0.103266\tvalid's rmse: 0.974244\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttrain's rmse: 0.445555\tvalid's rmse: 0.689098\n",
      "[200]\ttrain's rmse: 0.327157\tvalid's rmse: 0.665621\n",
      "[300]\ttrain's rmse: 0.260541\tvalid's rmse: 0.660158\n",
      "Early stopping, best iteration is:\n",
      "[223]\ttrain's rmse: 0.309868\tvalid's rmse: 0.659257\n",
      "CV : 0.814094\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml.run(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 39)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.engine.train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>k_class</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.227064</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>-0.009059</td>\n",
       "      <td>1.423867</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>-0.089850</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>-0.325170</td>\n",
       "      <td>1.760927</td>\n",
       "      <td>-0.735186</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.876043</td>\n",
       "      <td>-0.194021</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>-0.521549</td>\n",
       "      <td>1.221631</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>-0.518927</td>\n",
       "      <td>1.289043</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>-0.518383</td>\n",
       "      <td>1.356455</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>-0.413248</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>-0.392978</td>\n",
       "      <td>-0.868141</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.041624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>-0.213584</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>-0.481619</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.041624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>-0.160546</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.482274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.252844</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>3.716149</td>\n",
       "      <td>1.973872</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>-0.450616</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.414523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.089077</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>-0.412818</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>1.414523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>-0.413692</td>\n",
       "      <td>0.277863</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>-0.199959</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>-0.509056</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>-0.523883</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>-0.053126</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.041624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>-0.414757</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.547872</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>1.600973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>0.210451</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.496387</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>5.143518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.129540</td>\n",
       "      <td>1.221631</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.556754</td>\n",
       "      <td>-0.463669</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>-0.444298</td>\n",
       "      <td>-0.665905</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.041624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>-0.501907</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>1.496387</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>5.143518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>-0.232941</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>-0.526927</td>\n",
       "      <td>0.345275</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>-0.438724</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>1.298652</td>\n",
       "      <td>1.221631</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>1.041624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>-0.043385</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.041624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>4.643284</td>\n",
       "      <td>1.895751</td>\n",
       "      <td>-0.735186</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>-0.496427</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>-0.411989</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>251</td>\n",
       "      <td>3.131754</td>\n",
       "      <td>-0.665905</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>259</td>\n",
       "      <td>-0.330685</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>262</td>\n",
       "      <td>-0.296374</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>0.482274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>1.668140</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>4.957069</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>-0.200719</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285</td>\n",
       "      <td>-0.320064</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292</td>\n",
       "      <td>-0.226924</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>-0.517872</td>\n",
       "      <td>1.221631</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>309</td>\n",
       "      <td>-0.032390</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>7.757401</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>311</td>\n",
       "      <td>-0.520601</td>\n",
       "      <td>0.817159</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>314</td>\n",
       "      <td>-0.207936</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>317</td>\n",
       "      <td>0.067392</td>\n",
       "      <td>0.884571</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>10.451569</td>\n",
       "      <td>-0.822874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>-0.465178</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>-0.199991</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>1.228073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>-0.442203</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>1.160461</td>\n",
       "      <td>-0.126609</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>-0.520766</td>\n",
       "      <td>1.221631</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>0.172771</td>\n",
       "      <td>-0.665905</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>374</td>\n",
       "      <td>-0.043385</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.041624</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.051043</td>\n",
       "      <td>0.884571</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>381</td>\n",
       "      <td>-0.095399</td>\n",
       "      <td>0.345275</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>2.160322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>-0.456838</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>0.374206</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>4.584169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>401</td>\n",
       "      <td>2.658467</td>\n",
       "      <td>0.143039</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>403</td>\n",
       "      <td>0.247523</td>\n",
       "      <td>1.423867</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>423</td>\n",
       "      <td>1.022955</td>\n",
       "      <td>0.345275</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>429</td>\n",
       "      <td>-0.419666</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.113252</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.482274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>452</td>\n",
       "      <td>-0.139192</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>466</td>\n",
       "      <td>0.441620</td>\n",
       "      <td>-1.002965</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>487</td>\n",
       "      <td>-0.328710</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.482274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>488</td>\n",
       "      <td>-0.131149</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>-0.393693</td>\n",
       "      <td>1.423867</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>-0.291402</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.600973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>1.387838</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>1.787423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>534</td>\n",
       "      <td>-0.509124</td>\n",
       "      <td>0.143039</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>-0.165181</td>\n",
       "      <td>1.221631</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>543</td>\n",
       "      <td>2.246741</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>2.346772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>1.329939</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>2.346772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>-0.218216</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>572</td>\n",
       "      <td>-0.420505</td>\n",
       "      <td>-0.665905</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>2.643787</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>7.940265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>-0.212565</td>\n",
       "      <td>-0.328845</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>597</td>\n",
       "      <td>0.156618</td>\n",
       "      <td>-0.935553</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>598</td>\n",
       "      <td>0.404585</td>\n",
       "      <td>-0.733317</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>2.906121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>602</td>\n",
       "      <td>0.728103</td>\n",
       "      <td>0.817159</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>606</td>\n",
       "      <td>0.056353</td>\n",
       "      <td>1.693515</td>\n",
       "      <td>-0.735186</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>613</td>\n",
       "      <td>-0.525007</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>668</td>\n",
       "      <td>-0.354254</td>\n",
       "      <td>1.221631</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.600973</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685</td>\n",
       "      <td>-0.527438</td>\n",
       "      <td>0.817159</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>687</td>\n",
       "      <td>-0.309512</td>\n",
       "      <td>0.345275</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>-0.344063</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.482274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>699</td>\n",
       "      <td>-0.465687</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>704</td>\n",
       "      <td>-0.490334</td>\n",
       "      <td>0.345275</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705</td>\n",
       "      <td>-0.129235</td>\n",
       "      <td>1.491279</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>5.063233</td>\n",
       "      <td>-0.822874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>708</td>\n",
       "      <td>-0.350428</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>712</td>\n",
       "      <td>-0.405539</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>719</td>\n",
       "      <td>-0.120896</td>\n",
       "      <td>1.693515</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>1.787423</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>726</td>\n",
       "      <td>-0.024322</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>1.228073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735</td>\n",
       "      <td>-0.404859</td>\n",
       "      <td>1.626103</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>0.295825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>742</td>\n",
       "      <td>-0.480495</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>748</td>\n",
       "      <td>-0.333068</td>\n",
       "      <td>0.412687</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.449974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>754</td>\n",
       "      <td>-0.212565</td>\n",
       "      <td>-0.328845</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>761</td>\n",
       "      <td>-0.297322</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>766</td>\n",
       "      <td>0.105303</td>\n",
       "      <td>0.345275</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.822874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>-0.406969</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>-0.263525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775</td>\n",
       "      <td>-0.212565</td>\n",
       "      <td>-0.328845</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.668724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>778</td>\n",
       "      <td>-0.443086</td>\n",
       "      <td>0.749747</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>787</td>\n",
       "      <td>-0.336082</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>2.160322</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>801</td>\n",
       "      <td>-0.520902</td>\n",
       "      <td>0.884571</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>-0.517225</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>831</td>\n",
       "      <td>-0.517225</td>\n",
       "      <td>-0.531081</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.636424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>833</td>\n",
       "      <td>-0.024254</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>1.021981</td>\n",
       "      <td>-0.077075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835</td>\n",
       "      <td>-0.197247</td>\n",
       "      <td>-0.598493</td>\n",
       "      <td>-0.108556</td>\n",
       "      <td>-0.325103</td>\n",
       "      <td>0.855174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2          3         4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  k_class  pred\n",
       "0    0.227064 -0.531081 -0.108556   1.021981  0.295825  0  0  0  0  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0        9     8\n",
       "8   -0.009059  1.423867 -0.108556  -0.325103 -0.449974  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0        5     6\n",
       "16  -0.089850  0.008215 -0.108556   1.021981 -0.263525  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     2\n",
       "17  -0.325170  1.760927 -0.735186  -0.325103 -0.449974  0  0  0  0  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0        7     6\n",
       "24   1.876043 -0.194021 -0.108556  -0.325103 -0.263525  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0        6     5\n",
       "33  -0.521549  1.221631 -0.108556  -0.325103 -0.449974  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0        5     6\n",
       "36  -0.518927  1.289043 -0.108556  -0.325103 -0.636424  0  0  0  1  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "43  -0.518383  1.356455 -0.108556  -0.325103 -0.449974  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "60  -0.413248 -0.598493 -0.108556   1.021981 -0.263525  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "64  -0.392978 -0.868141 -0.108556  -0.325103  1.041624  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "65  -0.213584 -0.598493 -0.108556   1.021981  0.109375  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "85  -0.481619 -0.598493 -0.108556  -0.325103  1.041624  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        2     3\n",
       "86  -0.160546 -0.531081 -0.108556   1.021981  0.482274  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     2\n",
       "98   1.252844 -0.598493 -0.108556   3.716149  1.973872  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        3     4\n",
       "112 -0.450616 -0.598493 -0.108556  -0.325103  1.414523  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        8     7\n",
       "113  0.089077 -0.598493 -0.108556   2.369065  0.668724  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        9     8\n",
       "125 -0.412818 -0.598493 -0.108556   1.021981  1.414523  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        8     7\n",
       "126 -0.413692  0.277863 -0.108556   1.021981 -0.077075  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0        0     1\n",
       "135 -0.199959 -0.598493 -0.108556   1.021981  0.668724  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     7\n",
       "139 -0.509056 -0.598493 -0.108556   1.021981 -0.449974  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0        0     1\n",
       "147 -0.523883 -0.531081 -0.108556  -0.325103 -0.449974  0  0  0  0  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "153 -0.053126 -0.531081 -0.108556  -0.325103  1.041624  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     7\n",
       "161 -0.414757 -0.598493 -0.108556  -0.325103  0.109375  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0    -1\n",
       "171  0.547872 -0.598493 -0.108556   1.021981  1.600973  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "174  0.271838  0.210451 -0.108556   1.021981 -0.077075  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "183  1.496387 -0.598493 -0.108556   2.369065  5.143518  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        3     4\n",
       "184  0.129540  1.221631 -0.108556  -0.325103  0.855174  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0        5     6\n",
       "191  0.556754 -0.463669 -0.108556   1.021981  0.855174  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "192 -0.444298 -0.665905 -0.108556  -0.325103  1.041624  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "197 -0.501907 -0.531081 -0.108556   1.021981 -0.263525  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0        0     1\n",
       "207  1.496387 -0.598493 -0.108556   2.369065  5.143518  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        3     4\n",
       "216 -0.232941  0.075627 -0.108556   2.369065  0.295825  0  0  0  0  0   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9    10\n",
       "218 -0.526927  0.345275 -0.108556  -0.325103 -0.636424  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "219 -0.438724 -0.598493 -0.108556   1.021981  0.109375  0  0  0  1  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "224  1.298652  1.221631 -0.108556   2.369065  1.041624  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0        9     8\n",
       "232 -0.043385 -0.531081 -0.108556  -0.325103  1.041624  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "237  4.643284  1.895751 -0.735186  -0.325103 -0.449974  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        6     7\n",
       "239 -0.496427 -0.598493 -0.108556   1.021981 -0.263525  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "240 -0.411989 -0.598493 -0.108556   1.021981  0.109375  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "251  3.131754 -0.665905 -0.108556  -0.325103  0.109375  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0        6     5\n",
       "259 -0.330685  0.075627 -0.108556  -0.325103  0.855174  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        5     3\n",
       "262 -0.296374 -0.598493 -0.108556   2.369065  0.482274  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        9     8\n",
       "264  1.668140 -0.598493 -0.108556   1.021981  4.957069  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        8     7\n",
       "273 -0.200719 -0.598493 -0.108556   1.021981  0.668724  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     7\n",
       "285 -0.320064 -0.598493 -0.108556   1.021981  0.109375  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "292 -0.226924 -0.531081 -0.108556   1.021981  0.109375  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "300 -0.517872  1.221631 -0.108556  -0.325103 -0.449974  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "309 -0.032390 -0.531081 -0.108556   7.757401  0.295825  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        4     5\n",
       "311 -0.520601  0.817159 -0.108556  -0.325103 -0.449974  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        5     6\n",
       "314 -0.207936 -0.531081 -0.108556  -0.325103 -0.077075  0  0  0  0  0   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "317  0.067392  0.884571 -0.108556  10.451569 -0.822874  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0        4     5\n",
       "329 -0.465178 -0.598493 -0.108556   1.021981 -0.449974  0  0  0  0  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0        9     8\n",
       "341 -0.199991 -0.598493 -0.108556   1.021981  1.228073  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9    10\n",
       "342 -0.442203 -0.598493 -0.108556   1.021981  0.295825  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "348  1.160461 -0.126609 -0.108556   1.021981 -0.077075  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0        0     1\n",
       "359 -0.520766  1.221631 -0.108556  -0.325103 -0.449974  0  0  0  1  0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "361  0.172771 -0.665905 -0.108556  -0.325103 -0.077075  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "374 -0.043385 -0.531081 -0.108556  -0.325103  1.041624  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "380  0.051043  0.884571 -0.108556  -0.325103  0.855174  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0        5     6\n",
       "381 -0.095399  0.345275 -0.108556   1.021981  2.160322  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        8     7\n",
       "384 -0.456838 -0.598493 -0.108556  -0.325103  0.668724  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0     1\n",
       "385  0.374206 -0.531081 -0.108556   1.021981  4.584169  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        8     7\n",
       "401  2.658467  0.143039 -0.108556   1.021981  0.295825  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        6     7\n",
       "403  0.247523  1.423867 -0.108556   1.021981  0.668724  0  0  0  0  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        5     6\n",
       "423  1.022955  0.345275 -0.108556  -0.325103 -0.077075  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "429 -0.419666  0.075627 -0.108556   2.369065 -0.636424  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0        9     7\n",
       "430  0.113252  0.075627 -0.108556   1.021981  0.482274  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     7\n",
       "452 -0.139192 -0.531081 -0.108556  -0.325103 -0.077075  0  0  0  0  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0        0     1\n",
       "466  0.441620 -1.002965 -0.108556   1.021981  0.295825  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "487 -0.328710  0.075627 -0.108556  -0.325103  0.482274  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0        2     3\n",
       "488 -0.131149 -0.598493 -0.108556   1.021981  0.668724  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9    10\n",
       "501 -0.393693  1.423867 -0.108556  -0.325103 -0.449974  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "510 -0.291402 -0.598493 -0.108556  -0.325103  1.600973  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        8     7\n",
       "519  1.387838 -0.598493 -0.108556   2.369065  1.787423  0  0  0  0  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0        3     4\n",
       "534 -0.509124  0.143039 -0.108556  -0.325103 -0.636424  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        2     3\n",
       "535 -0.165181  1.221631 -0.108556   1.021981  0.855174  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "543  2.246741 -0.531081 -0.108556  -0.325103  2.346772  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        8     9\n",
       "552  1.329939 -0.531081 -0.108556  -0.325103  2.346772  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        8     7\n",
       "568 -0.218216 -0.598493 -0.108556   1.021981 -0.077075  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "572 -0.420505 -0.665905 -0.108556  -0.325103 -0.077075  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0    -1\n",
       "584  2.643787 -0.531081 -0.108556   2.369065  7.940265  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        3     4\n",
       "587 -0.212565 -0.328845 -0.108556  -0.325103  0.668724  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        2     3\n",
       "597  0.156618 -0.935553 -0.108556   1.021981 -0.449974  0  0  0  0  0   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "598  0.404585 -0.733317 -0.108556   2.369065  2.906121  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        3     4\n",
       "602  0.728103  0.817159 -0.108556  -0.325103 -0.077075  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0        5     6\n",
       "606  0.056353  1.693515 -0.735186   2.369065 -0.636424  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        7     8\n",
       "613 -0.525007 -0.598493 -0.108556   1.021981 -0.636424  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     2\n",
       "668 -0.354254  1.221631 -0.108556  -0.325103  1.600973  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        5     6\n",
       "685 -0.527438  0.817159 -0.108556  -0.325103 -0.636424  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "687 -0.309512  0.345275 -0.108556  -0.325103  0.855174  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        5     6\n",
       "695 -0.344063  0.075627 -0.108556   1.021981  0.482274  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0        9     8\n",
       "699 -0.465687 -0.598493 -0.108556   1.021981 -0.263525  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "704 -0.490334  0.345275 -0.108556  -0.325103 -0.263525  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     2\n",
       "705 -0.129235  1.491279 -0.108556   5.063233 -0.822874  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "708 -0.350428 -0.598493 -0.108556   1.021981  0.109375  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "712 -0.405539 -0.598493 -0.108556   1.021981 -0.449974  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "719 -0.120896  1.693515 -0.108556  -0.325103  1.787423  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        5     6\n",
       "726 -0.024322 -0.598493 -0.108556   1.021981  1.228073  0  0  0  0  0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9    10\n",
       "735 -0.404859  1.626103 -0.108556   1.021981  0.295825  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     8\n",
       "742 -0.480495 -0.598493 -0.108556  -0.325103  0.109375  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        0    -1\n",
       "748 -0.333068  0.412687 -0.108556   1.021981 -0.449974  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     2\n",
       "754 -0.212565 -0.328845 -0.108556  -0.325103  0.668724  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "761 -0.297322 -0.598493 -0.108556   1.021981 -0.077075  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "766  0.105303  0.345275 -0.108556  -0.325103 -0.822874  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     6\n",
       "770 -0.406969 -0.598493 -0.108556  -0.325103 -0.263525  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0    -1\n",
       "775 -0.212565 -0.328845 -0.108556  -0.325103  0.668724  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1\n",
       "778 -0.443086  0.749747 -0.108556  -0.325103  0.855174  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0        5     4\n",
       "787 -0.336082 -0.598493 -0.108556  -0.325103  2.160322  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        8     7\n",
       "801 -0.520902  0.884571 -0.108556   1.021981 -0.636424  0  0  0  0  0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0        7     8\n",
       "818 -0.517225 -0.531081 -0.108556   1.021981 -0.636424  0  0  0  0  0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "831 -0.517225 -0.531081 -0.108556   1.021981 -0.636424  0  0  0  0  0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     8\n",
       "833 -0.024254 -0.598493 -0.108556   1.021981 -0.077075  0  0  0  0  0   1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        9     7\n",
       "835 -0.197247 -0.598493 -0.108556  -0.325103  0.855174  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0        0     1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.engine.train[\"pred\"] = ml.predicts.round().astype(int)\n",
    "ml.engine.train[ml.engine.train[\"k_class\"] != ml.engine.train[\"pred\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 40)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.engine.train[ml.engine.train[\"k_class\"] != ml.engine.train[\"pred\"]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649940262843488"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 - (113.0/837.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = pd.read_csv(\"../input/vortex/vortex_actual_05.csv\")\n",
    "actual[\"pred\"] = ml.predicts\n",
    "actual.to_csv(\"actual_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"selected.pkl\", \"rb\") as f:\n",
    "    hoge = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train[[\"Age\", \"Fare\"]])\n",
    "\n",
    "train[[\"Age\", \"Fare\"]] = scaler.transform(train[[\"Age\", \"Fare\"]])\n",
    "train[\"Age\"].fillna(-9999, inplace=True)\n",
    "train[\"Fare\"].fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "um = umap.UMAP()\n",
    "um.fit(train[[\"Age\", \"Fare\"]])\n",
    "\n",
    "d = um.transform(train[[\"Age\", \"Fare\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Age\", \"Fare\"]] = train[[\"Age\", \"Fare\"]].replace(np.inf, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ml.engine.train, ml.engine.test], ignore_index=True)\n",
    "skip_columns = [\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in df.columns if f not in skip_columns]\n",
    "num_columns = [col for col in feats if df[col].dtype.name in FeatureEngineering.NUMERICS and df[col].unique().shape[0] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in num_columns:\n",
    "    df[col] = df[col].replace(np.inf, np.nan)\n",
    "    df[col].fillna(-9999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um = umap.UMAP()\n",
    "um.fit(df[num_columns])\n",
    "df[num_columns] = um.transform(df[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[num_columns].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "um.transform(df[num_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./\"\n",
    "base_score = 0.7681353456669913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = 0.0\n",
    "selected = set([])\n",
    "params = None\n",
    "scenario = None\n",
    "with open(f\"{base_path}/param_{base_score}.json\") as f:\n",
    "    params = json.load(f)\n",
    "with open(f\"{base_path}/scenario_{base_score}.yml\", \"r\") as yml:\n",
    "    scenario = yaml.safe_load(yml)\n",
    "\n",
    "train = pd.read_pickle(f\"{base_path}/train_{base_score}.pkl\")\n",
    "test = pd.read_pickle(f\"{base_path}/test_{base_score}.pkl\")\n",
    "\n",
    "train_x = [f for f in train.columns if f not in [\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for col in train_x:\n",
    "    if col not in selected:\n",
    "        feats = list(selected) + [col]\n",
    "        param_with_score = 1\n",
    "        scores.append((col, param_with_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_feature, b_score = sorted(scores, key=lambda tpl: tpl[1])[0]\n",
    "if b_score > best_score:\n",
    "    selected.add(b_feature)\n",
    "    best_score = b_score\n",
    "    print(f'selected:{b_feature}')\n",
    "    print(f'score:{b_score}')\n",
    "else:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
