{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime, time, re, warnings\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "from sklearn import datasets, manifold, mixture, model_selection\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz, hstack\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    print(f'[{title}] start')\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering(metaclass=ABCMeta):\n",
    "    BASE_DIR = \".\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = self.__class__.__name__\n",
    "        self.train = pd.DataFrame()\n",
    "        self.test = pd.DataFrame()\n",
    "        self.train_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_train\"\n",
    "        self.test_file_path = f\"{Path(self.BASE_DIR)}/{self.name.lower()}_test\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_data(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def create_features(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def run(self, use_columns=[], skip_columns=[]):\n",
    "        with timer(self.name):\n",
    "            self.load_data()\n",
    "            self.replace_na(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.onehot_encode(use_columns=use_columns, skip_columns=skip_columns)\n",
    "            self.create_features()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def onehot_encode(self, use_columns=[], skip_columns=[], sparse=False):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        self.label_encode(use_columns, skip_columns)\n",
    "        if sparse:\n",
    "            encoder = OneHotEncoder(categories='auto', sparse=sparse, dtype='uint8').fit(pd.concat([self.train.loc[:, use_columns], self.test.loc[:, use_columns]]))\n",
    "            m = 100000\n",
    "            train = vstack([encoder.transform(self.train[i*m:(i+1)*m].loc[:, use_columns]) for i in range(self.train.shape[0] // m + 1)])\n",
    "            test  = vstack([encoder.transform(self.test[i*m:(i+1)*m].loc[:, use_columns])  for i in range(self.test.shape[0] // m +  1)])\n",
    "            save_npz(f\"{self.train_file_path}.npz\", train, compressed=True)\n",
    "            save_npz(f\"{self.test_file_path}.npz\",  test,  compressed=True)\n",
    "        else:\n",
    "            for col in use_columns:\n",
    "                self.train = self.train.join(pd.get_dummies(self.train[col], prefix=col))\n",
    "                self.test = self.test.join(pd.get_dummies(self.test[col], prefix=col))\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def label_encode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            self.train[col] = self.train[col].astype('str')\n",
    "            self.test[col] = self.test[col].astype('str')\n",
    "            \n",
    "            le = LabelEncoder().fit(np.unique(self.train[col].unique().tolist()+self.test[col].unique().tolist()))\n",
    "            self.train[col] = le.transform(self.train[col])+1\n",
    "            self.test[col]  = le.transform(self.test[col])+1\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def target_encode(self, col_name, target_name, min_samples_leaf=1, smoothing=1, noise_level=0):\n",
    "        trn_series = self.train[col_name]\n",
    "        tst_series = self.test[col_name]\n",
    "        target = self.train[target_name]\n",
    "        \n",
    "        assert len(trn_series) == len(target)\n",
    "\n",
    "        temp = pd.concat([trn_series, target], axis=1)\n",
    "        averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "        smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "        prior = target.mean()\n",
    "        averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "        averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "        ft_trn_series = pd.merge(\n",
    "            trn_series.to_frame(trn_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=trn_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_trn_series.index = trn_series.index \n",
    "        ft_tst_series = pd.merge(\n",
    "            tst_series.to_frame(tst_series.name),\n",
    "            averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "            on=tst_series.name,\n",
    "            how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "        ft_tst_series.index = tst_series.index\n",
    "\n",
    "        self.train[f\"te_smoothing_{col_name}\"], self.test[f\"te_smoothing_{col_name}\"] = self.__add_noise(ft_trn_series, noise_level), self.__add_noise(ft_tst_series, noise_level)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "\n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                self.train[f\"{prefix}{k}_{v}\"] = self.train.groupby(group)[k].transform(v)\n",
    "                self.test[f\"{prefix}{k}_{v}\"] = self.test.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    self.train[f\"{prefix}{k}_{vv}\"] = self.train.groupby(group)[k].transform(vv)\n",
    "                    self.test[f\"{prefix}{k}_{vv}\"] = self.test.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def agg_transform_ratio(self, group, agg, prefix=\"\"):\n",
    "        if prefix:\n",
    "            prefix += \"_\"\n",
    "        else:\n",
    "            prefix = f\"{'_'.join(group)}_\" if type(group) is list else f\"{group}_\"\n",
    "        prefix = f\"ratio_{prefix}\"\n",
    "        \n",
    "        for k, v in agg.items():\n",
    "            if type(v) is str:\n",
    "                self.train[f\"{prefix}{k}_{v}\"] = self.train[k] / self.train.groupby(group)[k].transform(v)\n",
    "                self.test[f\"{prefix}{k}_{v}\"] = self.test[k] / self.test.groupby(group)[k].transform(v)\n",
    "            else:\n",
    "                for vv in v:\n",
    "                    self.train[f\"{prefix}{k}_{vv}\"] = self.train[k] / self.train.groupby(group)[k].transform(vv)\n",
    "                    self.test[f\"{prefix}{k}_{vv}\"] = self.test[k] / self.test.groupby(group)[k].transform(vv)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def replace_na(self, use_columns=[], skip_columns=[], fill_value=-1):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(fill_value))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(fill_value)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mode(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mode().values[0])\n",
    "            self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mode().values[0])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def replace_na_mean(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].mean())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].mean())\n",
    "\n",
    "        return self\n",
    "\n",
    "    def replace_na_median(self, use_columns=[], skip_columns=[]):\n",
    "        use_columns = use_columns if use_columns else [c for c in self.train.columns if c not in skip_columns]\n",
    "        for col in use_columns:\n",
    "            if isinstance(self.train[col].dtype, CategoricalDtype):\n",
    "                self.train[col] = self.train[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "                self.test[col] = self.test[col].cat.add_categories(str(fill_value)).replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(str(-1))\n",
    "            else:\n",
    "                self.train[col] = self.train[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.train[col].median())\n",
    "                self.test[col] = self.test[col].replace(np.inf, np.nan).replace(-np.inf, np.nan).fillna(self.test[col].median())\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_topic_score(self, topic_text_columns, num_topics=5):\n",
    "        df = pd.concat([self.train.loc[:, topic_text_columns], self.test.loc[:, topic_text_columns]])\n",
    "        \n",
    "        for col in topic_text_columns:\n",
    "            texts = [[word for word in document.lower().split()] for document in df[col].values]\n",
    "            dictionary = corpora.Dictionary(texts)\n",
    "            bow_corpus = [dictionary.doc2bow(t) for t in texts]\n",
    "            lda = models.LdaModel(bow_corpus, id2word=dictionary, num_topics=num_topics)\n",
    "                        \n",
    "            size = df.shape[0]\n",
    "            topics = {i:[-1]*size for i in range(num_topics)}\n",
    "            for i, row in enumerate(lda[bow_corpus]):\n",
    "                for (topic_num, prop_topic) in row:\n",
    "                    topics[topic_num][i] = prop_topic\n",
    "            \n",
    "            for i in range(num_topics):\n",
    "                self.train[f\"{col}_topic_{i}\"] = topics[i][:self.train.shape[0]]\n",
    "                self.test[f\"{col}_topic_{i}\"] = topics[i][self.train.shape[0]:]\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def calc_scdv_word2vec_score(self, text_col_name):\n",
    "        features_num = 20\n",
    "        min_word_count = 10\n",
    "        context = 5\n",
    "        downsampling = 1e-3\n",
    "        epoch_num = 10\n",
    "        clusters_num = 6\n",
    "        \n",
    "        df = pd.concat([self.train.loc[:, [text_col_name]], self.test.loc[:, [text_col_name]]])\n",
    "        df[text_col_name] = df[text_col_name].fillna(\"\")\n",
    "        \n",
    "        corpus = [self.__analyzer_cat(text) for text in df[text_col_name]]\n",
    "        word2vecs = Word2Vec(sentences=corpus, iter=epoch_num, size=features_num, min_count=min_word_count, window=context, sample=downsampling)\n",
    "        word_vectors = word2vecs.wv.vectors\n",
    "        \n",
    "        gmm = mixture.GaussianMixture(n_components=clusters_num, covariance_type='tied', max_iter=50)\n",
    "        gmm.fit(word_vectors)\n",
    "        \n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer=self.__analyzer_cat, min_df=min_word_count)\n",
    "        tfidfs = tfidf_vectorizer.fit_transform(df[text_col_name])\n",
    "        \n",
    "        idf_dic = dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer._tfidf.idf_))\n",
    "        assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict(word_vectors)))\n",
    "        soft_assign_dic = dict(zip(word2vecs.wv.index2word, gmm.predict_proba(word_vectors)))\n",
    "        \n",
    "        word_topic_vecs = {}\n",
    "        for word in assign_dic:\n",
    "            word_topic_vecs[word] = np.zeros(features_num*clusters_num, dtype=np.float32)\n",
    "            for i in range(0, clusters_num):\n",
    "                try:\n",
    "                    word_topic_vecs[word][i*features_num:(i+1)*features_num] = word2vecs.wv[word]*soft_assign_dic[word][i]*idf_dic[word]\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        scdvs = np.zeros((len(df[text_col_name]), clusters_num*features_num), dtype=np.float32)\n",
    "\n",
    "        a_min = 0\n",
    "        a_max = 0\n",
    "\n",
    "        for i, text in enumerate(df[text_col_name]):\n",
    "            tmp = np.zeros(clusters_num*features_num, dtype=np.float32)\n",
    "            words = self.__analyzer_cat(text)\n",
    "            for word in words:\n",
    "                if word in word_topic_vecs:\n",
    "                    tmp += word_topic_vecs[word]\n",
    "            norm = np.sqrt(np.sum(tmp**2))\n",
    "            if norm > 0:\n",
    "                tmp /= norm\n",
    "            a_min += min(tmp)\n",
    "            a_max += max(tmp)\n",
    "            scdvs[i] = tmp\n",
    "\n",
    "        p = 0.04\n",
    "        a_min = a_min*1.0 / len(df[text_col_name])\n",
    "        a_max = a_max*1.0 / len(df[text_col_name])\n",
    "        thres = (abs(a_min)+abs(a_max)) / 2\n",
    "        thres *= p\n",
    "        scdvs[abs(scdvs) < thres] = 0\n",
    "        \n",
    "        tsne_scdv = manifold.TSNE(n_components=2).fit_transform(scdvs)\n",
    "        \n",
    "        self.train[f\"scdv_{text_col_name}_x\"] = tsne_scdv[:self.train.shape[0], 0]\n",
    "        self.train[f\"scdv_{text_col_name}_y\"] = tsne_scdv[:self.train.shape[0], 1]        \n",
    "        self.test[f\"scdv_{text_col_name}_x\"] = tsne_scdv[self.train.shape[0]:, 0]\n",
    "        self.test[f\"scdv_{text_col_name}_y\"] = tsne_scdv[self.train.shape[0]:, 1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def columns_1d(self):\n",
    "        self.train.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.train.columns.tolist()])\n",
    "        self.test.columns = pd.Index([(e[0] + \"_\" + e[1].lower()) if (len(e[1]) > 0) else e[0] for e in self.test.columns.tolist()])\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def head(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train head: {title}\")\n",
    "        print(self.train.loc[:, train_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test head: {title}\")\n",
    "        print(self.test.loc[:, test_cols].head(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def tail(self, title=\"\", columns=[], limit=5):\n",
    "        train_cols, test_cols = (columns, columns) if columns else (self.train.columns, self.test.columns)\n",
    "        \n",
    "        print(f\"train tail: {title}\")\n",
    "        print(self.train.loc[:, train_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        print(f\"test tail: {title}\")\n",
    "        print(self.test.loc[:, test_cols].tail(limit))\n",
    "        print(\"----------------------------\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def save(self, format=\"feather\", index=False):\n",
    "        if format == \"feather\":\n",
    "            self.train.to_feather(f\"{self.train_file_path}.ftr\")\n",
    "            self.test.to_feather(f\"{self.test_file_path}.ftr\")\n",
    "        elif format == \"csv\":\n",
    "            self.train.to_csv(f\"{self.train_file_path}.csv\", index=index)\n",
    "            self.test.to_csv(f\"{self.test_file_path}.csv\", index=index)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __add_noise(self, series, noise_level):\n",
    "        return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "    def __analyzer_nlp(self, text):\n",
    "        stop_words = ['i', 'a', 'an', 'the', 'to', 'and', 'or', 'if', 'is', 'are', 'am', 'it', 'this', 'that', 'of', 'from', 'in', 'on']\n",
    "        text = text.lower()\n",
    "        text = text.replace('\\n', '')\n",
    "        text = text.replace('\\t', '')\n",
    "        text = re.sub(re.compile(r'[!-\\/:-@[-`{-~]'), ' ', text)\n",
    "        text = text.split(' ')\n",
    "\n",
    "        words = []\n",
    "        for word in text:\n",
    "            if (re.compile(r'^.*[0-9]+.*$').fullmatch(word) is not None):\n",
    "                continue\n",
    "            if word in stop_words:\n",
    "                continue\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            words.append(word)\n",
    "\n",
    "        return words\n",
    "\n",
    "    def __analyzer_cat(self, text):\n",
    "        return text.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample(FeatureEngineering):\n",
    "    def load_data(self):\n",
    "        self.train = pd.read_csv(\"../sample-data/train.csv\", nrows=100)\n",
    "        self.test = pd.read_csv(\"../sample-data/test.csv\", nrows=100)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def create_features(self):\n",
    "        return self\n",
    "    \n",
    "    def create_topic_text(self):\n",
    "        self.train[\"count_1\"] = self.train[\"first_active_month\"].astype(\"str\") + self.train.groupby(\"first_active_month\")[\"first_active_month\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.train[\"count_2\"] = self.train[\"feature_1\"].astype(\"int\").astype(\"str\") + self.train.groupby(\"feature_1\")[\"feature_1\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.train[\"topic_text\"] = \"A\"+self.train[\"count_1\"].astype(str) \\\n",
    "                            +\" B\"+self.train[\"count_2\"].astype(str)\n",
    "        \n",
    "        self.test[\"count_1\"] = self.test[\"first_active_month\"].astype(\"str\") + self.test.groupby(\"first_active_month\")[\"first_active_month\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.test[\"count_2\"] = self.test[\"feature_1\"].astype(\"int\").astype(\"str\") + self.test.groupby(\"feature_1\")[\"feature_1\"].transform(\"count\").astype(\"int\").astype(\"str\")\n",
    "        self.test[\"topic_text\"] = \"A\"+self.test[\"count_1\"].astype(str) \\\n",
    "                            +\" B\"+self.test[\"count_2\"].astype(str)\n",
    "        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3    target\n",
      "0            2017-06  C_ID_92a2005557          5          2          1 -0.820283\n",
      "1            2017-01  C_ID_3d0044924f          4          1          0  0.392913\n",
      "2            2016-08  C_ID_d639edf6cd          2          2          0  0.688056\n",
      "3            2017-09  C_ID_186d6a6901          4          3          0  0.142495\n",
      "4            2017-11  C_ID_cdbd2c0db2          1          3          0 -0.159749\n",
      "----------------------------\n",
      "test head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3\n",
      "0            2017-04  C_ID_0ab67a22ab          3          3          1\n",
      "1            2017-01  C_ID_130fd0cbdd          2          3          0\n",
      "2            2017-08  C_ID_b709037bc5          5          1          1\n",
      "3            2017-12  C_ID_d27d835a9f          2          1          0\n",
      "4            2015-12  C_ID_2b5e3df5c2          5          1          1\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Sample at 0x1ed2ff9e978>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sample()\n",
    "# s.load_data().head(title=\"before label_encode\").label_encode(skip_columns=[\"target\"]).head(title=\"after label_encode\", limit=10).agg_transform(group=[\"feature_1\"], agg={\"first_active_month\": [\"min\", \"max\", \"mean\"]}).tail()\n",
    "# s.run(skip_columns=[\"target\"]).agg_transform(group=\"first_active_month\", agg={\"feature_1_1\": [\"min\", \"max\", \"mean\"]}).head(columns=[\"card_id\", \"feature_1_1_max\"]).save()\n",
    "s.load_data().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3    target  te_smoothing_feature_1\n",
      "0            2017-06  C_ID_92a2005557          5          2          1 -0.820283               -0.703912\n",
      "1            2017-01  C_ID_3d0044924f          4          1          0  0.392913               -0.713972\n",
      "2            2016-08  C_ID_d639edf6cd          2          2          0  0.688056               -0.712038\n",
      "3            2017-09  C_ID_186d6a6901          4          3          0  0.142495               -0.725263\n",
      "4            2017-11  C_ID_cdbd2c0db2          1          3          0 -0.159749               -0.724358\n",
      "----------------------------\n",
      "test head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3  te_smoothing_feature_1\n",
      "0            2017-04  C_ID_0ab67a22ab          3          3          1               -0.714440\n",
      "1            2017-01  C_ID_130fd0cbdd          2          3          0               -0.708047\n",
      "2            2017-08  C_ID_b709037bc5          5          1          1               -0.707837\n",
      "3            2017-12  C_ID_d27d835a9f          2          1          0               -0.704616\n",
      "4            2015-12  C_ID_2b5e3df5c2          5          1          1               -0.712842\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Sample at 0x1ed2ff9e978>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.target_encode(col_name=\"feature_1\", target_name=\"target\", min_samples_leaf=100, smoothing=10, noise_level=0.01).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3    target    count_1 count_2       topic_text\n",
      "0            2017-06  C_ID_92a2005557          5          2          1 -0.820283   2017-067     520   A2017-067 B520\n",
      "1            2017-01  C_ID_3d0044924f          4          1          0  0.392913   2017-019     413   A2017-019 B413\n",
      "2            2016-08  C_ID_d639edf6cd          2          2          0  0.688056   2016-086     235   A2016-086 B235\n",
      "3            2017-09  C_ID_186d6a6901          4          3          0  0.142495  2017-0913     413  A2017-0913 B413\n",
      "4            2017-11  C_ID_cdbd2c0db2          1          3          0 -0.159749   2017-116      14    A2017-116 B14\n",
      "----------------------------\n",
      "test head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3   count_1 count_2      topic_text\n",
      "0            2017-04  C_ID_0ab67a22ab          3          3          1  2017-048     336  A2017-048 B336\n",
      "1            2017-01  C_ID_130fd0cbdd          2          3          0  2017-015     233  A2017-015 B233\n",
      "2            2017-08  C_ID_b709037bc5          5          1          1  2017-085     516  A2017-085 B516\n",
      "3            2017-12  C_ID_d27d835a9f          2          1          0  2017-124     233  A2017-124 B233\n",
      "4            2015-12  C_ID_2b5e3df5c2          5          1          1  2015-124     516  A2015-124 B516\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Sample at 0x1ed2ff9e978>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.load_data().create_topic_text().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3    target    count_1 count_2       topic_text  scdv_topic_text_x  scdv_topic_text_y\n",
      "0            2017-06  C_ID_92a2005557          5          2          1 -0.820283   2017-067     520   A2017-067 B520          -0.025154          -6.124799\n",
      "1            2017-01  C_ID_3d0044924f          4          1          0  0.392913   2017-019     413   A2017-019 B413          -0.701709           1.323653\n",
      "2            2016-08  C_ID_d639edf6cd          2          2          0  0.688056   2016-086     235   A2016-086 B235           6.286077         -10.981548\n",
      "3            2017-09  C_ID_186d6a6901          4          3          0  0.142495  2017-0913     413  A2017-0913 B413          -1.336526           0.664063\n",
      "4            2017-11  C_ID_cdbd2c0db2          1          3          0 -0.159749   2017-116      14    A2017-116 B14          -1.284992          -2.359389\n",
      "----------------------------\n",
      "test head: \n",
      "  first_active_month          card_id  feature_1  feature_2  feature_3   count_1 count_2      topic_text  scdv_topic_text_x  scdv_topic_text_y\n",
      "0            2017-04  C_ID_0ab67a22ab          3          3          1  2017-048     336  A2017-048 B336           5.401772           8.365432\n",
      "1            2017-01  C_ID_130fd0cbdd          2          3          0  2017-015     233  A2017-015 B233          -5.534831           8.331580\n",
      "2            2017-08  C_ID_b709037bc5          5          1          1  2017-085     516  A2017-085 B516           1.909045          -1.610176\n",
      "3            2017-12  C_ID_d27d835a9f          2          1          0  2017-124     233  A2017-124 B233          -6.011029           7.454511\n",
      "4            2015-12  C_ID_2b5e3df5c2          5          1          1  2015-124     516  A2015-124 B516           1.917519          -1.610648\n",
      "----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Sample at 0x1ed2ff9e978>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.calc_scdv_word2vec_score(\"topic_text\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>count_1</th>\n",
       "      <th>count_2</th>\n",
       "      <th>topic_text</th>\n",
       "      <th>scdv_topic_text_x</th>\n",
       "      <th>scdv_topic_text_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>2017-067</td>\n",
       "      <td>520</td>\n",
       "      <td>A2017-067 B520</td>\n",
       "      <td>-0.025154</td>\n",
       "      <td>-6.124799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>2017-019</td>\n",
       "      <td>413</td>\n",
       "      <td>A2017-019 B413</td>\n",
       "      <td>-0.701709</td>\n",
       "      <td>1.323653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>2016-086</td>\n",
       "      <td>235</td>\n",
       "      <td>A2016-086 B235</td>\n",
       "      <td>6.286077</td>\n",
       "      <td>-10.981548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>2017-0913</td>\n",
       "      <td>413</td>\n",
       "      <td>A2017-0913 B413</td>\n",
       "      <td>-1.336526</td>\n",
       "      <td>0.664063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>2017-116</td>\n",
       "      <td>14</td>\n",
       "      <td>A2017-116 B14</td>\n",
       "      <td>-1.284992</td>\n",
       "      <td>-2.359389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3    target    count_1 count_2       topic_text  scdv_topic_text_x  scdv_topic_text_y\n",
       "0            2017-06  C_ID_92a2005557          5          2          1 -0.820283   2017-067     520   A2017-067 B520          -0.025154          -6.124799\n",
       "1            2017-01  C_ID_3d0044924f          4          1          0  0.392913   2017-019     413   A2017-019 B413          -0.701709           1.323653\n",
       "2            2016-08  C_ID_d639edf6cd          2          2          0  0.688056   2016-086     235   A2016-086 B235           6.286077         -10.981548\n",
       "3            2017-09  C_ID_186d6a6901          4          3          0  0.142495  2017-0913     413  A2017-0913 B413          -1.336526           0.664063\n",
       "4            2017-11  C_ID_cdbd2c0db2          1          3          0 -0.159749   2017-116      14    A2017-116 B14          -1.284992          -2.359389"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MachineIdentifier</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>EngineVersion</th>\n",
       "      <th>AppVersion</th>\n",
       "      <th>AvSigVersion</th>\n",
       "      <th>IsBeta</th>\n",
       "      <th>RtpStateBitfield</th>\n",
       "      <th>IsSxsPassiveMode</th>\n",
       "      <th>DefaultBrowsersIdentifier</th>\n",
       "      <th>AVProductStatesIdentifier</th>\n",
       "      <th>...</th>\n",
       "      <th>count_18</th>\n",
       "      <th>count_19</th>\n",
       "      <th>count_20</th>\n",
       "      <th>count_21</th>\n",
       "      <th>topic_text</th>\n",
       "      <th>topic_text_topic_0</th>\n",
       "      <th>topic_text_topic_1</th>\n",
       "      <th>topic_text_topic_2</th>\n",
       "      <th>topic_text_topic_3</th>\n",
       "      <th>topic_text_topic_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000010489e3af074adeac69c53e555e</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15400.5</td>\n",
       "      <td>4.18.1810.5</td>\n",
       "      <td>1.281.501.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53447</td>\n",
       "      <td>...</td>\n",
       "      <td>8071</td>\n",
       "      <td>4.18.1810.531</td>\n",
       "      <td>5344764</td>\n",
       "      <td>-135</td>\n",
       "      <td>A798 B5344764 C585521 D1814 E15063.0.amd64fre....</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.963180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00000176ac758d54827acd545b6315a5</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15400.4</td>\n",
       "      <td>4.18.1809.2</td>\n",
       "      <td>1.279.301.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53447</td>\n",
       "      <td>...</td>\n",
       "      <td>5549</td>\n",
       "      <td>4.18.1809.238</td>\n",
       "      <td>5344764</td>\n",
       "      <td>RequireAdmin23</td>\n",
       "      <td>A798 B5344764 C713951 D-138 E16299.431.amd64fr...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.962994</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000019dcefc128c2d4387c1273dae1d</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15300.6</td>\n",
       "      <td>4.18.1809.2</td>\n",
       "      <td>1.277.230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>49480</td>\n",
       "      <td>...</td>\n",
       "      <td>55615</td>\n",
       "      <td>4.18.1809.238</td>\n",
       "      <td>494802</td>\n",
       "      <td>RequireAdmin16</td>\n",
       "      <td>A798 B494802 C662023 D-138 E14393.2189.amd64fr...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.963127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000055553dc51b1295785415f1a224d</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15400.5</td>\n",
       "      <td>4.18.1810.5</td>\n",
       "      <td>1.281.664.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42160</td>\n",
       "      <td>...</td>\n",
       "      <td>62820</td>\n",
       "      <td>4.18.1810.531</td>\n",
       "      <td>421601</td>\n",
       "      <td>RequireAdmin16</td>\n",
       "      <td>A798 B421601 C1209171 D-138 E16299.15.amd64fre...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.846206</td>\n",
       "      <td>0.126227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000574cefffeca83ec8adf9285b2bf</td>\n",
       "      <td>win8defender</td>\n",
       "      <td>1.1.15400.4</td>\n",
       "      <td>4.18.1809.2</td>\n",
       "      <td>1.279.236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>53447</td>\n",
       "      <td>...</td>\n",
       "      <td>55615</td>\n",
       "      <td>4.18.1809.238</td>\n",
       "      <td>5344764</td>\n",
       "      <td>RequireAdmin23</td>\n",
       "      <td>A798 B5344764 C1247361 D1814 E16299.15.amd64fr...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.963245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 109 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MachineIdentifier   ProductName EngineVersion   AppVersion AvSigVersion  IsBeta  RtpStateBitfield  IsSxsPassiveMode  DefaultBrowsersIdentifier  AVProductStatesIdentifier        ...          count_18       count_19  count_20        count_21                                         topic_text  topic_text_topic_0  topic_text_topic_1  topic_text_topic_2 topic_text_topic_3 topic_text_topic_4\n",
       "0  0000010489e3af074adeac69c53e555e  win8defender   1.1.15400.5  4.18.1810.5  1.281.501.0       0               7.0                 0                       -1.0                      53447        ...              8071  4.18.1810.531   5344764            -135  A798 B5344764 C585521 D1814 E15063.0.amd64fre....                -1.0                -1.0           -1.000000          -1.000000           0.963180\n",
       "1  00000176ac758d54827acd545b6315a5  win8defender   1.1.15400.4  4.18.1809.2  1.279.301.0       0               7.0                 0                       -1.0                      53447        ...              5549  4.18.1809.238   5344764  RequireAdmin23  A798 B5344764 C713951 D-138 E16299.431.amd64fr...                -1.0                -1.0            0.962994          -1.000000          -1.000000\n",
       "2  0000019dcefc128c2d4387c1273dae1d  win8defender   1.1.15300.6  4.18.1809.2  1.277.230.0       0               7.0                 0                       -1.0                      49480        ...             55615  4.18.1809.238    494802  RequireAdmin16  A798 B494802 C662023 D-138 E14393.2189.amd64fr...                -1.0                -1.0           -1.000000          -1.000000           0.963127\n",
       "3  0000055553dc51b1295785415f1a224d  win8defender   1.1.15400.5  4.18.1810.5  1.281.664.0       0               7.0                 0                       -1.0                      42160        ...             62820  4.18.1810.531    421601  RequireAdmin16  A798 B421601 C1209171 D-138 E16299.15.amd64fre...                -1.0                -1.0           -1.000000           0.846206           0.126227\n",
       "4  00000574cefffeca83ec8adf9285b2bf  win8defender   1.1.15400.4  4.18.1809.2  1.279.236.0       0               7.0                 0                       -1.0                      53447        ...             55615  4.18.1809.238   5344764  RequireAdmin23  A798 B5344764 C1247361 D1814 E16299.15.amd64fr...                -1.0                -1.0           -1.000000          -1.000000           0.963245\n",
       "\n",
       "[5 rows x 109 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
